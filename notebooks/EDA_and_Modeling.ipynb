{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab7cc9c4",
   "metadata": {},
   "source": [
    "EDA Baby!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d2e8bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to connect to database at: c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\data\\licensing_data.db\n",
      "Database connection successful!\n",
      "\n",
      "Loading data into DataFrames...\n",
      "Loaded 5852 tweets.\n",
      "Loaded 0 Google Trends data points.\n",
      "Loaded 209 products.\n",
      "\n",
      "Database connection closed.\n",
      "\n",
      "--- Tweet Data Sample ---\n",
      "   id brand_name             tweet_id tweet_date username tweet_content  \\\n",
      "0   1   Fanatics  1981414626412941519             unknown                 \n",
      "1   2   Fanatics  1981378630342111638             unknown                 \n",
      "2   3   Fanatics  1981336097633218724             unknown                 \n",
      "3   4   Fanatics  1980808490873430305             unknown                 \n",
      "4   5   Fanatics  1980808431754780854             unknown                 \n",
      "\n",
      "  language  reply_count  retweet_count  like_count  quote_count  \n",
      "0       en            0              0           0            0  \n",
      "1       en            0              0           0            0  \n",
      "2       en            0              0           0            0  \n",
      "3       en            0              0           0            0  \n",
      "4       en            0              0           0            0  \n",
      "\n",
      "--- Tweet Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5852 entries, 0 to 5851\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             5852 non-null   int64 \n",
      " 1   brand_name     5852 non-null   object\n",
      " 2   tweet_id       5852 non-null   object\n",
      " 3   tweet_date     5852 non-null   object\n",
      " 4   username       5852 non-null   object\n",
      " 5   tweet_content  5852 non-null   object\n",
      " 6   language       5852 non-null   object\n",
      " 7   reply_count    5852 non-null   int64 \n",
      " 8   retweet_count  5852 non-null   int64 \n",
      " 9   like_count     5852 non-null   int64 \n",
      " 10  quote_count    5852 non-null   int64 \n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 503.0+ KB\n",
      "\n",
      "--- Google Trends Data ---\n",
      "(No data loaded)\n",
      "\n",
      "--- Product Data Sample ---\n",
      "   id  brand_id   platform                                       product_name  \\\n",
      "0   1         1  Amazon.sa  FanaticsNew England Patriots NFL Poly Mesh Sup...   \n",
      "1   2         1  Amazon.sa                FanaticsCore NFL Team Jersey Trikot   \n",
      "2   3         1  Amazon.sa                      FanaticsNFL Team Track Jacket   \n",
      "3   4         1  Amazon.sa  FanaticsMen's American Football Jersey New Eng...   \n",
      "4   5         1  Amazon.sa  FanaticsMen Crew Neck Short Sleeves Graphic Pr...   \n",
      "\n",
      "    price  avg_rating  num_reviews                                  url  \\\n",
      "0  350.26         5.0          3.0  https://www.amazon.sa/dp/B0D38MMGYY   \n",
      "1  275.60         4.4         18.0  https://www.amazon.sa/dp/B0C3D6MBVW   \n",
      "2  333.64         5.0          1.0  https://www.amazon.sa/dp/B0DH4N9GHT   \n",
      "3  314.05         4.0          1.0  https://www.amazon.sa/dp/B0B31SRXHW   \n",
      "4   86.45         NaN          NaN  https://www.amazon.sa/dp/B0D2DWF919   \n",
      "\n",
      "  brand_name  \n",
      "0   Fanatics  \n",
      "1   Fanatics  \n",
      "2   Fanatics  \n",
      "3   Fanatics  \n",
      "4   Fanatics  \n",
      "\n",
      "--- Product Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209 entries, 0 to 208\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            209 non-null    int64  \n",
      " 1   brand_id      209 non-null    int64  \n",
      " 2   platform      209 non-null    object \n",
      " 3   product_name  209 non-null    object \n",
      " 4   price         186 non-null    float64\n",
      " 5   avg_rating    119 non-null    float64\n",
      " 6   num_reviews   119 non-null    float64\n",
      " 7   url           209 non-null    object \n",
      " 8   brand_name    209 non-null    object \n",
      "dtypes: float64(3), int64(2), object(4)\n",
      "memory usage: 14.8+ KB\n",
      "\n",
      "--- Raw Tweet Date Samples ---\n",
      "0     \n",
      "1     \n",
      "2     \n",
      "3     \n",
      "4     \n",
      "5     \n",
      "6     \n",
      "7     \n",
      "8     \n",
      "9     \n",
      "10    \n",
      "11    \n",
      "12    \n",
      "13    \n",
      "14    \n",
      "15    \n",
      "16    \n",
      "17    \n",
      "18    \n",
      "19    \n",
      "Name: tweet_date, dtype: object\n",
      "\n",
      "--- Inspecting Raw Tweet Dates ---\n",
      "Data type of 'tweet_date' column: object\n",
      "First 20 raw date string samples:\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Database Connection ---\n",
    "\n",
    "# Construct the path relative to the notebook's expected location in the 'notebooks' folder\n",
    "db_relative_path = os.path.join('..', 'data', 'licensing_data.db')\n",
    "db_path = os.path.abspath(db_relative_path)\n",
    "\n",
    "print(f\"Attempting to connect to database at: {db_path}\")\n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    print(\"Database connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to database: {e}\")\n",
    "    conn = None \n",
    "\n",
    "# --- Load Data into Pandas DataFrames ---\n",
    "\n",
    "if conn:\n",
    "    print(\"\\nLoading data into DataFrames...\")\n",
    "    try:\n",
    "        # Load Tweets \n",
    "        df_tweets = pd.read_sql_query(\"SELECT * FROM tweets\", conn)\n",
    "        print(f\"Loaded {len(df_tweets)} tweets.\")\n",
    "\n",
    "        # Load Google Trends (Handle if empty/missing)\n",
    "        try:\n",
    "             df_trends = pd.read_sql_query(\"SELECT * FROM google_trends_data\", conn)\n",
    "             print(f\"Loaded {len(df_trends)} Google Trends data points.\")\n",
    "        except (pd.io.sql.DatabaseError, Exception) as e:\n",
    "             # Check specifically for \"no such table\" common after failed scrapes\n",
    "             if \"no such table: google_trends_data\" in str(e).lower():\n",
    "                 print(\"INFO: 'google_trends_data' table not found or empty. Proceeding without Google Trends.\")\n",
    "             else: # Print other errors but still create empty df\n",
    "                  print(f\"WARNING: Error loading Google Trends data: {e}. Proceeding without it.\")\n",
    "             df_trends = pd.DataFrame() # Create empty DataFrame\n",
    "\n",
    "        # Load Products (joining with brands table)\n",
    "        # Ensure the brands table was created and populated if needed by get_brand_id during scraping\n",
    "        # If brands table might be empty or missing IDs, handle potential errors or adjust query\n",
    "        try:\n",
    "            # Assuming brands table exists and has matching IDs from scraping phase\n",
    "            df_products = pd.read_sql_query(\"SELECT p.*, b.brand_name FROM products p LEFT JOIN brands b ON p.brand_id = b.id\", conn)\n",
    "            print(f\"Loaded {len(df_products)} products.\")\n",
    "        except (pd.io.sql.DatabaseError, Exception) as e:\n",
    "             print(f\"ERROR loading products (check if 'brands' table exists and has IDs): {e}\")\n",
    "             df_products = pd.DataFrame() # Create empty if load fails\n",
    "\n",
    "        # Close the connection \n",
    "        conn.close()\n",
    "        print(\"\\nDatabase connection closed.\")\n",
    "\n",
    "        # --- Initial Data Inspection ---\n",
    "        print(\"\\n--- Tweet Data Sample ---\")\n",
    "        # Display more columns if needed: pd.set_option('display.max_columns', None)\n",
    "        print(df_tweets.head())\n",
    "        print(\"\\n--- Tweet Data Info ---\")\n",
    "        df_tweets.info()\n",
    "\n",
    "        if not df_trends.empty:\n",
    "            print(\"\\n--- Google Trends Data Sample ---\")\n",
    "            print(df_trends.head())\n",
    "            print(\"\\n--- Google Trends Data Info ---\")\n",
    "            df_trends.info()\n",
    "        else:\n",
    "            print(\"\\n--- Google Trends Data ---\")\n",
    "            print(\"(No data loaded)\")\n",
    "\n",
    "        if not df_products.empty:\n",
    "            print(\"\\n--- Product Data Sample ---\")\n",
    "            print(df_products.head())\n",
    "            print(\"\\n--- Product Data Info ---\")\n",
    "            df_products.info()\n",
    "        else:\n",
    "             print(\"\\n--- Product Data ---\")\n",
    "             print(\"(No data loaded or error during load)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data loading or inspection: {e}\")\n",
    "        if conn:\n",
    "            conn.close() \n",
    "            print(\"Database connection closed due to error.\")\n",
    "else:\n",
    "    print(\"Cannot proceed without database connection.\")\n",
    "\n",
    "# Add this line at the end of Cell 1\n",
    "if 'df_tweets' in locals() and not df_tweets.empty:\n",
    "    print(\"\\n--- Raw Tweet Date Samples ---\")\n",
    "    print(df_tweets['tweet_date'].head(20))\n",
    "\n",
    "# Add/Modify these lines at the end of Cell 1\n",
    "if 'df_tweets' in locals() and not df_tweets.empty:\n",
    "    print(\"\\n--- Inspecting Raw Tweet Dates ---\")\n",
    "    print(\"Data type of 'tweet_date' column:\", df_tweets['tweet_date'].dtype)\n",
    "    print(\"First 20 raw date string samples:\")\n",
    "    # Use .unique() to potentially see different formats if they exist\n",
    "    unique_dates = df_tweets['tweet_date'].unique()\n",
    "    print(unique_dates[:20]) \n",
    "    # Check if ALL are the same format (or if there are variations)\n",
    "    if len(unique_dates) > 20:\n",
    "        print(\"...\")\n",
    "        print(\"Last 5 unique raw date strings:\")\n",
    "        print(unique_dates[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfb5406f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Cleaning and Preprocessing ---\n",
      "\n",
      "Cleaning Tweet Data...\n",
      "   Starting with 5852 tweets.\n",
      "   Attempting to parse dates (will keep rows even if parsing fails)...\n",
      "   WARNING: 5852 date formats could not be parsed and remain NaT.\n",
      "Tweet Data Cleaned:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5852 entries, 0 to 5851\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   id             5852 non-null   int64         \n",
      " 1   brand_name     5852 non-null   object        \n",
      " 2   tweet_id       5852 non-null   object        \n",
      " 3   tweet_date     0 non-null      datetime64[ns]\n",
      " 4   username       5852 non-null   object        \n",
      " 5   tweet_content  5852 non-null   object        \n",
      " 6   language       5852 non-null   object        \n",
      " 7   reply_count    5852 non-null   int64         \n",
      " 8   retweet_count  5852 non-null   int64         \n",
      " 9   like_count     5852 non-null   int64         \n",
      " 10  quote_count    5852 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(5), object(5)\n",
      "memory usage: 503.0+ KB\n",
      "\n",
      "Cleaning Product Data...\n",
      "Product Data Cleaned:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 209 entries, 0 to 208\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            209 non-null    int64  \n",
      " 1   brand_id      209 non-null    int64  \n",
      " 2   platform      209 non-null    object \n",
      " 3   product_name  209 non-null    object \n",
      " 4   price         186 non-null    float64\n",
      " 5   avg_rating    209 non-null    float64\n",
      " 6   num_reviews   209 non-null    int64  \n",
      " 7   url           209 non-null    object \n",
      " 8   brand_name    209 non-null    object \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 14.8+ KB\n",
      "\n",
      "Cleaning Complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nayef Alam\\AppData\\Local\\Temp\\ipykernel_5060\\1113502020.py:18: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  parsed_dates = pd.to_datetime(date_strings, infer_datetime_format=True, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "print(\"--- Data Cleaning and Preprocessing ---\")\n",
    "\n",
    "# --- Clean df_tweets ---\n",
    "print(\"\\nCleaning Tweet Data...\")\n",
    "\n",
    "if 'df_tweets' in locals() and not df_tweets.empty:\n",
    "\n",
    "    original_tweet_count = len(df_tweets)\n",
    "    print(f\"   Starting with {original_tweet_count} tweets.\")\n",
    "\n",
    "    # --- FIX V5: Attempt date parsing but DO NOT DROP ROWS if all fail ---\n",
    "    print(\"   Attempting to parse dates (will keep rows even if parsing fails)...\")\n",
    "    date_strings = df_tweets['tweet_date'].astype(str).str.strip()\n",
    "    parsed_dates = pd.to_datetime(date_strings, infer_datetime_format=True, errors='coerce')\n",
    "\n",
    "    df_tweets['tweet_date'] = parsed_dates # Assign results (will contain NaT)\n",
    "\n",
    "    parsed_count = df_tweets['tweet_date'].notna().sum()\n",
    "    if parsed_count < original_tweet_count:\n",
    "        print(f\"   WARNING: {original_tweet_count - parsed_count} date formats could not be parsed and remain NaT.\")\n",
    "        # DO NOT DROP: # df_tweets.dropna(subset=['tweet_date'], inplace=True)\n",
    "    else:\n",
    "        print(\"   All tweet dates parsed successfully (or were already datetime).\")\n",
    "\n",
    "    # Ensure numeric columns are numeric (Keep as before)\n",
    "    numeric_tweet_cols = ['reply_count', 'retweet_count', 'like_count', 'quote_count']\n",
    "    for col in numeric_tweet_cols:\n",
    "        df_tweets[col] = pd.to_numeric(df_tweets[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # (Keep text cleaning function if needed)\n",
    "    # def clean_text(text): ...\n",
    "\n",
    "    print(\"Tweet Data Cleaned:\")\n",
    "    df_tweets.info() # Should show 5852 entries, but 0 non-null for tweet_date\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"   WARNING: df_tweets is empty or does not exist before cleaning.\")\n",
    "\n",
    "# --- Clean df_products (Keep as before) ---\n",
    "print(\"\\nCleaning Product Data...\")\n",
    "if 'df_products' in locals() and not df_products.empty:\n",
    "    numeric_product_cols = ['price', 'avg_rating', 'num_reviews']\n",
    "    for col in numeric_product_cols:\n",
    "        df_products[col] = pd.to_numeric(df_products[col], errors='coerce')\n",
    "\n",
    "    df_products['avg_rating'] = df_products['avg_rating'].fillna(0)\n",
    "    df_products['num_reviews'] = df_products['num_reviews'].fillna(0).astype(int)\n",
    "\n",
    "    print(\"Product Data Cleaned:\")\n",
    "    df_products.info()\n",
    "else:\n",
    "    print(\"   Product DataFrame is empty or does not exist, skipping cleaning.\")\n",
    "\n",
    "print(\"\\nCleaning Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dded1735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature Engineering ---\n",
      "\n",
      "Calculating Tweet Volume per Brand...\n",
      "   Created 'df_tweet_volume' DataFrame.\n",
      "      brand_name  tweet_volume\n",
      "0       Al-Hilal          1028\n",
      "1       Al-Nassr           958\n",
      "2       Fanatics           502\n",
      "3      KSA Anime           103\n",
      "4  KSA One Piece            45\n",
      "\n",
      "Calculating Brand Metrics from Product Data...\n",
      "   Created 'df_brand_metrics' DataFrame.\n",
      "      brand_name  market_saturation  avg_perceived_quality  avg_num_reviews\n",
      "0       Al-Hilal                 25                   1.38             0.84\n",
      "1       Al-Nassr                 24                   1.35             0.75\n",
      "2       Fanatics                 25                   3.12             8.60\n",
      "3  KSA One Piece                 25                   2.14             4.12\n",
      "4        Lazurde                 25                   3.45           294.92\n",
      "\n",
      "Combining all metrics...\n",
      "   Created 'df_combined_metrics' DataFrame.\n",
      "             brand_name  tweet_volume  market_saturation  \\\n",
      "0              Al-Hilal          1028                 25   \n",
      "5               Lazurde          1015                 25   \n",
      "9          Saudi Aramco          1008                  0   \n",
      "1              Al-Nassr           958                 24   \n",
      "7         Riyadh Season           625                 10   \n",
      "6                   PIF           560                 25   \n",
      "2              Fanatics           502                 25   \n",
      "3             KSA Anime           103                  0   \n",
      "4         KSA One Piece            45                 25   \n",
      "10  Vacheron Constantin             8                 25   \n",
      "8                   STC             0                 25   \n",
      "\n",
      "    avg_perceived_quality  avg_num_reviews  \n",
      "0                    1.38             0.84  \n",
      "5                    3.45           294.92  \n",
      "9                    0.00             0.00  \n",
      "1                    1.35             0.75  \n",
      "7                    0.50             0.10  \n",
      "6                    3.91           205.16  \n",
      "2                    3.12             8.60  \n",
      "3                    0.00             0.00  \n",
      "4                    2.14             4.12  \n",
      "10                   1.79            16.72  \n",
      "8                    2.26            16.76  \n",
      "\n",
      "--- Feature Engineering Complete ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # Ensure pandas is imported\n",
    "\n",
    "print(\"--- Feature Engineering ---\")\n",
    "\n",
    "# --- Calculate Tweet Volume per Brand ---\n",
    "print(\"\\nCalculating Tweet Volume per Brand...\")\n",
    "\n",
    "# Check if df_tweets exists and has data\n",
    "if 'df_tweets' in locals() and not df_tweets.empty and 'brand_name' in df_tweets.columns:\n",
    "    # --- FIX V6: Group tweets by brand and count them ---\n",
    "    df_tweet_volume = df_tweets.groupby('brand_name').size().reset_index(name='tweet_volume')\n",
    "    \n",
    "    print(\"   Created 'df_tweet_volume' DataFrame.\")\n",
    "    print(df_tweet_volume.head())\n",
    "else:\n",
    "     print(\"   WARNING: Cannot calculate tweet volume. df_tweets is empty or missing 'brand_name'.\")\n",
    "     df_tweet_volume = pd.DataFrame(columns=['brand_name', 'tweet_volume'])\n",
    "\n",
    "\n",
    "# --- Calculate Brand Metrics from Products ---\n",
    "# (Keep this part exactly the same as before)\n",
    "print(\"\\nCalculating Brand Metrics from Product Data...\")\n",
    "if 'df_products' in locals() and not df_products.empty:\n",
    "    if 'brand_name' in df_products.columns and 'product_name' in df_products.columns and \\\n",
    "       'avg_rating' in df_products.columns and 'num_reviews' in df_products.columns:\n",
    "        \n",
    "        df_brand_metrics = df_products.groupby('brand_name').agg(\n",
    "            market_saturation=('product_name', 'count'),  \n",
    "            avg_perceived_quality=('avg_rating', 'mean'), \n",
    "            avg_num_reviews=('num_reviews', 'mean')       \n",
    "        ).reset_index()\n",
    "        # Round the averages for cleaner display\n",
    "        df_brand_metrics['avg_perceived_quality'] = df_brand_metrics['avg_perceived_quality'].round(2)\n",
    "        df_brand_metrics['avg_num_reviews'] = df_brand_metrics['avg_num_reviews'].round(2)\n",
    "        print(\"   Created 'df_brand_metrics' DataFrame.\")\n",
    "        print(df_brand_metrics.head())\n",
    "    else:\n",
    "        print(\"   ERROR: Required columns missing in df_products. Cannot calculate brand metrics.\")\n",
    "        df_brand_metrics = pd.DataFrame(columns=['brand_name', 'market_saturation', 'avg_perceived_quality', 'avg_num_reviews'])\n",
    "else:\n",
    "    print(\"   Product DataFrame is empty or does not exist, skipping brand metrics calculation.\")\n",
    "    df_brand_metrics = pd.DataFrame(columns=['brand_name', 'market_saturation', 'avg_perceived_quality', 'avg_num_reviews'])\n",
    "\n",
    "# --- Combine Metrics into One DataFrame ---\n",
    "print(\"\\nCombining all metrics...\")\n",
    "\n",
    "# Ensure both dataframes exist before merging\n",
    "if 'df_tweet_volume' in locals() and 'df_brand_metrics' in locals():\n",
    "    # Merge tweet volume with product metrics using brand_name\n",
    "    df_combined_metrics = pd.merge(df_tweet_volume, df_brand_metrics, on='brand_name', how='outer')\n",
    "\n",
    "    # Fill NaN values that result from the merge \n",
    "    df_combined_metrics['tweet_volume'] = df_combined_metrics['tweet_volume'].fillna(0).astype(int) \n",
    "    df_combined_metrics['market_saturation'] = df_combined_metrics['market_saturation'].fillna(0).astype(int)\n",
    "    df_combined_metrics['avg_perceived_quality'] = df_combined_metrics['avg_perceived_quality'].fillna(0)\n",
    "    df_combined_metrics['avg_num_reviews'] = df_combined_metrics['avg_num_reviews'].fillna(0)\n",
    "     \n",
    "    print(\"   Created 'df_combined_metrics' DataFrame.\")\n",
    "    # Sort by tweet_volume descending for better initial view\n",
    "    print(df_combined_metrics.sort_values(by='tweet_volume', ascending=False)) \n",
    "else:\n",
    "    print(\"   ERROR: Could not combine metrics because one or both required DataFrames are missing.\")\n",
    "    df_combined_metrics = pd.DataFrame() # Create empty if merge fails\n",
    "\n",
    "print(\"\\n--- Feature Engineering Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2e9db30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Checking Raw Engagement Counts from DB ---\n",
      "Sample sums of raw engagement counts per brand:\n",
      "            brand_name  total_likes  total_retweets  num_tweets\n",
      "0  Vacheron Constantin            0               0           8\n",
      "1         Saudi Aramco            0               0        1008\n",
      "2        Riyadh Season            0               0         625\n",
      "3                  PIF            0               0         560\n",
      "4              Lazurde            0               0        1015\n",
      "5        KSA One Piece            0               0          45\n",
      "6            KSA Anime            0               0         103\n",
      "7             Fanatics            0               0         502\n",
      "8             Al-Nassr            0               0         958\n",
      "9             Al-Hilal            0               0        1028\n"
     ]
    }
   ],
   "source": [
    "# --- Check Raw Engagement Counts ---\n",
    "print(\"\\n--- Checking Raw Engagement Counts from DB ---\")\n",
    "conn = None # Ensure conn is defined\n",
    "try:\n",
    "    conn = sqlite3.connect(db_path) # db_path should still be defined from Cell 1\n",
    "    df_check = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            brand_name, \n",
    "            SUM(like_count) as total_likes, \n",
    "            SUM(retweet_count) as total_retweets,\n",
    "            COUNT(*) as num_tweets\n",
    "        FROM tweets \n",
    "        GROUP BY brand_name\n",
    "        ORDER BY total_likes DESC\n",
    "        LIMIT 15 \n",
    "    \"\"\", conn)\n",
    "    \n",
    "    print(\"Sample sums of raw engagement counts per brand:\")\n",
    "    print(df_check)\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error checking raw counts: {e}\")\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef8dacc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Visualization (Refined) ---\n",
      "\n",
      "Generating Plot 1: Tweet Volume by Brand...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nayef Alam\\AppData\\Local\\Temp\\ipykernel_5060\\3220100558.py:17: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=df_sorted_hype, y='brand_name', x='tweet_volume', palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved plot as tweet_volume_by_brand_v2.png\n",
      "\n",
      "Generating Plot 2: Market Saturation (Amazon Products) by Brand...\n",
      "   Saved plot as market_saturation_by_brand_v2.png\n",
      "\n",
      "Generating Plot 3: Tweet Volume vs. Market Saturation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nayef Alam\\AppData\\Local\\Temp\\ipykernel_5060\\3220100558.py:33: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=df_sorted_saturation, y='brand_name', x='market_saturation', palette='magma')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved plot as hype_vs_saturation_v2.png\n",
      "\n",
      "--- Visualization Complete ---\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np # For potential log scale\n",
    "import os # For saving plots\n",
    "\n",
    "print(\"--- Data Visualization (Refined) ---\")\n",
    "\n",
    "# Ensure the combined metrics DataFrame exists and isn't empty\n",
    "if 'df_combined_metrics' in locals() and not df_combined_metrics.empty:\n",
    "\n",
    "    # --- Plot 1: Tweet Volume (Hype Proxy) ---\n",
    "    print(\"\\nGenerating Plot 1: Tweet Volume by Brand...\")\n",
    "    plt.figure(figsize=(12, 7)) \n",
    "    df_sorted_hype = df_combined_metrics.sort_values('tweet_volume', ascending=False)\n",
    "    # Filter out brands with 0 tweet volume if desired for cleaner plot\n",
    "    # df_sorted_hype = df_sorted_hype[df_sorted_hype['tweet_volume'] > 0] \n",
    "    sns.barplot(data=df_sorted_hype, y='brand_name', x='tweet_volume', palette='viridis')\n",
    "    plt.title('Tweet Volume (Hype Proxy) by Brand')\n",
    "    plt.xlabel('Total Tweets Collected')\n",
    "    plt.ylabel('Brand')\n",
    "    plt.tight_layout() \n",
    "    plt.savefig(os.path.join('..', 'tweet_volume_by_brand_v2.png')) \n",
    "    print(\"   Saved plot as tweet_volume_by_brand_v2.png\")\n",
    "    plt.close() \n",
    "\n",
    "\n",
    "    # --- Plot 2: Market Saturation ---\n",
    "    print(\"\\nGenerating Plot 2: Market Saturation (Amazon Products) by Brand...\")\n",
    "    df_saturated = df_combined_metrics[df_combined_metrics['market_saturation'] > 0]\n",
    "    if not df_saturated.empty:\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        df_sorted_saturation = df_saturated.sort_values('market_saturation', ascending=False)\n",
    "        sns.barplot(data=df_sorted_saturation, y='brand_name', x='market_saturation', palette='magma')\n",
    "        plt.title('Market Saturation (Amazon Products Found) by Brand')\n",
    "        plt.xlabel('Number of Products Found (Max 25)')\n",
    "        plt.ylabel('Brand')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join('..', 'market_saturation_by_brand_v2.png'))\n",
    "        print(\"   Saved plot as market_saturation_by_brand_v2.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"   Skipping Market Saturation plot: No brands with products found.\")\n",
    "\n",
    "\n",
    "    # --- Plot 3: Hype vs. Saturation Scatter Plot ---\n",
    "    print(\"\\nGenerating Plot 3: Tweet Volume vs. Market Saturation...\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # Use only brands with BOTH tweets and products for this plot for clearer comparison\n",
    "    df_plot_data = df_combined_metrics[(df_combined_metrics['market_saturation'] > 0) & (df_combined_metrics['tweet_volume'] > 0)].copy()\n",
    "\n",
    "    if not df_plot_data.empty:\n",
    "        scatter = sns.scatterplot(\n",
    "            data=df_plot_data, \n",
    "            x='market_saturation', \n",
    "            y='tweet_volume', \n",
    "            hue='avg_perceived_quality', # Color points by average rating\n",
    "            size='avg_num_reviews',      # Size points by average number of reviews\n",
    "            sizes=(50, 500),             \n",
    "            palette='coolwarm',          \n",
    "            legend='auto' \n",
    "        )\n",
    "        \n",
    "        # Add labels \n",
    "        for i in range(df_plot_data.shape[0]):\n",
    "            plt.text(\n",
    "                x=df_plot_data['market_saturation'].iloc[i] + 0.1, \n",
    "                y=df_plot_data['tweet_volume'].iloc[i] + 5, \n",
    "                s=df_plot_data['brand_name'].iloc[i], \n",
    "                fontdict=dict(color='black', size=9)\n",
    "            )\n",
    "\n",
    "        plt.title('Hype (Tweet Volume) vs. Market Saturation')\n",
    "        plt.xlabel('Market Saturation (Amazon Products)')\n",
    "        plt.ylabel('Tweet Volume (Total Tweets)')\n",
    "        \n",
    "        # Add quadrant lines at median values for context\n",
    "        median_hype = df_plot_data['tweet_volume'].median()\n",
    "        median_saturation = df_plot_data['market_saturation'].median()\n",
    "        plt.axhline(median_hype, color='grey', linestyle='--', linewidth=0.8)\n",
    "        plt.axvline(median_saturation, color='grey', linestyle='--', linewidth=0.8)\n",
    "        # Add text labels for quadrants if desired (example)\n",
    "        # plt.text(median_saturation * 1.1, median_hype * 1.1, \"High Hype, High Saturation\", color='grey')\n",
    "        # plt.text(median_saturation * 0.9, median_hype * 1.1, \"High Hype, Low Saturation\", color='grey', ha='right')\n",
    "        # ... etc for other quadrants ...\n",
    "        \n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1]) \n",
    "        plt.savefig(os.path.join('..', 'hype_vs_saturation_v2.png'))\n",
    "        print(\"   Saved plot as hype_vs_saturation_v2.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "         print(\"   Skipping Hype vs. Saturation plot: No brands with both products and tweets found.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Visualization Complete ---\")\n",
    "\n",
    "else:\n",
    "    print(\"   ERROR: 'df_combined_metrics' DataFrame not found or empty. Cannot create plots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1185abab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving Combined Metrics ---\n",
      "   Successfully saved combined metrics to: c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\data\\brand_metrics_final.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Save Final Metrics to CSV ---\n",
    "print(\"\\n--- Saving Combined Metrics ---\")\n",
    "\n",
    "if 'df_combined_metrics' in locals() and not df_combined_metrics.empty:\n",
    "    csv_path_relative = os.path.join('..', 'data', 'brand_metrics_final.csv')\n",
    "    csv_path = os.path.abspath(csv_path_relative)\n",
    "    try:\n",
    "        df_combined_metrics.to_csv(csv_path, index=False)\n",
    "        print(f\"   Successfully saved combined metrics to: {csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Error saving metrics to CSV: {e}\")\n",
    "else:\n",
    "    print(\"   ERROR: 'df_combined_metrics' not found or empty. Cannot save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10901ca9",
   "metadata": {},
   "source": [
    "Sentiment Analysis (Did not work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "652a419d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
      "Requirement already satisfied: requests in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from vaderSentiment) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from requests->vaderSentiment) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from requests->vaderSentiment) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from requests->vaderSentiment) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from requests->vaderSentiment) (2025.10.5)\n",
      "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a357de7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 3a: Tweet Sentiment Analysis ---\n",
      "\n",
      "Calculating sentiment scores for tweets...\n",
      "   Added 'sentiment_score' column.\n",
      "  brand_name tweet_content  sentiment_score\n",
      "0   Fanatics                            0.0\n",
      "1   Fanatics                            0.0\n",
      "2   Fanatics                            0.0\n",
      "3   Fanatics                            0.0\n",
      "4   Fanatics                            0.0\n",
      "\n",
      "Calculating average sentiment per brand...\n",
      "   Created 'df_avg_sentiment' DataFrame.\n",
      "      brand_name  avg_tweet_sentiment\n",
      "0       Al-Hilal                  0.0\n",
      "1       Al-Nassr                  0.0\n",
      "2       Fanatics                  0.0\n",
      "3      KSA Anime                  0.0\n",
      "4  KSA One Piece                  0.0\n",
      "\n",
      "Merging average sentiment into combined metrics...\n",
      "   Updated 'df_combined_metrics' DataFrame:\n",
      "             brand_name  tweet_volume  market_saturation  \\\n",
      "0              Al-Hilal          1028                 25   \n",
      "1              Al-Nassr           958                 24   \n",
      "2              Fanatics           502                 25   \n",
      "3             KSA Anime           103                  0   \n",
      "4         KSA One Piece            45                 25   \n",
      "5               Lazurde          1015                 25   \n",
      "6                   PIF           560                 25   \n",
      "7         Riyadh Season           625                 10   \n",
      "8                   STC             0                 25   \n",
      "9          Saudi Aramco          1008                  0   \n",
      "10  Vacheron Constantin             8                 25   \n",
      "\n",
      "    avg_perceived_quality  avg_num_reviews  avg_tweet_sentiment  \n",
      "0                    1.38             0.84                  0.0  \n",
      "1                    1.35             0.75                  0.0  \n",
      "2                    3.12             8.60                  0.0  \n",
      "3                    0.00             0.00                  0.0  \n",
      "4                    2.14             4.12                  0.0  \n",
      "5                    3.45           294.92                  0.0  \n",
      "6                    3.91           205.16                  0.0  \n",
      "7                    0.50             0.10                  0.0  \n",
      "8                    2.26            16.76                  0.0  \n",
      "9                    0.00             0.00                  0.0  \n",
      "10                   1.79            16.72                  0.0  \n",
      "\n",
      "--- Sentiment Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd # Ensure pandas is imported\n",
    "\n",
    "print(\"--- Phase 3a: Tweet Sentiment Analysis ---\")\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get VADER sentiment score (specifically the compound score)\n",
    "def get_vader_sentiment(text):\n",
    "    if isinstance(text, str):\n",
    "        # VADER's polarity_scores returns dict: {neg, neu, pos, compound}\n",
    "        # Compound score is a normalized score between -1 (most negative) and +1 (most positive)\n",
    "        return analyzer.polarity_scores(text)['compound']\n",
    "    return 0 # Return neutral score for non-string data (like potential NaN)\n",
    "\n",
    "# Check if df_tweets exists and has the content column\n",
    "if 'df_tweets' in locals() and not df_tweets.empty and 'tweet_content' in df_tweets.columns:\n",
    "    print(\"\\nCalculating sentiment scores for tweets...\")\n",
    "    # Apply the function to the 'tweet_content' column\n",
    "    # Create a new column 'sentiment_score'\n",
    "    df_tweets['sentiment_score'] = df_tweets['tweet_content'].apply(get_vader_sentiment)\n",
    "    \n",
    "    print(\"   Added 'sentiment_score' column.\")\n",
    "    # Display sample results including the new score\n",
    "    print(df_tweets[['brand_name', 'tweet_content', 'sentiment_score']].head())\n",
    "\n",
    "    # --- Calculate Average Sentiment per Brand ---\n",
    "    print(\"\\nCalculating average sentiment per brand...\")\n",
    "    # Group by brand_name and calculate the mean of the sentiment scores\n",
    "    df_avg_sentiment = df_tweets.groupby('brand_name')['sentiment_score'].mean().reset_index()\n",
    "    df_avg_sentiment.rename(columns={'sentiment_score': 'avg_tweet_sentiment'}, inplace=True)\n",
    "    df_avg_sentiment['avg_tweet_sentiment'] = df_avg_sentiment['avg_tweet_sentiment'].round(3) # Round for readability\n",
    "    \n",
    "    print(\"   Created 'df_avg_sentiment' DataFrame.\")\n",
    "    print(df_avg_sentiment.head())\n",
    "\n",
    "    # --- Merge Average Sentiment into Combined Metrics ---\n",
    "    print(\"\\nMerging average sentiment into combined metrics...\")\n",
    "    if 'df_combined_metrics' in locals() and not df_combined_metrics.empty:\n",
    "        df_combined_metrics = pd.merge(df_combined_metrics, df_avg_sentiment, on='brand_name', how='left')\n",
    "        # Fill potential NaN if a brand had no tweets to analyze\n",
    "        df_combined_metrics['avg_tweet_sentiment'] = df_combined_metrics['avg_tweet_sentiment'].fillna(0) \n",
    "        \n",
    "        print(\"   Updated 'df_combined_metrics' DataFrame:\")\n",
    "        # Display the updated combined metrics, sorted by sentiment\n",
    "        print(df_combined_metrics.sort_values(by='avg_tweet_sentiment', ascending=False))\n",
    "    else:\n",
    "        print(\"   ERROR: 'df_combined_metrics' not found. Cannot merge sentiment.\")\n",
    "        \n",
    "else:\n",
    "    print(\"   WARNING: df_tweets is empty or missing 'tweet_content'. Cannot perform sentiment analysis.\")\n",
    "\n",
    "print(\"\\n--- Sentiment Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1946d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inspecting Tweet Content and Sentiment Scores ---\n",
      "Random sample of tweets and their calculated sentiment scores:\n",
      "        brand_name tweet_content  sentiment_score\n",
      "2366  Saudi Aramco                            0.0\n",
      "4330      Al-Hilal                            0.0\n",
      "1935           PIF                            0.0\n",
      "4347      Al-Hilal                            0.0\n",
      "4984      Al-Nassr                            0.0\n",
      "1797           PIF                            0.0\n",
      "4419      Al-Hilal                            0.0\n",
      "157       Fanatics                            0.0\n",
      "1000       Lazurde                            0.0\n",
      "1227       Lazurde                            0.0\n",
      "1376       Lazurde                            0.0\n",
      "1869           PIF                            0.0\n",
      "3793      Al-Hilal                            0.0\n",
      "80        Fanatics                            0.0\n",
      "2054           PIF                            0.0\n",
      "\n",
      "Value counts for sentiment_score:\n",
      "sentiment_score\n",
      "0.0    5852\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Inspecting Tweet Content and Sentiment Scores ---\")\n",
    "\n",
    "if 'df_tweets' in locals() and not df_tweets.empty and 'sentiment_score' in df_tweets.columns:\n",
    "    # Display some tweets and their scores\n",
    "    # Filter for potentially non-neutral tweets if possible (though scores are 0 now)\n",
    "    # Let's just look at a random sample\n",
    "    print(\"Random sample of tweets and their calculated sentiment scores:\")\n",
    "    print(df_tweets[['brand_name', 'tweet_content', 'sentiment_score']].sample(15))\n",
    "\n",
    "    # Check distribution of scores (will likely be all 0)\n",
    "    print(\"\\nValue counts for sentiment_score:\")\n",
    "    print(df_tweets['sentiment_score'].value_counts())\n",
    "else:\n",
    "    print(\"df_tweets is empty or missing sentiment_score column.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
