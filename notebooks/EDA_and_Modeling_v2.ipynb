{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c05e115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: vaderSentiment in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (1.7.2)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: requests in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from vaderSentiment) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.10.23-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from requests->vaderSentiment) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from requests->vaderSentiment) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from requests->vaderSentiment) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nayef alam\\desktop\\ksa_licensing_model\\venv\\lib\\site-packages (from requests->vaderSentiment) (2025.10.5)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 5.9 MB/s  0:00:00\n",
      "Downloading regex-2025.10.23-cp313-cp313-win_amd64.whl (276 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: regex, click, nltk\n",
      "\n",
      "   ------------- -------------------------- 1/3 [click]\n",
      "   ------------- -------------------------- 1/3 [click]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   -------------------------- ------------- 2/3 [nltk]\n",
      "   ---------------------------------------- 3/3 [nltk]\n",
      "\n",
      "Successfully installed click-8.3.0 nltk-3.9.2 regex-2025.10.23\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Cell 0: Install necessary libraries\n",
    "%pip install pandas matplotlib seaborn vaderSentiment scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf5caf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to connect to database at: c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\data\\licensing_data.db\n",
      "Database connection successful!\n",
      "\n",
      "Loading data into DataFrames...\n",
      "Loaded 17386 raw tweets.\n",
      "Loaded 1020 raw products.\n",
      "\n",
      "Database connection closed.\n",
      "\n",
      "--- Raw Tweet Data Sample ---\n",
      "  brand_name                      tweet_date  \\\n",
      "0    Almarai  Thu Oct 23 09:27:43 +0000 2025   \n",
      "1    Almarai  Thu Oct 23 07:35:39 +0000 2025   \n",
      "2    Almarai  Tue Oct 21 11:23:38 +0000 2025   \n",
      "3    Almarai  Mon Oct 20 18:22:12 +0000 2025   \n",
      "4    Almarai  Sun Oct 19 16:16:23 +0000 2025   \n",
      "\n",
      "                                       tweet_content  like_count  \\\n",
      "0  Almarai Jobs in Dammam Jobs in Saudi Arabia\\n\\...           0   \n",
      "1  Are you ready to take your career to new heigh...           0   \n",
      "2  what next, selling our land to other countries...           0   \n",
      "3  @m_almuhaidib @almarai I have dates, Saudi cof...           1   \n",
      "4  @Almarai_Care Asslam walaikum, I request to al...           0   \n",
      "\n",
      "   retweet_count  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "\n",
      "--- Raw Tweet Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17386 entries, 0 to 17385\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             17386 non-null  int64 \n",
      " 1   brand_name     17386 non-null  object\n",
      " 2   tweet_id       17386 non-null  object\n",
      " 3   tweet_date     17386 non-null  object\n",
      " 4   username       17386 non-null  object\n",
      " 5   tweet_content  17386 non-null  object\n",
      " 6   language       17386 non-null  object\n",
      " 7   reply_count    17386 non-null  int64 \n",
      " 8   retweet_count  17386 non-null  int64 \n",
      " 9   like_count     17386 non-null  int64 \n",
      " 10  quote_count    17386 non-null  int64 \n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 1.5+ MB\n",
      "\n",
      "--- Raw Product Data Sample ---\n",
      "  brand_name                                       product_name  price  \\\n",
      "0    Almarai  Almarai Uht Full Fat Milk With Vitamin In Tetr...  54.99   \n",
      "1    Almarai                          Almarai Ghee Butter, 800G  37.95   \n",
      "2    Almarai       Almarai Fresh Full Fat Plain Yoghurt, 170 gm   2.00   \n",
      "3    Almarai     Almarai Full Cream Milk Powder, 2.25 kg, White  84.95   \n",
      "4    Almarai                       Evaporated Milk 6 Pack 170 G  17.95   \n",
      "\n",
      "   avg_rating  num_reviews  \n",
      "0         4.4       1432.0  \n",
      "1         4.6       1194.0  \n",
      "2         5.0         10.0  \n",
      "3         4.6        876.0  \n",
      "4         4.6        320.0  \n",
      "\n",
      "--- Raw Product Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1020 entries, 0 to 1019\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            1020 non-null   int64  \n",
      " 1   brand_id      1020 non-null   int64  \n",
      " 2   platform      1020 non-null   object \n",
      " 3   product_name  1020 non-null   object \n",
      " 4   price         828 non-null    float64\n",
      " 5   avg_rating    644 non-null    float64\n",
      " 6   num_reviews   644 non-null    float64\n",
      " 7   url           1020 non-null   object \n",
      " 8   brand_name    1020 non-null   object \n",
      "dtypes: float64(3), int64(2), object(4)\n",
      "memory usage: 71.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load Data from Database\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Database Connection ---\n",
    "db_relative_path = os.path.join('..', 'data', 'licensing_data.db')\n",
    "db_path = os.path.abspath(db_relative_path)\n",
    "print(f\"Attempting to connect to database at: {db_path}\")\n",
    "\n",
    "conn = None # Initialize conn\n",
    "try:\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    print(\"Database connection successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not connect to database: {e}\")\n",
    "    # Stop execution if DB connection fails\n",
    "    raise SystemExit(\"Database connection failed, cannot proceed.\") from e\n",
    "\n",
    "# --- Load Data into Pandas DataFrames ---\n",
    "print(\"\\nLoading data into DataFrames...\")\n",
    "try:\n",
    "    # Load Tweets (using correct table name 'tweets')\n",
    "    df_tweets_raw = pd.read_sql_query(\"SELECT * FROM tweets\", conn)\n",
    "    print(f\"Loaded {len(df_tweets_raw)} raw tweets.\")\n",
    "    \n",
    "    # Load Products (joining with brands table)\n",
    "    # Using LEFT JOIN to keep products even if brand_id is somehow missing in brands table\n",
    "    df_products_raw = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            p.*, \n",
    "            b.brand_name AS brand_name_from_join \n",
    "        FROM products p \n",
    "        LEFT JOIN brands b ON p.brand_id = b.id\n",
    "    \"\"\", conn)\n",
    "    # Use the brand_name from the join, handle potential nulls if join failed\n",
    "    df_products_raw['brand_name'] = df_products_raw['brand_name_from_join']\n",
    "    df_products_raw.drop(columns=['brand_name_from_join'], inplace=True) \n",
    "    print(f\"Loaded {len(df_products_raw)} raw products.\")\n",
    "    \n",
    "    # Close the connection\n",
    "    conn.close()\n",
    "    print(\"\\nDatabase connection closed.\")\n",
    "    \n",
    "    # --- Initial Data Inspection ---\n",
    "    print(\"\\n--- Raw Tweet Data Sample ---\")\n",
    "    # Display more info to confirm fields are loaded\n",
    "    print(df_tweets_raw[['brand_name', 'tweet_date', 'tweet_content', 'like_count', 'retweet_count']].head())\n",
    "    print(\"\\n--- Raw Tweet Data Info ---\")\n",
    "    df_tweets_raw.info()\n",
    "\n",
    "    print(\"\\n--- Raw Product Data Sample ---\")\n",
    "    print(df_products_raw[['brand_name', 'product_name', 'price', 'avg_rating', 'num_reviews']].head())\n",
    "    print(\"\\n--- Raw Product Data Info ---\")\n",
    "    df_products_raw.info()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Error loading data from database: {e}\")\n",
    "    if conn:\n",
    "        conn.close()\n",
    "        print(\"Database connection closed due to error.\")\n",
    "    raise SystemExit(\"Data loading failed.\") from e # Stop if loading fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e06901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Cleaning and Preprocessing ---\n",
      "\n",
      "Cleaning Tweet Data...\n",
      "   Starting with 17386 tweets.\n",
      "   Attempting to parse dates using format: '%a %b %d %H:%M:%S +0000 %Y'...\n",
      "   All tweet dates parsed successfully.\n",
      "   Applying basic cleaning to tweet_content...\n",
      "Tweet Data Cleaned:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17386 entries, 0 to 17385\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   id               17386 non-null  int64         \n",
      " 1   brand_name       17386 non-null  object        \n",
      " 2   tweet_id         17386 non-null  object        \n",
      " 3   tweet_date       17386 non-null  datetime64[ns]\n",
      " 4   username         17386 non-null  object        \n",
      " 5   tweet_content    17386 non-null  object        \n",
      " 6   language         17386 non-null  object        \n",
      " 7   reply_count      17386 non-null  int64         \n",
      " 8   retweet_count    17386 non-null  int64         \n",
      " 9   like_count       17386 non-null  int64         \n",
      " 10  quote_count      17386 non-null  int64         \n",
      " 11  cleaned_content  17386 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(5), object(6)\n",
      "memory usage: 1.6+ MB\n",
      "\n",
      "Cleaning Product Data...\n",
      "Product Data Cleaned:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1020 entries, 0 to 1019\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            1020 non-null   int64  \n",
      " 1   brand_id      1020 non-null   int64  \n",
      " 2   platform      1020 non-null   object \n",
      " 3   product_name  1020 non-null   object \n",
      " 4   price         828 non-null    float64\n",
      " 5   avg_rating    1020 non-null   float64\n",
      " 6   num_reviews   1020 non-null   int64  \n",
      " 7   url           1020 non-null   object \n",
      " 8   brand_name    1020 non-null   object \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 71.8+ KB\n",
      "\n",
      "--- Cleaning Complete ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Cleaning & Preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd # Ensure pandas is imported\n",
    "\n",
    "print(\"--- Data Cleaning and Preprocessing ---\")\n",
    "\n",
    "# --- Clean df_tweets ---\n",
    "print(\"\\nCleaning Tweet Data...\")\n",
    "\n",
    "# Make a copy to avoid SettingWithCopyWarning\n",
    "df_tweets = df_tweets_raw.copy()\n",
    "\n",
    "if not df_tweets.empty:\n",
    "\n",
    "    original_tweet_count = len(df_tweets)\n",
    "    print(f\"   Starting with {original_tweet_count} tweets.\")\n",
    "\n",
    "    # --- FIX: Parse Tweet Dates using the CORRECT format ---\n",
    "    # The format from the JSON file looks like: 'Mon Oct 20 16:41:09 +0000 2025'\n",
    "    # This corresponds to the format string: '%a %b %d %H:%M:%S +0000 %Y'\n",
    "    date_format_string = '%a %b %d %H:%M:%S +0000 %Y' \n",
    "    print(f\"   Attempting to parse dates using format: '{date_format_string}'...\")\n",
    "    \n",
    "    parsed_dates = pd.to_datetime(df_tweets['tweet_date'], format=date_format_string, errors='coerce')\n",
    "\n",
    "    df_tweets['tweet_date'] = parsed_dates\n",
    "    \n",
    "    # --- Drop rows with NaT dates ---\n",
    "    parsed_count = df_tweets['tweet_date'].notna().sum()\n",
    "    if parsed_count < original_tweet_count:\n",
    "        print(f\"   WARNING: {original_tweet_count - parsed_count} date formats could not be parsed even with explicit format.\")\n",
    "        # Print first few failed *original* strings for diagnosis\n",
    "        failed_indices = df_tweets[df_tweets['tweet_date'].isna()].index\n",
    "        print(\"   First 5 failing original date strings:\")\n",
    "        # Re-access original raw data for failed indices\n",
    "        print(df_tweets_raw.loc[failed_indices, 'tweet_date'].head()) \n",
    "        \n",
    "        df_tweets.dropna(subset=['tweet_date'], inplace=True)\n",
    "        print(f\"   Dropped invalid date rows. Remaining tweets: {len(df_tweets)}\")\n",
    "    else:\n",
    "        print(\"   All tweet dates parsed successfully.\")\n",
    "\n",
    "    # Ensure numeric columns are numeric (using correct names)\n",
    "    numeric_tweet_cols = ['reply_count', 'retweet_count', 'like_count', 'quote_count']\n",
    "    for col in numeric_tweet_cols:\n",
    "        df_tweets[col] = pd.to_numeric(df_tweets[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Basic text cleaning function \n",
    "    def clean_text(text): \n",
    "        if isinstance(text, str):\n",
    "            text = re.sub(r'http\\S+', '', text) # Remove URLs\n",
    "            # Keep basic punctuation, remove others. Keep Arabic.\n",
    "            text = re.sub(r'[^\\w\\s.,!?-_\\u0600-\\u06FF]+', '', text) \n",
    "            text = text.lower().strip()\n",
    "        # Return empty string if input wasn't a string (handles potential None/NaN)\n",
    "        return text if isinstance(text, str) else '' \n",
    "\n",
    "    # Apply cleaning to 'tweet_content'\n",
    "    print(\"   Applying basic cleaning to tweet_content...\")\n",
    "    df_tweets['cleaned_content'] = df_tweets['tweet_content'].apply(clean_text)\n",
    "\n",
    "    print(\"Tweet Data Cleaned:\")\n",
    "    if not df_tweets.empty:\n",
    "        df_tweets.info() \n",
    "    else:\n",
    "        print(\"   DataFrame became empty after dropping rows with unparseable dates.\")\n",
    "\n",
    "else:\n",
    "    print(\"   WARNING: Raw tweet DataFrame is empty. Skipping tweet cleaning.\")\n",
    "\n",
    "# --- Clean df_products ---\n",
    "print(\"\\nCleaning Product Data...\")\n",
    "\n",
    "# Make a copy\n",
    "df_products = df_products_raw.copy()\n",
    "\n",
    "if not df_products.empty:\n",
    "    # Ensure numeric columns are numeric\n",
    "    numeric_product_cols = ['price', 'avg_rating', 'num_reviews']\n",
    "    for col in numeric_product_cols:\n",
    "        df_products[col] = pd.to_numeric(df_products[col], errors='coerce')\n",
    "        \n",
    "    # Fill missing ratings and review counts with 0\n",
    "    df_products['avg_rating'] = df_products['avg_rating'].fillna(0)\n",
    "    # Ensure num_reviews is integer after filling\n",
    "    df_products['num_reviews'] = df_products['num_reviews'].fillna(0).astype(int) \n",
    "    \n",
    "    print(\"Product Data Cleaned:\")\n",
    "    df_products.info()\n",
    "else:\n",
    "    print(\"   Raw product DataFrame is empty. Skipping product cleaning.\")\n",
    "\n",
    "print(\"\\n--- Cleaning Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4075310f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature Engineering ---\n",
      "\n",
      "Calculating Tweet Volume per Brand...\n",
      "   Created 'df_tweet_volume' DataFrame.\n",
      "                                          brand_name  tweet_volume\n",
      "0  \\n    # Copied from the log where errors start...           144\n",
      "1                                               APOA             5\n",
      "2                                             Abadia            38\n",
      "3                             Abdul Samad Al Qurashi            44\n",
      "4                                    Al Nakheel Mall           167\n",
      "\n",
      "Calculating Brand Metrics from Product Data...\n",
      "   Created 'df_brand_metrics' DataFrame.\n",
      "               brand_name  market_saturation  avg_perceived_quality  \\\n",
      "0                    1886                 25                   3.58   \n",
      "1                    APOA                  2                   0.00   \n",
      "2                  Abadia                 25                   2.10   \n",
      "3  Abdul Samad Al Qurashi                 25                   1.57   \n",
      "4                Al Rabie                 25                   2.96   \n",
      "\n",
      "   avg_num_reviews  \n",
      "0           254.12  \n",
      "1             0.00  \n",
      "2             4.56  \n",
      "3             4.72  \n",
      "4            49.16  \n",
      "\n",
      "Combining all metrics...\n",
      "   Created 'df_combined_metrics' DataFrame.\n",
      "   brand_name  tweet_volume  market_saturation  avg_perceived_quality  \\\n",
      "52       SACO          1030                 25                   2.16   \n",
      "58      eXtra          1026                 23                   4.45   \n",
      "13    Almarai          1021                 25                   4.62   \n",
      "36       Kudu          1013                 25                   1.25   \n",
      "8     Al-Ahli           980                  0                   0.00   \n",
      "\n",
      "    avg_num_reviews  \n",
      "52           128.40  \n",
      "58           298.65  \n",
      "13           285.80  \n",
      "36            72.12  \n",
      "8              0.00  \n",
      "\n",
      "--- Feature Engineering Complete ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Feature Engineering (Tweet Volume, Product Metrics)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd # Ensure pandas is imported\n",
    "\n",
    "print(\"--- Feature Engineering ---\")\n",
    "\n",
    "# --- Calculate Tweet Volume per Brand ---\n",
    "print(\"\\nCalculating Tweet Volume per Brand...\")\n",
    "\n",
    "# Check if df_tweets exists and has data\n",
    "if 'df_tweets' in locals() and not df_tweets.empty and 'brand_name' in df_tweets.columns:\n",
    "    # Group tweets by brand and count them\n",
    "    df_tweet_volume = df_tweets.groupby('brand_name').size().reset_index(name='tweet_volume')\n",
    "\n",
    "    print(\"   Created 'df_tweet_volume' DataFrame.\")\n",
    "    print(df_tweet_volume.head())\n",
    "else:\n",
    "     print(\"   WARNING: Cannot calculate tweet volume. df_tweets is empty or missing 'brand_name'.\")\n",
    "     df_tweet_volume = pd.DataFrame(columns=['brand_name', 'tweet_volume'])\n",
    "\n",
    "\n",
    "# --- Calculate Brand Metrics from Products ---\n",
    "print(\"\\nCalculating Brand Metrics from Product Data...\")\n",
    "if 'df_products' in locals() and not df_products.empty:\n",
    "    if 'brand_name' in df_products.columns and 'product_name' in df_products.columns and \\\n",
    "       'avg_rating' in df_products.columns and 'num_reviews' in df_products.columns:\n",
    "\n",
    "        df_brand_metrics = df_products.groupby('brand_name').agg(\n",
    "            market_saturation=('product_name', 'count'),\n",
    "            avg_perceived_quality=('avg_rating', 'mean'),\n",
    "            avg_num_reviews=('num_reviews', 'mean')\n",
    "        ).reset_index()\n",
    "        # Round the averages for cleaner display\n",
    "        df_brand_metrics['avg_perceived_quality'] = df_brand_metrics['avg_perceived_quality'].round(2)\n",
    "        df_brand_metrics['avg_num_reviews'] = df_brand_metrics['avg_num_reviews'].round(2)\n",
    "        print(\"   Created 'df_brand_metrics' DataFrame.\")\n",
    "        print(df_brand_metrics.head())\n",
    "    else:\n",
    "        print(\"   ERROR: Required columns missing in df_products. Cannot calculate brand metrics.\")\n",
    "        print(\"   Columns found:\", df_products.columns)\n",
    "        df_brand_metrics = pd.DataFrame(columns=['brand_name', 'market_saturation', 'avg_perceived_quality', 'avg_num_reviews'])\n",
    "else:\n",
    "    print(\"   Product DataFrame is empty or does not exist, skipping brand metrics calculation.\")\n",
    "    df_brand_metrics = pd.DataFrame(columns=['brand_name', 'market_saturation', 'avg_perceived_quality', 'avg_num_reviews'])\n",
    "\n",
    "# --- Combine Metrics into One DataFrame ---\n",
    "print(\"\\nCombining all metrics...\")\n",
    "\n",
    "# Ensure both dataframes exist before merging\n",
    "if 'df_tweet_volume' in locals() and 'df_brand_metrics' in locals():\n",
    "    # Merge tweet volume with product metrics using brand_name\n",
    "    df_combined_metrics = pd.merge(df_tweet_volume, df_brand_metrics, on='brand_name', how='outer')\n",
    "\n",
    "    # Fill NaN values that result from the merge\n",
    "    df_combined_metrics['tweet_volume'] = df_combined_metrics['tweet_volume'].fillna(0).astype(int)\n",
    "    df_combined_metrics['market_saturation'] = df_combined_metrics['market_saturation'].fillna(0).astype(int)\n",
    "    df_combined_metrics['avg_perceived_quality'] = df_combined_metrics['avg_perceived_quality'].fillna(0)\n",
    "    df_combined_metrics['avg_num_reviews'] = df_combined_metrics['avg_num_reviews'].fillna(0)\n",
    "\n",
    "    print(\"   Created 'df_combined_metrics' DataFrame.\")\n",
    "    print(df_combined_metrics.sort_values(by='tweet_volume', ascending=False).head()) # Show top by volume\n",
    "else:\n",
    "    print(\"   ERROR: Could not combine metrics because one or both required DataFrames are missing.\")\n",
    "    # Define df_combined_metrics as empty if merge fails, to prevent later errors\n",
    "    df_combined_metrics = pd.DataFrame() \n",
    "\n",
    "print(\"\\n--- Feature Engineering Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef21d912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 3a: Tweet Sentiment Analysis ---\n",
      "\n",
      "Calculating sentiment scores for tweets using 'cleaned_content'...\n",
      "   Added 'sentiment_score' column.\n",
      "   Sample tweets with sentiment scores:\n",
      "                   brand_name  \\\n",
      "15270                   eXtra   \n",
      "645                   Almarai   \n",
      "12477            Body Masters   \n",
      "17088                  Qormuz   \n",
      "7931              Arabian Oud   \n",
      "1259   Saudia Dairy (SADAFCO)   \n",
      "264                   Almarai   \n",
      "3611        Al-Othaim Markets   \n",
      "6181                    Goody   \n",
      "2604                    NADEC   \n",
      "\n",
      "                                         cleaned_content  sentiment_score  \n",
      "15270  @kaskoolc ياهلا انتهت عروض اليوم الوطني بتاريخ...           0.0000  \n",
      "645    @almarai ألف ألف مبروك تأهل منتخبنا الوطني إلى...           0.0000  \n",
      "12477  نصيحة بودي_ماسترز \\n\\n4 tips to increase your ...           0.3802  \n",
      "17088  صحيفة قرمز بحلّتها الجديدة تصدر غدًا!\\n\\nاشترك...           0.0000  \n",
      "7931                      @arabian_oud العربيةللعودتهديك           0.0000  \n",
      "1259   we are hiring do you find the concept of selli...           0.0000  \n",
      "264    almarai company saudi arabia latest job openin...          -0.0772  \n",
      "3611                 عروض العثيم 22122015 المتمم 1131437           0.0000  \n",
      "6181                   أكاديمية قودي لتعليم الطهي  تعليم           0.0000  \n",
      "2604   nadec plans 5 cash dividend for fy2015   agric...           0.0000  \n",
      "\n",
      "Calculating average sentiment per brand...\n",
      "   Created 'df_avg_sentiment' DataFrame.\n",
      "   Average Sentiment per Brand (Top 5 Positive):\n",
      "                                           brand_name  avg_tweet_sentiment\n",
      "2                                              Abadia                0.392\n",
      "19                                        Charmaleena                0.373\n",
      "49                                               Tamr                0.372\n",
      "1                                                APOA                0.360\n",
      "0   \\n    # Copied from the log where errors start...                0.299\n",
      "   Average Sentiment per Brand (Top 5 Negative/Neutral):\n",
      "                brand_name  avg_tweet_sentiment\n",
      "22                Fanatics               -0.001\n",
      "3   Abdul Samad Al Qurashi                0.000\n",
      "18              Camel Step                0.000\n",
      "6             Al Romansiah                0.000\n",
      "30           KSA One Piece                0.000\n",
      "\n",
      "Merging average sentiment into combined metrics...\n",
      "   Updated 'df_combined_metrics' DataFrame:\n",
      "                                          brand_name  tweet_volume  \\\n",
      "0  \\n    # Copied from the log where errors start...           144   \n",
      "1                                               1886             0   \n",
      "2                                               APOA             5   \n",
      "3                                             Abadia            38   \n",
      "4                             Abdul Samad Al Qurashi            44   \n",
      "\n",
      "   market_saturation  avg_perceived_quality  avg_num_reviews  \\\n",
      "0                  0                   0.00             0.00   \n",
      "1                 25                   3.58           254.12   \n",
      "2                  2                   0.00             0.00   \n",
      "3                 25                   2.10             4.56   \n",
      "4                 25                   1.57             4.72   \n",
      "\n",
      "   avg_tweet_sentiment  \n",
      "0                0.299  \n",
      "1                0.000  \n",
      "2                0.360  \n",
      "3                0.392  \n",
      "4                0.000  \n",
      "\n",
      "   Checking data types of combined metrics:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59 entries, 0 to 58\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   brand_name             59 non-null     object \n",
      " 1   tweet_volume           59 non-null     int64  \n",
      " 2   market_saturation      59 non-null     int64  \n",
      " 3   avg_perceived_quality  59 non-null     float64\n",
      " 4   avg_num_reviews        59 non-null     float64\n",
      " 5   avg_tweet_sentiment    59 non-null     float64\n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 2.9+ KB\n",
      "\n",
      "--- Sentiment Analysis Complete ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Phase 3a - Tweet Sentiment Analysis\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd # Ensure pandas is imported\n",
    "\n",
    "print(\"--- Phase 3a: Tweet Sentiment Analysis ---\")\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get VADER sentiment score (compound score)\n",
    "def get_vader_sentiment(text):\n",
    "    if isinstance(text, str) and text.strip(): # Check if text is a non-empty string\n",
    "        # Compound score: normalized, weighted composite score, -1 (most neg) to +1 (most pos)\n",
    "        return analyzer.polarity_scores(text)['compound']\n",
    "    return 0.0 # Return neutral score for empty strings or non-string data\n",
    "\n",
    "# Check if df_tweets exists and has the cleaned content column\n",
    "if 'df_tweets' in locals() and not df_tweets.empty and 'cleaned_content' in df_tweets.columns:\n",
    "    print(\"\\nCalculating sentiment scores for tweets using 'cleaned_content'...\")\n",
    "    \n",
    "    # Apply the function to the 'cleaned_content' column\n",
    "    df_tweets['sentiment_score'] = df_tweets['cleaned_content'].apply(get_vader_sentiment)\n",
    "    \n",
    "    print(\"   Added 'sentiment_score' column.\")\n",
    "    # Display sample results including the new score\n",
    "    print(\"   Sample tweets with sentiment scores:\")\n",
    "    print(df_tweets[['brand_name', 'cleaned_content', 'sentiment_score']].sample(10)) # Show a random sample\n",
    "\n",
    "    # --- Calculate Average Sentiment per Brand ---\n",
    "    print(\"\\nCalculating average sentiment per brand...\")\n",
    "    # Group by brand_name and calculate the mean of the sentiment scores\n",
    "    df_avg_sentiment = df_tweets.groupby('brand_name')['sentiment_score'].mean().reset_index()\n",
    "    df_avg_sentiment.rename(columns={'sentiment_score': 'avg_tweet_sentiment'}, inplace=True)\n",
    "    df_avg_sentiment['avg_tweet_sentiment'] = df_avg_sentiment['avg_tweet_sentiment'].round(3) # Round for readability\n",
    "    \n",
    "    print(\"   Created 'df_avg_sentiment' DataFrame.\")\n",
    "    print(\"   Average Sentiment per Brand (Top 5 Positive):\")\n",
    "    print(df_avg_sentiment.sort_values(by='avg_tweet_sentiment', ascending=False).head())\n",
    "    print(\"   Average Sentiment per Brand (Top 5 Negative/Neutral):\")\n",
    "    print(df_avg_sentiment.sort_values(by='avg_tweet_sentiment', ascending=True).head())\n",
    "\n",
    "\n",
    "    # --- Merge Average Sentiment into Combined Metrics ---\n",
    "    print(\"\\nMerging average sentiment into combined metrics...\")\n",
    "    # Ensure df_combined_metrics exists from the previous cell\n",
    "    if 'df_combined_metrics' in locals() and not df_combined_metrics.empty:\n",
    "        # Merge, ensuring brand_name column exists in both\n",
    "        if 'brand_name' in df_combined_metrics.columns and 'brand_name' in df_avg_sentiment.columns:\n",
    "            df_combined_metrics = pd.merge(df_combined_metrics, df_avg_sentiment, on='brand_name', how='left')\n",
    "            # Fill potential NaN if a brand had no tweets to analyze (shouldn't happen if df_tweets was used to create df_combined_metrics initially)\n",
    "            df_combined_metrics['avg_tweet_sentiment'] = df_combined_metrics['avg_tweet_sentiment'].fillna(0.0) \n",
    "            \n",
    "            print(\"   Updated 'df_combined_metrics' DataFrame:\")\n",
    "            # Display the updated combined metrics\n",
    "            print(df_combined_metrics.head())\n",
    "            print(\"\\n   Checking data types of combined metrics:\")\n",
    "            df_combined_metrics.info()\n",
    "        else:\n",
    "            print(\"   ERROR: 'brand_name' column missing in one of the DataFrames. Cannot merge sentiment.\")\n",
    "            \n",
    "    else:\n",
    "        print(\"   ERROR: 'df_combined_metrics' not found from previous step. Cannot merge sentiment.\")\n",
    "        \n",
    "else:\n",
    "    print(\"   WARNING: df_tweets is empty or missing 'cleaned_content'. Cannot perform sentiment analysis.\")\n",
    "\n",
    "print(\"\\n--- Sentiment Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3414909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to download NLTK stopwords...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Nayef\n",
      "[nltk_data]     Alam\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK stopwords downloaded successfully or already present.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 (Run Once): Download NLTK stopwords (Simplified)\n",
    "import nltk\n",
    "import ssl # Import ssl to handle potential certificate issues\n",
    "\n",
    "try:\n",
    "    # Disable SSL certificate verification (sometimes needed for nltk.download)\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass # Means it might not be needed or already handled\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "print(\"Attempting to download NLTK stopwords...\")\n",
    "try:\n",
    "    nltk.download('stopwords')\n",
    "    print(\"NLTK stopwords downloaded successfully or already present.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not download NLTK stopwords. Error: {e}\")\n",
    "    print(\"Please check your internet connection and try running this cell again.\")\n",
    "    # You might need to configure nltk data path manually if issues persist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19396438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 3b: Topic Modeling (LDA) ---\n",
      "\n",
      "Processing topics for each brand...\n",
      "\n",
      "--- Topics for: \n",
      "    # Copied from the log where errors started\n",
      "    \"Al-Nassr\": \"Al Nassr OR النصر\",\n",
      "    \"Al-Ittihad\": \"Al Ittihad OR الاتحاد\",\n",
      "    \"Al-Ahli\": \"Al Ahli OR الاهلي\",\n",
      "    \"Fanatics\": \"Fanatics saudi\",\n",
      "    \"KSA Anime\": \"anime saudi OR انمي السعودية\",\n",
      "    \"KSA One Piece\": \"one piece saudi OR ون بيس السعودية\",\n",
      "    \"Fitness Time\": \"Fitness Time saudi OR وقت اللياقة\",\n",
      "    \"Body Masters\": \"Body Masters saudi OR بودي ماسترز\",\n",
      "    \"PureGym KSA\": \"PureGym saudi OR بيورجيم\",\n",
      "    \"Jarir Bookstore\": \"Jarir Bookstore saudi OR جرير\",\n",
      "    \"SACO\": \"SACO saudi OR ساكو\",\n",
      "    \"eXtra\": \"eXtra saudi OR اكسترا\",\n",
      "    \"Mall of Arabia\": \"Mall of Arabia saudi OR مول العرب\",\n",
      "    \"Riyadh Park Mall\": \"Riyadh Park saudi OR رياض بارك\",\n",
      "    \"Red Sea Mall\": \"Red Sea Mall saudi OR رد سي مول\",\n",
      "    \"Al Nakheel Mall\": \"Al Nakheel Mall saudi OR النخيل مول\",\n",
      "    \"Kingdom Centre\": \"Kingdom Centre saudi OR برج المملكة\",\n",
      "    \"Al Romansiah\": \"Al Romansiah saudi OR مطعم الرومانسية\",\n",
      "    \"Mama Noura\": \"Mama Noura saudi OR ماما نورة\"\n",
      "    Sleysla ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: jeddah, arabia, saudi, بحمد, سليسلة, riyadh, saudiarabia\n",
      "Topic 2: بالتعاون, sleysla, saudi_brand, beautiful, saudi, women, sleysla_bag\n",
      "Topic 3: لك, sleysla, بالتعاون, مؤسسة, خير, جهودهم, دورة\n",
      "Topic 4: saudi_aramco, التسجيل, أرامكو, لك, سليسلة, sleysla, embroidered\n",
      "Topic 5: saudi_aramco, سليسسلة, السعودية, sleysla, saud, مؤسسة, أرامكو\n",
      "\n",
      "--- Topics for: APOA ---\n",
      "Topic 1: brand, nomination, saudi, fashion, anticipated, leem\n",
      "Topic 2: brand, saudi, fashion, anticipated, nomination, leem\n",
      "Topic 3: leem, anticipated, brand, saudi, fashion, nomination\n",
      "Topic 4: fashion, saudi, anticipated, brand, leem, nomination\n",
      "Topic 5: anticipated, saudi, brand, fashion, leem, nomination\n",
      "\n",
      "--- Topics for: Abadia ---\n",
      "Topic 1: meet, dresses, rania, queen, ethical, brand, saudi\n",
      "Topic 2: saudi, fashion, label, scene, heritage, spotlight, first\n",
      "Topic 3: fashion, international, saudi, brands, retail, saudiarabia, infoblaze\n",
      "Topic 4: queen, worn, look, likes, saudiarabia, aram, arabian\n",
      "Topic 5: designer, global, world, netaporter, talent, founder, shahdalshehail\n",
      "\n",
      "--- Topics for: Abdul Samad Al Qurashi ---\n",
      "Topic 1: samad, al, qurashi, abdul, عبدالصمد_القرشي, عرض, القرشي\n",
      "Topic 2: المنتجات, الرابط, خصم, موقع, عروض, جميع, القرشي\n",
      "Topic 3: القرشي, عبدالصمد, وفي, عطور, الأسعار, لحملة, فأعلى\n",
      "Topic 4: وظائف, بالكويت, شركة, اضغط, القرشي, تفاصيل, فأعلى\n",
      "Topic 5: وظائف, بالكويت, شركة, أكثر, السابق, تفاصيل, القرشي\n",
      "\n",
      "--- Topics for: Al Nakheel Mall ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: وش, مجمع, nakheel_riyadh, السوق, الظهران, حياكم, skinfood\n",
      "Topic 2: al, nakheel, mall, النخيل_مول, بعد, لعيون, الرياض\n",
      "Topic 3: شكل, غير, زحمه, اروح, nakheel, al, بالرياض\n",
      "Topic 4: ليه, مدري, مافي, عامل, والله, فيرجن, لك\n",
      "Topic 5: mall, al, nakheel, انتظار, riyadh, السعودية, لله\n",
      "\n",
      "--- Topics for: Al Rabie ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: al, rabie, arabia, saudi, الربيع, بوفيه, juice\n",
      "Topic 2: حي, district, الربيع, al, rabie, saudi, foods\n",
      "Topic 3: موقع, hosts, شريك, csr, program, ksa, banquets\n",
      "Topic 4: شركة, التفاصيل, الاتحاد, دوري_عبداللطيف_جميل, وديا, الربيع, region\n",
      "Topic 5: الربيع, السعودية, صحة_للجميع, تطبيق, التطبيق, آندرويد, آيفون\n",
      "\n",
      "--- Topics for: Al Romansiah ---\n",
      "Topic 1: romansiah, al, الرومانسية, jeeran, riyadh, ksa, برايكم\n",
      "Topic 2: الرومانسية, al, romansiah, jeeran, برايكم, riyadh, ksa\n",
      "Topic 3: برايكم, jeeran, romansiah, riyadh, al, ksa, الرومانسية\n",
      "Topic 4: riyadh, ksa, romansiah, الرومانسية, برايكم, al, jeeran\n",
      "Topic 5: jeeran, برايكم, ksa, riyadh, الرومانسية, al, romansiah\n",
      "\n",
      "--- Topics for: Al-Ahli ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: الاهلي, الأهلي, الهلال, مباراة, دوري, الغرافة, آسيا\n",
      "Topic 2: al, ahli, hospital, alahli, ahlicentral, gharafa, aclelite\n",
      "Topic 3: الاهلي, الأهلي, شباب, النجمه_الاهلي, الإمارات_اليوم, بعد, ابو\n",
      "Topic 4: al, ahli, alahli, vs, ahlicentral, win, saudi\n",
      "Topic 5: al, ahli, sc, league, hilal, rwanda, clubs\n",
      "\n",
      "--- Topics for: Al-Hilal ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: al, hilal, الهلال, saudi, club, league, pro\n",
      "Topic 2: al, saudi, vs, hilal, player, ittihad, league\n",
      "Topic 3: الهلال, تذاكر, غرينتاهب, الملك, طرح, رابط, للاتحاد\n",
      "Topic 4: الاتحاد, الهلال, الاتحاد_الهلال, تذكرة, مباراة, مربع, الهلال_الاتحاد\n",
      "Topic 5: al, saudi, hilal, league, mls, team, teams\n",
      "\n",
      "--- Topics for: Al-Ittihad ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: الاتحاد_الهلال, كاريزما85, الاتحاد, لك, طلاب, الهلال, مباراة\n",
      "Topic 2: al, ittihad, hilal, vs, win, united, cup\n",
      "Topic 3: al, ittihad, league, champions, moussadiaby_19, hilal, afc\n",
      "Topic 4: الاتحاد, الدوري, اذا, المفروض, هلال, read, ضد\n",
      "Topic 5: الاتحاد, الاتحاد_الهلال, الهلال, الهلال_الاتحاد, جمهور, الف, صوت\n",
      "\n",
      "--- Topics for: Al-Nassr ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: thenassrzone, al, nassr, fc, win, get, kits\n",
      "Topic 2: al, nassr, ronaldo, felix, win, joao, hazem\n",
      "Topic 3: al_casber, النصر, al_nassr_live, day, وش, dey, هههههههههههه\n",
      "Topic 4: al, nassr, goals, cristiano, ronaldo, league, saudi\n",
      "Topic 5: النصر, النصر_الحزم, يلعب, الاتحاد, ماني, مباراة, نادي\n",
      "\n",
      "--- Topics for: Al-Othaim Markets ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: المتمم, اخر, عروض, العثيم, ركن, 26112015, 1421437\n",
      "Topic 2: المتمم, اكتساب, العثيم, اخر, عروض, تطبيق, تواصلك\n",
      "Topic 3: اخر, المتمم, عروض, العثيم, تخفيضات, توفير, العروض\n",
      "Topic 4: othaim, markets, عروض, أسواق, offers, العثيم, السعودية\n",
      "Topic 5: شركة, وظائف, الرياض, وظيفة, توفر, أسواق, othaimmarkets\n",
      "\n",
      "--- Topics for: Almarai ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: saudi, arizona, water, arabia, leases, fondomonte, dairy\n",
      "Topic 2: الكبسة, وطن_له_طعم, المراعي, طبق, saudi, dairy, 18\n",
      "Topic 3: arabia, saudi, job, openings, apply, jobs, announced\n",
      "Topic 4: المراعي, وطن_له_طعم, almarai_care, saudi_fda, mcgovsa, thailand, mcgovsa_care\n",
      "Topic 5: المراعي, وظائف, إلى, شركة, شكرا, عبر, الرابط\n",
      "\n",
      "--- Topics for: Almunajem Foods ---\n",
      "Topic 1: riyadh, food, arabia, foods, saudi, revenue, public\n",
      "Topic 2: completion, almunajemfoods, public, initial, foods, offering, shares\n",
      "Topic 3: main, market, listing, company, hsbc, shares, arabia\n",
      "Topic 4: 25, soar, q1, revenue, jump, threefold, saudi\n",
      "Topic 5: saudi, listing, announces, exchange, foods, largest, arabias\n",
      "\n",
      "--- Topics for: Arabian Oud ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: للعود, العربية, عليكم, arabian_oud, السلام, سناب, عروض\n",
      "Topic 2: العربية_للعود, ماوس, الصغيرات, ديزني, عطرميني, تبتكر, بالمشاركة\n",
      "Topic 3: arabian, oud, العربية, العربية_للعود, عطر, للعود, عطور\n",
      "Topic 4: arabian_oud, للعود, العربيه, العربية, العربية_للعود_تهديك, العربية_للعود, عطر\n",
      "Topic 5: العربية_للعود, يوم, العربية, تستاهلين, روز, arabian_oud, السنوي\n",
      "\n",
      "--- Topics for: Bayara ---\n",
      "Topic 1: بايارا, 260, food, شركة, acquisition, manufacturer, subsidiary\n",
      "Topic 2: million, 260, group, holding, agreement, arabias, limited\n",
      "Topic 3: بائع, uaebased, مستودع, نجران, أمين, us260m, snack\n",
      "Topic 4: egypt, مصر, وظائف, بايارا, شركة, consumer, maker\n",
      "Topic 5: food, uae, saudi, savola_group, acquires, 260m, uaes\n",
      "\n",
      "--- Topics for: BinDawood ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: تفوت, لتحميل, صديقك, رائعة, رمز, إليك, تطبيق\n",
      "Topic 2: عروض, الموافق, الأسبوعية, داود, 1446, 2025, مكة\n",
      "Topic 3: رابط, العرض, عروض, صفحة, داود, جدة, واحدة\n",
      "Topic 4: bin, dawood, الفترة, وحتي, weekly, deals, الرابط\n",
      "Topic 5: العروض, اخترنا, لكم, bindawoodco, تسري, 2023, الكمية\n",
      "\n",
      "--- Topics for: Body Masters ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: masters, body, ماسترز, بودي, بعد, photo, اجل\n",
      "Topic 2: بودي_ماسترز, body_masters, ksa, take, بطاقات, weight, بكل\n",
      "Topic 3: حان, وقت, السليم, أول, السباحة, بودي, masters\n",
      "Topic 4: بودي_ماسترز, بداية, بالنادي, body_masters, نادي, water, healthy\n",
      "Topic 5: خلال, أو, بودي, ماسترز, شهر, أندية, يمكنك\n",
      "\n",
      "--- Topics for: Camel Step ---\n",
      "Topic 1: step, camel, coffee, roasters, خطوة_جمل, الفرع, خطوة\n",
      "Topic 2: جمل, فرع, camel_step, خطوة, الفرع, camel, step\n",
      "Topic 3: جمل, خطوة, الفرع, فرع, coffee, خطوة_جمل, camel_step\n",
      "Topic 4: خطوة, خطوة_جمل, camel_step, coffee, جمل, camel, فرع\n",
      "Topic 5: قهوة, خطوة_جمل, camel_step, فرع, coffee, الفرع, camel\n",
      "\n",
      "--- Topics for: Charmaleena ---\n",
      "Topic 1: interview, designer, fine, saudi, love, شارمالينا, jeddah\n",
      "Topic 2: شارمالينا, thank, designer, mycharmaleena, charmaleenajewellery, love, saudi\n",
      "Topic 3: saudi, collection, beauty, lt3, launch, riyadh, april\n",
      "Topic 4: jeddah, ksa, look, fresh, summer, saudi, charmaleenajewellery\n",
      "Topic 5: riyadh, jeddah, lt3, saudi, ksa, fine, love\n",
      "\n",
      "--- Topics for: DHAD ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: ضاد, برنامج, الصوم, عليك, إذا, للكتب, الصوتية\n",
      "Topic 2: منصة, ضاد, dhad_sa, saudi_airlines, mdalomar, tmt1989, الناس\n",
      "Topic 3: dhad_sa, فوازير_ضاد, كتاب, جاوبوها_صح, ضاد, لأنك, تطبيق\n",
      "Topic 4: ضاد, شكرا, dhad_sa, بدأت, العربية, اللغة, قصة_ريادة\n",
      "Topic 5: saudi, arabia, ثم, ضاد, الضاد, مسابقة_لبيه_الرمضانية, العربية\n",
      "\n",
      "--- Topics for: Dania Shinkar ---\n",
      "   Skipping Dania Shinkar: Not enough tweets (found 2) for LDA.\n",
      "\n",
      "--- Topics for: Fanatics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: saudi, arabia, wwe, religion, us, want, people\n",
      "Topic 2: money, wwe, saudi, applepodcasts, youtube, ring, corrupt\n",
      "Topic 3: adamschefter, especially, share, arabia, millions, saudi, would\n",
      "Topic 4: saudi, religious, arabia, iran, israel, dont, islam\n",
      "Topic 5: football, flag, classic, riyadh, march, 21, brady\n",
      "\n",
      "--- Topics for: Fitness Time ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: عرعر, مفروشه, عرعر_مول, شقق, مميزه, ايجار, بالكامل\n",
      "Topic 2: time, fitness, وقت, اللياقة, fitnesstimesa, riyadh, pro\n",
      "Topic 3: وقـت, اللـياقة, بطاقة, time, fitness, تقدم, الأول\n",
      "Topic 4: وقت_اللياقة, time, fitness, fitness_time, اللياقة, وقت, وقت_اللياقه\n",
      "Topic 5: fitness_time, وقت_اللياقة, اللياقه, حي, العمل, وقت, فيتس_هوم\n",
      "\n",
      "--- Topics for: Goody ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: saudi, arabia, oh, food, like, saudis, uae\n",
      "Topic 2: منتجات, products, consumer, البحرين, bahrain, retweet, قودي\n",
      "Topic 3: تطبيق, مطبخ, goodykitchen, قودي, حملي, لمشاهدة, المجلة\n",
      "Topic 4: قودي, ورق, شركةة, فضيحة, لمحبي, العنب, شركة\n",
      "Topic 5: saudi, oh, arabia, get, women, bag, prince\n",
      "\n",
      "--- Topics for: Hasawi ---\n",
      "Topic 1: شاهد, هههههه, correspondent, look, حساوي, saudis, معنا\n",
      "Topic 2: حساوي, aal_hasawi, بالاضافة, مندي, خضرا, اطباق, ت0135961888\n",
      "Topic 3: حساوي, لعبة, بلهجة, شلون, حساوي_ديل, عالمية, حساوية\n",
      "Topic 4: فولو, حساوي, saudi, rice, متوفره, الآن, حساوي_ديل\n",
      "Topic 5: الأحساء, saudi, بودكاست_حساوي, alahsa, السعودية, arabia, exhibition\n",
      "\n",
      "--- Topics for: Herfy ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: arabia, saudi, riyadh, im, kingdom, food, services\n",
      "Topic 2: saudi, chain, fastfood, nigeria, tadawul, restaurants, expands\n",
      "Topic 3: burger, turkish, herfys, saudi, make, ceo, women\n",
      "Topic 4: هرفي, herfyfsc, كاس_العالم_2034, worldcup2034, يوم, هرفيxسوبرمان, ليس\n",
      "Topic 5: يورو2024, euro2024, herfyfsc, اسبانيا, هرفي, منتخب, لامين\n",
      "\n",
      "--- Topics for: Hindamme ---\n",
      "Topic 1: jeddah, check, talents, commemorates, pay, designer, saudi\n",
      "Topic 2: newest, driving, lift, hindammes, voguearabia, design, ode\n",
      "Topic 3: saudi, brand, collection, fashion, new, launches, luxury\n",
      "Topic 4: wrth_ksa, miskartinst, aramfashion, saudinationalday95, traditional, heritage, crafts\n",
      "Topic 5: museum, jacket, display, driving, londons, iv, victoria\n",
      "\n",
      "--- Topics for: Jarir Bookstore ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: jarir, bookstore, saudi, arabia, available, books, retail\n",
      "Topic 2: jarir, bookstore, saudi, arabia, جرير, offers, مكتبة\n",
      "Topic 3: مكتبة_جرير, jarir_bookstore, video, وظائف, نجوم, كافة, youtube\n",
      "Topic 4: خصم, founder, جرير, مكتبة, computer, supplies, الدفع\n",
      "Topic 5: عرض, المتمم, جرير, مكتبة, 1443, الثلاثاء, 2021\n",
      "\n",
      "--- Topics for: KSA Anime ---\n",
      "Topic 1: الحلقة, ささ恋, اوتاكو, أنمي, مترجمة, للعربية, انمي\n",
      "Topic 2: انمي, onepiece, anime, figures, عبر, كونان, سبيستون\n",
      "Topic 3: manga, yugioh, coffee, كافيهات_جدة, anime, ksa, cardgames\n",
      "Topic 4: saudi, anime, انمي, انميات, art, متجر, الانمي\n",
      "Topic 5: otaku, الدمام, الخبر, animation, الدمام_الخبر, thesoog, new\n",
      "\n",
      "--- Topics for: KSA One Piece ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: مانجا, مصر, الامارات, قطر, الجزائر, البحرين, الكويت\n",
      "Topic 2: khaledalhrbi, السعودية, مترجمة, انمي, تحميل, 607, one\n",
      "Topic 3: one_piece_mix, الآن, ترند, ون, ون_بيس, السعودية, الأنمي\n",
      "Topic 4: بيس, انمي, السعودية, one, piece, ون, مانجا\n",
      "Topic 5: luffy, ون_بيس, one_piece, فلم, crowdstrike, كاريزما13, iconic\n",
      "\n",
      "--- Topics for: Kudu ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: وظائف, المملكة, كودو, مناطق, المنطقة, تعلن, للتقديم\n",
      "Topic 2: كودو, هلا_باللذيذ, وجبة, 920006999, kuduksa, اليومية, التوصيل\n",
      "Topic 3: investment, completes, breakfast, saudis, says, كودو, tpg\n",
      "Topic 4: saudi, food, arabia, كودو, fast, riyadh, make\n",
      "Topic 5: chain, saudi, fastfood, abraaj, sources, tpg, update\n",
      "\n",
      "--- Topics for: Lazurde ---\n",
      "Topic 1: saudi, arabia, apply, deal, manager, signs, rival\n",
      "Topic 2: لزوردي, elissakh, اليسا, lazurde_injoy, للمنزل, فرع, الشحنه\n",
      "Topic 3: lazurde_injoy, khaleedalshada1, montadatakmem, rashaghcom, السعودية, mozahem_takmim, nawaf_anazi\n",
      "Topic 4: lolo222811, mousa66908, pizzahut_saudi, norahwawa54321, naanoo686, lazurde_injoy, hail86sultan010\n",
      "Topic 5: saudi, jewelry, gold, company, new, ksa, riyadh\n",
      "\n",
      "--- Topics for: Mall of Arabia ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: مجمع, بالخير, العرب, مول, العرب_مول, arabia, مجمع_العرب\n",
      "Topic 2: علي, بالبوم, الرياض, شارك, مايو, متجر, سامسونج\n",
      "Topic 3: لك, arab, el, بمدينة, جوز, يبقى, mall\n",
      "Topic 4: mall, مول, العرب, arabia, دي, cairo, اسمه\n",
      "Topic 5: mall_of_arabia, مول_العرب, إلى, فرع, ويلز, القاهرة, فروع\n",
      "\n",
      "--- Topics for: Mama Noura ---\n",
      "   Skipping Mama Noura: Not enough tweets (found 2) for LDA.\n",
      "\n",
      "--- Topics for: Mikyajy ---\n",
      "Topic 1: مكياجي, منتجات, احصلي, هل, makeup, مناسبة, looks\n",
      "Topic 2: رمضان_كريم, ramadankareem, gift, رمضان, day, مكياجي, recently\n",
      "Topic 3: saudi, buy, 99, get, jeddah, fragrance, set\n",
      "Topic 4: saudi, riyadh, arabia, brand, get, sea, red\n",
      "Topic 5: مكياجي, هدايا, السعودي, حياة_مول, مجموعة, الحب, شهر\n",
      "\n",
      "--- Topics for: NADEC ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: dairy, via, unit, buy, firm, danone, saudi\n",
      "Topic 2: التسجيل, فى, solar, tasi, 3000, مواصلات, saudi\n",
      "Topic 3: company, national, development, agricultural, saudi, arabia, training\n",
      "Topic 4: نادك, شركة, تدريب, تعلن, بالتوظيف, مدير, وظائف\n",
      "Topic 5: nadecfoods, jobs, saudi, job, careers, apply, freshgulfjob\n",
      "\n",
      "--- Topics for: Nada Dairy ---\n",
      "Topic 1: كافد, professional, requiref, east, dairyfmcgfood, middle, لاين\n",
      "Topic 2: jobs, years, arabia, service, saudi, gulf, client\n",
      "Topic 3: gtsalesman1750com, 716104808, asst, 9am, othman, handle, onward\n",
      "Topic 4: ندى, nadadairy, dairy, saudi, arabia, بكل, ومذاق\n",
      "Topic 5: ندى, food, nada_dairy, dairy, nadadairy, accommodation, jobs\n",
      "\n",
      "--- Topics for: Nahdi ---\n",
      "Topic 1: فرع, السعودية, صيدليه, النهدى, pharmacy, النهدي, حي\n",
      "Topic 2: nahdihope, pharmacy, صيدلية, جدة, النهدي, السعودية, صيدلية_النهدي\n",
      "Topic 3: صيدلية, النهدي, al, pharmacy, وظائف, الرابط, علي\n",
      "Topic 4: عروض, الأسبوعية, الموافق, صيدلية, 2024, النهدي, حي\n",
      "Topic 5: الرياض, التحلية, فوق, صيدلية, بسعر, النهدي, حي\n",
      "\n",
      "--- Topics for: Panda ---\n",
      "   Skipping Panda: Not enough tweets (found 3) for LDA.\n",
      "\n",
      "--- Topics for: PureGym KSA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: puregym, arabia, saudi, darrengrimes_, got, الخاص, puregymarabia\n",
      "Topic 2: pure, opens, site, puregym, saudi, ambitions, new\n",
      "Topic 3: boycott, فروع, puregym, saudi, procurement, permission, 13\n",
      "Topic 4: deal, puregym, market, ektimal, franchise, enter, cobboldhumphrey\n",
      "Topic 5: إلى, puregym, بيورجيم, imminent, sites, three, launch\n",
      "\n",
      "--- Topics for: Qormuz ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: قرمز, رابط, شعار, متجر, الازدهار, أن, المحل\n",
      "Topic 2: smalied, قرمز, السعودية, عبدالرحمن, العابد, saudi, abdulrhmn_abed\n",
      "Topic 3: قرمز, ديوان_قرمز, رمز, أبواب, إلى, منها, لطيفة\n",
      "Topic 4: قرمز, رمز, اللطيف, الثميري, عند, الجميلة, يقدمون\n",
      "Topic 5: رمز, smalied, قرمز, بس, حبيب, المعزب26, القلب\n",
      "\n",
      "--- Topics for: Rani ---\n",
      "   Skipping Rani: Not enough tweets (found 1) for LDA.\n",
      "\n",
      "--- Topics for: Razan Alazzouni ---\n",
      "Topic 1: مجموعة, رزان, أكثر, مجلة, تصميم, العزوني, التجارية\n",
      "Topic 2: أسبوع_الأزياء_في_الرياض, riyadhfashionweek, المملكة, razanalazzouni, ملابس, مجموعة, رزان_العزوني\n",
      "Topic 3: التجارية, العلامة, مصممة, السعودية, razan, القطاع, بانكس\n",
      "Topic 4: العالمية, وصلت, سعوديه, رزان, razan, alazzouni, العزوني\n",
      "Topic 5: القائمة, الزفاف, والأزياء, صاحبات, أكثر, ومؤس, سة\n",
      "\n",
      "--- Topics for: Red Sea Mall ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: رد, redseamallksa, others, jeddah, makkah, جدة, حملة\n",
      "Topic 2: رد, صورة, redseamallksa, نشر, هنا, والله, دا\n",
      "Topic 3: رد, وهذا, قهوة, love, اللهم, الخير, الريد\n",
      "Topic 4: رد, ردسي, بس, أخبار, إعجابكم, بصفحتنا, الفيسبوك\n",
      "Topic 5: رد, بعد, الف, الشي, قهوتي, best, رقم\n",
      "\n",
      "--- Topics for: Riyadh Park Mall ---\n",
      "Topic 1: بارك, رياض, الرياض, مول, افضل, riyadh, park\n",
      "Topic 2: عيشها, ايماجينيشن_بارك, احجز, موسم_الرياض, منطقة, تذكرتك, الحين\n",
      "Topic 3: mall, park, riyadh, الساعة, مول, المسلسلات, الرياض\n",
      "Topic 4: معرض, السيارات, بأجواء, النادرة, مول, تجربة, concours\n",
      "Topic 5: الحين, للسيارات, احجز, متنوعة, تجارب, concours, النادرة\n",
      "\n",
      "--- Topics for: SACO ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: saudi, hardware, company, investor, relations, retailer, arabia\n",
      "Topic 2: نفس, المشكلة, منك, ساكو, هل, خصم, ولكن\n",
      "Topic 3: saco_ksa, ساكو, مبكرا, افحصي, واطمئني, سرطان, حياتك\n",
      "Topic 4: saudi, riyadh, ksa, please, saco_ksa, looking, world\n",
      "Topic 5: أو, ساكو, 2025, الخصم, سبتمبر, المبكر, الآن\n",
      "\n",
      "--- Topics for: Saudia Dairy (SADAFCO) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: sadafco, saudi, talent, com, job, jeddah, mail\n",
      "Topic 2: jump, higher, profits, stake, fonterra, saudibased, 48\n",
      "Topic 3: عام, سعودية, الألبان, شركة, mimgov, مساهمة, yorkksa\n",
      "Topic 4: برنامج, سدافكو, sadafco, 000, السعودية, sparkling, drink\n",
      "Topic 5: dairy, foodstuff, saudia, company, sadafco, saudi, jobs\n",
      "\n",
      "--- Topics for: Sunbulah Group ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: baytcom, ksa, opportunities, job, food, group, saudi\n",
      "Topic 2: sunbulah, group, saudi, jobs, manager, recruitment, specialist\n",
      "Topic 3: السنبلة, مجموعة, وظيفة, material, جدة, للعمل, وظائف_شاغرة\n",
      "Topic 4: السنبلة, مجموعة, administration, supply, product, human, accounting\n",
      "Topic 5: sunbulah_group, sunbulahgroup, السنبلة, مجموعة, saudi__platform, 0548876446, samer_kurdi\n",
      "\n",
      "--- Topics for: Tamr ---\n",
      "Topic 1: soft, ripe, rutab, dates, unripe, arabic, dried\n",
      "Topic 2: saudi, dates, arabia, like, made, mahshi, fresh\n",
      "Topic 3: region, تمر, arabic, food, dates, benefits, staple\n",
      "Topic 4: تمر, dates, ramadan, date, certain, health, benefits\n",
      "Topic 5: tourism, learn, dates, saudiarabia, saudi, date, arabic\n",
      "\n",
      "--- Topics for: The Dropped Collection ---\n",
      "Topic 1: collection, saudi, dropped, arabia, fashion, brand, cant\n",
      "Topic 2: time, watch, arg, 44, tuesday, fan, countrys\n",
      "Topic 3: nfts, argentina, hours, nft, win, 21, arabias\n",
      "Topic 4: days, new, collection, dropped, cant, nft, time\n",
      "Topic 5: brand, dropped, argentina, 21, tuesday, 387, 24\n",
      "\n",
      "--- Topics for: Torba Studio ---\n",
      "   Skipping Torba Studio: Not enough tweets (found 1) for LDA.\n",
      "\n",
      "--- Topics for: eXtra ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: saudi, arabia, money, like, would, oil, dont\n",
      "Topic 2: saudi_esports, al, cup, ufmradio, ewc_ar, ewc_extra_ar, _d7y0\n",
      "Topic 3: الجوية, الأنواء, الحرارة, الطقس, درجات_الحرارة, ssc, bags\n",
      "Topic 4: اكسترا, تسري, موقع, تطبيق, 2025, الرابط, عروض\n",
      "Topic 5: العراق, اكسترا_عراق, بنسبة, extra_iraq, اخبار, اخر_الاخبار, دينار\n",
      "\n",
      "\n",
      "--- Brand Topics Summary ---\n",
      "                                                                                              Topic 1  \\\n",
      "\\n    # Copied from the log where errors starte...  jeddah, arabia, saudi, بحمد, سليسلة, riyadh, s...   \n",
      "APOA                                                brand, nomination, saudi, fashion, anticipated...   \n",
      "Abadia                                              meet, dresses, rania, queen, ethical, brand, s...   \n",
      "Abdul Samad Al Qurashi                              samad, al, qurashi, abdul, عبدالصمد_القرشي, عر...   \n",
      "Al Nakheel Mall                                     وش, مجمع, nakheel_riyadh, السوق, الظهران, حياك...   \n",
      "Al Rabie                                               al, rabie, arabia, saudi, الربيع, بوفيه, juice   \n",
      "Al Romansiah                                        romansiah, al, الرومانسية, jeeran, riyadh, ksa...   \n",
      "Al-Ahli                                             الاهلي, الأهلي, الهلال, مباراة, دوري, الغرافة,...   \n",
      "Al-Hilal                                                  al, hilal, الهلال, saudi, club, league, pro   \n",
      "Al-Ittihad                                          الاتحاد_الهلال, كاريزما85, الاتحاد, لك, طلاب, ...   \n",
      "Al-Nassr                                                  thenassrzone, al, nassr, fc, win, get, kits   \n",
      "Al-Othaim Markets                                   المتمم, اخر, عروض, العثيم, ركن, 26112015, 1421437   \n",
      "Almarai                                             saudi, arizona, water, arabia, leases, fondomo...   \n",
      "Almunajem Foods                                     riyadh, food, arabia, foods, saudi, revenue, p...   \n",
      "Arabian Oud                                         للعود, العربية, عليكم, arabian_oud, السلام, سن...   \n",
      "Bayara                                              بايارا, 260, food, شركة, acquisition, manufact...   \n",
      "BinDawood                                                تفوت, لتحميل, صديقك, رائعة, رمز, إليك, تطبيق   \n",
      "Body Masters                                             masters, body, ماسترز, بودي, بعد, photo, اجل   \n",
      "Camel Step                                          step, camel, coffee, roasters, خطوة_جمل, الفرع...   \n",
      "Charmaleena                                         interview, designer, fine, saudi, love, شارمال...   \n",
      "DHAD                                                    ضاد, برنامج, الصوم, عليك, إذا, للكتب, الصوتية   \n",
      "Fanatics                                               saudi, arabia, wwe, religion, us, want, people   \n",
      "Fitness Time                                        عرعر, مفروشه, عرعر_مول, شقق, مميزه, ايجار, بال...   \n",
      "Goody                                                      saudi, arabia, oh, food, like, saudis, uae   \n",
      "Hasawi                                              شاهد, هههههه, correspondent, look, حساوي, saud...   \n",
      "Herfy                                               arabia, saudi, riyadh, im, kingdom, food, serv...   \n",
      "Hindamme                                            jeddah, check, talents, commemorates, pay, des...   \n",
      "Jarir Bookstore                                     jarir, bookstore, saudi, arabia, available, bo...   \n",
      "KSA Anime                                            الحلقة, ささ恋, اوتاكو, أنمي, مترجمة, للعربية, انمي   \n",
      "KSA One Piece                                       مانجا, مصر, الامارات, قطر, الجزائر, البحرين, ا...   \n",
      "Kudu                                                وظائف, المملكة, كودو, مناطق, المنطقة, تعلن, لل...   \n",
      "Lazurde                                             saudi, arabia, apply, deal, manager, signs, rival   \n",
      "Mall of Arabia                                      مجمع, بالخير, العرب, مول, العرب_مول, arabia, م...   \n",
      "Mikyajy                                              مكياجي, منتجات, احصلي, هل, makeup, مناسبة, looks   \n",
      "NADEC                                                      dairy, via, unit, buy, firm, danone, saudi   \n",
      "Nada Dairy                                          كافد, professional, requiref, east, dairyfmcgf...   \n",
      "Nahdi                                               فرع, السعودية, صيدليه, النهدى, pharmacy, النهد...   \n",
      "PureGym KSA                                         puregym, arabia, saudi, darrengrimes_, got, ال...   \n",
      "Qormuz                                                    قرمز, رابط, شعار, متجر, الازدهار, أن, المحل   \n",
      "Razan Alazzouni                                     مجموعة, رزان, أكثر, مجلة, تصميم, العزوني, التج...   \n",
      "Red Sea Mall                                        رد, redseamallksa, others, jeddah, makkah, جدة...   \n",
      "Riyadh Park Mall                                          بارك, رياض, الرياض, مول, افضل, riyadh, park   \n",
      "SACO                                                saudi, hardware, company, investor, relations,...   \n",
      "Saudia Dairy (SADAFCO)                                 sadafco, saudi, talent, com, job, jeddah, mail   \n",
      "Sunbulah Group                                      baytcom, ksa, opportunities, job, food, group,...   \n",
      "Tamr                                                  soft, ripe, rutab, dates, unripe, arabic, dried   \n",
      "The Dropped Collection                              collection, saudi, dropped, arabia, fashion, b...   \n",
      "eXtra                                                    saudi, arabia, money, like, would, oil, dont   \n",
      "Dania Shinkar                                                                                     NaN   \n",
      "Mama Noura                                                                                        NaN   \n",
      "Panda                                                                                             NaN   \n",
      "Rani                                                                                              NaN   \n",
      "Torba Studio                                                                                      NaN   \n",
      "\n",
      "                                                                                              Topic 2  \\\n",
      "\\n    # Copied from the log where errors starte...  بالتعاون, sleysla, saudi_brand, beautiful, sau...   \n",
      "APOA                                                brand, saudi, fashion, anticipated, nomination...   \n",
      "Abadia                                              saudi, fashion, label, scene, heritage, spotli...   \n",
      "Abdul Samad Al Qurashi                                المنتجات, الرابط, خصم, موقع, عروض, جميع, القرشي   \n",
      "Al Nakheel Mall                                     al, nakheel, mall, النخيل_مول, بعد, لعيون, الرياض   \n",
      "Al Rabie                                                حي, district, الربيع, al, rabie, saudi, foods   \n",
      "Al Romansiah                                        الرومانسية, al, romansiah, jeeran, برايكم, riy...   \n",
      "Al-Ahli                                             al, ahli, hospital, alahli, ahlicentral, ghara...   \n",
      "Al-Hilal                                                al, saudi, vs, hilal, player, ittihad, league   \n",
      "Al-Ittihad                                                   al, ittihad, hilal, vs, win, united, cup   \n",
      "Al-Nassr                                                  al, nassr, ronaldo, felix, win, joao, hazem   \n",
      "Al-Othaim Markets                                    المتمم, اكتساب, العثيم, اخر, عروض, تطبيق, تواصلك   \n",
      "Almarai                                             الكبسة, وطن_له_طعم, المراعي, طبق, saudi, dairy...   \n",
      "Almunajem Foods                                     completion, almunajemfoods, public, initial, f...   \n",
      "Arabian Oud                                         العربية_للعود, ماوس, الصغيرات, ديزني, عطرميني,...   \n",
      "Bayara                                              million, 260, group, holding, agreement, arabi...   \n",
      "BinDawood                                             عروض, الموافق, الأسبوعية, داود, 1446, 2025, مكة   \n",
      "Body Masters                                        بودي_ماسترز, body_masters, ksa, take, بطاقات, ...   \n",
      "Camel Step                                             جمل, فرع, camel_step, خطوة, الفرع, camel, step   \n",
      "Charmaleena                                         شارمالينا, thank, designer, mycharmaleena, cha...   \n",
      "DHAD                                                منصة, ضاد, dhad_sa, saudi_airlines, mdalomar, ...   \n",
      "Fanatics                                            money, wwe, saudi, applepodcasts, youtube, rin...   \n",
      "Fitness Time                                        time, fitness, وقت, اللياقة, fitnesstimesa, ri...   \n",
      "Goody                                               منتجات, products, consumer, البحرين, bahrain, ...   \n",
      "Hasawi                                              حساوي, aal_hasawi, بالاضافة, مندي, خضرا, اطباق...   \n",
      "Herfy                                               saudi, chain, fastfood, nigeria, tadawul, rest...   \n",
      "Hindamme                                            newest, driving, lift, hindammes, voguearabia,...   \n",
      "Jarir Bookstore                                     jarir, bookstore, saudi, arabia, جرير, offers,...   \n",
      "KSA Anime                                           انمي, onepiece, anime, figures, عبر, كونان, سب...   \n",
      "KSA One Piece                                       khaledalhrbi, السعودية, مترجمة, انمي, تحميل, 6...   \n",
      "Kudu                                                كودو, هلا_باللذيذ, وجبة, 920006999, kuduksa, ا...   \n",
      "Lazurde                                             لزوردي, elissakh, اليسا, lazurde_injoy, للمنزل...   \n",
      "Mall of Arabia                                         علي, بالبوم, الرياض, شارك, مايو, متجر, سامسونج   \n",
      "Mikyajy                                             رمضان_كريم, ramadankareem, gift, رمضان, day, م...   \n",
      "NADEC                                                  التسجيل, فى, solar, tasi, 3000, مواصلات, saudi   \n",
      "Nada Dairy                                          jobs, years, arabia, service, saudi, gulf, client   \n",
      "Nahdi                                               nahdihope, pharmacy, صيدلية, جدة, النهدي, السع...   \n",
      "PureGym KSA                                         pure, opens, site, puregym, saudi, ambitions, new   \n",
      "Qormuz                                              smalied, قرمز, السعودية, عبدالرحمن, العابد, sa...   \n",
      "Razan Alazzouni                                     أسبوع_الأزياء_في_الرياض, riyadhfashionweek, ال...   \n",
      "Red Sea Mall                                             رد, صورة, redseamallksa, نشر, هنا, والله, دا   \n",
      "Riyadh Park Mall                                    عيشها, ايماجينيشن_بارك, احجز, موسم_الرياض, منط...   \n",
      "SACO                                                           نفس, المشكلة, منك, ساكو, هل, خصم, ولكن   \n",
      "Saudia Dairy (SADAFCO)                              jump, higher, profits, stake, fonterra, saudib...   \n",
      "Sunbulah Group                                      sunbulah, group, saudi, jobs, manager, recruit...   \n",
      "Tamr                                                  saudi, dates, arabia, like, made, mahshi, fresh   \n",
      "The Dropped Collection                                   time, watch, arg, 44, tuesday, fan, countrys   \n",
      "eXtra                                               saudi_esports, al, cup, ufmradio, ewc_ar, ewc_...   \n",
      "Dania Shinkar                                                                                     NaN   \n",
      "Mama Noura                                                                                        NaN   \n",
      "Panda                                                                                             NaN   \n",
      "Rani                                                                                              NaN   \n",
      "Torba Studio                                                                                      NaN   \n",
      "\n",
      "                                                                                              Topic 3  \\\n",
      "\\n    # Copied from the log where errors starte...    لك, sleysla, بالتعاون, مؤسسة, خير, جهودهم, دورة   \n",
      "APOA                                                leem, anticipated, brand, saudi, fashion, nomi...   \n",
      "Abadia                                              fashion, international, saudi, brands, retail,...   \n",
      "Abdul Samad Al Qurashi                              القرشي, عبدالصمد, وفي, عطور, الأسعار, لحملة, ف...   \n",
      "Al Nakheel Mall                                            شكل, غير, زحمه, اروح, nakheel, al, بالرياض   \n",
      "Al Rabie                                               موقع, hosts, شريك, csr, program, ksa, banquets   \n",
      "Al Romansiah                                        برايكم, jeeran, romansiah, riyadh, al, ksa, ال...   \n",
      "Al-Ahli                                             الاهلي, الأهلي, شباب, النجمه_الاهلي, الإمارات_...   \n",
      "Al-Hilal                                            الهلال, تذاكر, غرينتاهب, الملك, طرح, رابط, للا...   \n",
      "Al-Ittihad                                          al, ittihad, league, champions, moussadiaby_19...   \n",
      "Al-Nassr                                            al_casber, النصر, al_nassr_live, day, وش, dey,...   \n",
      "Al-Othaim Markets                                   اخر, المتمم, عروض, العثيم, تخفيضات, توفير, العروض   \n",
      "Almarai                                             arabia, saudi, job, openings, apply, jobs, ann...   \n",
      "Almunajem Foods                                     main, market, listing, company, hsbc, shares, ...   \n",
      "Arabian Oud                                         arabian, oud, العربية, العربية_للعود, عطر, للع...   \n",
      "Bayara                                              بائع, uaebased, مستودع, نجران, أمين, us260m, s...   \n",
      "BinDawood                                                   رابط, العرض, عروض, صفحة, داود, جدة, واحدة   \n",
      "Body Masters                                            حان, وقت, السليم, أول, السباحة, بودي, masters   \n",
      "Camel Step                                          جمل, خطوة, الفرع, فرع, coffee, خطوة_جمل, camel...   \n",
      "Charmaleena                                         saudi, collection, beauty, lt3, launch, riyadh...   \n",
      "DHAD                                                dhad_sa, فوازير_ضاد, كتاب, جاوبوها_صح, ضاد, لأ...   \n",
      "Fanatics                                            adamschefter, especially, share, arabia, milli...   \n",
      "Fitness Time                                        وقـت, اللـياقة, بطاقة, time, fitness, تقدم, الأول   \n",
      "Goody                                               تطبيق, مطبخ, goodykitchen, قودي, حملي, لمشاهدة...   \n",
      "Hasawi                                              حساوي, لعبة, بلهجة, شلون, حساوي_ديل, عالمية, ح...   \n",
      "Herfy                                                burger, turkish, herfys, saudi, make, ceo, women   \n",
      "Hindamme                                            saudi, brand, collection, fashion, new, launch...   \n",
      "Jarir Bookstore                                     مكتبة_جرير, jarir_bookstore, video, وظائف, نجو...   \n",
      "KSA Anime                                           manga, yugioh, coffee, كافيهات_جدة, anime, ksa...   \n",
      "KSA One Piece                                       one_piece_mix, الآن, ترند, ون, ون_بيس, السعودي...   \n",
      "Kudu                                                investment, completes, breakfast, saudis, says...   \n",
      "Lazurde                                             lazurde_injoy, khaleedalshada1, montadatakmem,...   \n",
      "Mall of Arabia                                                  لك, arab, el, بمدينة, جوز, يبقى, mall   \n",
      "Mikyajy                                                   saudi, buy, 99, get, jeddah, fragrance, set   \n",
      "NADEC                                               company, national, development, agricultural, ...   \n",
      "Nada Dairy                                          gtsalesman1750com, 716104808, asst, 9am, othma...   \n",
      "Nahdi                                                صيدلية, النهدي, al, pharmacy, وظائف, الرابط, علي   \n",
      "PureGym KSA                                         boycott, فروع, puregym, saudi, procurement, pe...   \n",
      "Qormuz                                                 قرمز, ديوان_قرمز, رمز, أبواب, إلى, منها, لطيفة   \n",
      "Razan Alazzouni                                     التجارية, العلامة, مصممة, السعودية, razan, الق...   \n",
      "Red Sea Mall                                                رد, وهذا, قهوة, love, اللهم, الخير, الريد   \n",
      "Riyadh Park Mall                                    mall, park, riyadh, الساعة, مول, المسلسلات, ال...   \n",
      "SACO                                                saco_ksa, ساكو, مبكرا, افحصي, واطمئني, سرطان, ...   \n",
      "Saudia Dairy (SADAFCO)                              عام, سعودية, الألبان, شركة, mimgov, مساهمة, yo...   \n",
      "Sunbulah Group                                      السنبلة, مجموعة, وظيفة, material, جدة, للعمل, ...   \n",
      "Tamr                                                region, تمر, arabic, food, dates, benefits, st...   \n",
      "The Dropped Collection                                  nfts, argentina, hours, nft, win, 21, arabias   \n",
      "eXtra                                               الجوية, الأنواء, الحرارة, الطقس, درجات_الحرارة...   \n",
      "Dania Shinkar                                                                                     NaN   \n",
      "Mama Noura                                                                                        NaN   \n",
      "Panda                                                                                             NaN   \n",
      "Rani                                                                                              NaN   \n",
      "Torba Studio                                                                                      NaN   \n",
      "\n",
      "                                                                                              Topic 4  \\\n",
      "\\n    # Copied from the log where errors starte...  saudi_aramco, التسجيل, أرامكو, لك, سليسلة, sle...   \n",
      "APOA                                                fashion, saudi, anticipated, brand, leem, nomi...   \n",
      "Abadia                                              queen, worn, look, likes, saudiarabia, aram, a...   \n",
      "Abdul Samad Al Qurashi                              وظائف, بالكويت, شركة, اضغط, القرشي, تفاصيل, فأعلى   \n",
      "Al Nakheel Mall                                               ليه, مدري, مافي, عامل, والله, فيرجن, لك   \n",
      "Al Rabie                                            شركة, التفاصيل, الاتحاد, دوري_عبداللطيف_جميل, ...   \n",
      "Al Romansiah                                        riyadh, ksa, romansiah, الرومانسية, برايكم, al...   \n",
      "Al-Ahli                                                 al, ahli, alahli, vs, ahlicentral, win, saudi   \n",
      "Al-Hilal                                            الاتحاد, الهلال, الاتحاد_الهلال, تذكرة, مباراة...   \n",
      "Al-Ittihad                                              الاتحاد, الدوري, اذا, المفروض, هلال, read, ضد   \n",
      "Al-Nassr                                            al, nassr, goals, cristiano, ronaldo, league, ...   \n",
      "Al-Othaim Markets                                   othaim, markets, عروض, أسواق, offers, العثيم, ...   \n",
      "Almarai                                             المراعي, وطن_له_طعم, almarai_care, saudi_fda, ...   \n",
      "Almunajem Foods                                         25, soar, q1, revenue, jump, threefold, saudi   \n",
      "Arabian Oud                                         arabian_oud, للعود, العربيه, العربية, العربية_...   \n",
      "Bayara                                               egypt, مصر, وظائف, بايارا, شركة, consumer, maker   \n",
      "BinDawood                                            bin, dawood, الفترة, وحتي, weekly, deals, الرابط   \n",
      "Body Masters                                        بودي_ماسترز, بداية, بالنادي, body_masters, ناد...   \n",
      "Camel Step                                          خطوة, خطوة_جمل, camel_step, coffee, جمل, camel...   \n",
      "Charmaleena                                         jeddah, ksa, look, fresh, summer, saudi, charm...   \n",
      "DHAD                                                ضاد, شكرا, dhad_sa, بدأت, العربية, اللغة, قصة_...   \n",
      "Fanatics                                            saudi, religious, arabia, iran, israel, dont, ...   \n",
      "Fitness Time                                        وقت_اللياقة, time, fitness, fitness_time, اللي...   \n",
      "Goody                                                     قودي, ورق, شركةة, فضيحة, لمحبي, العنب, شركة   \n",
      "Hasawi                                              فولو, حساوي, saudi, rice, متوفره, الآن, حساوي_ديل   \n",
      "Herfy                                               هرفي, herfyfsc, كاس_العالم_2034, worldcup2034,...   \n",
      "Hindamme                                            wrth_ksa, miskartinst, aramfashion, saudinatio...   \n",
      "Jarir Bookstore                                     خصم, founder, جرير, مكتبة, computer, supplies,...   \n",
      "KSA Anime                                               saudi, anime, انمي, انميات, art, متجر, الانمي   \n",
      "KSA One Piece                                              بيس, انمي, السعودية, one, piece, ون, مانجا   \n",
      "Kudu                                                    saudi, food, arabia, كودو, fast, riyadh, make   \n",
      "Lazurde                                             lolo222811, mousa66908, pizzahut_saudi, norahw...   \n",
      "Mall of Arabia                                              mall, مول, العرب, arabia, دي, cairo, اسمه   \n",
      "Mikyajy                                                   saudi, riyadh, arabia, brand, get, sea, red   \n",
      "NADEC                                                  نادك, شركة, تدريب, تعلن, بالتوظيف, مدير, وظائف   \n",
      "Nada Dairy                                           ندى, nadadairy, dairy, saudi, arabia, بكل, ومذاق   \n",
      "Nahdi                                               عروض, الأسبوعية, الموافق, صيدلية, 2024, النهدي...   \n",
      "PureGym KSA                                         deal, puregym, market, ektimal, franchise, ent...   \n",
      "Qormuz                                               قرمز, رمز, اللطيف, الثميري, عند, الجميلة, يقدمون   \n",
      "Razan Alazzouni                                     العالمية, وصلت, سعوديه, رزان, razan, alazzouni...   \n",
      "Red Sea Mall                                          رد, ردسي, بس, أخبار, إعجابكم, بصفحتنا, الفيسبوك   \n",
      "Riyadh Park Mall                                    معرض, السيارات, بأجواء, النادرة, مول, تجربة, c...   \n",
      "SACO                                                saudi, riyadh, ksa, please, saco_ksa, looking,...   \n",
      "Saudia Dairy (SADAFCO)                              برنامج, سدافكو, sadafco, 000, السعودية, sparkl...   \n",
      "Sunbulah Group                                      السنبلة, مجموعة, administration, supply, produ...   \n",
      "Tamr                                                تمر, dates, ramadan, date, certain, health, be...   \n",
      "The Dropped Collection                                days, new, collection, dropped, cant, nft, time   \n",
      "eXtra                                                   اكسترا, تسري, موقع, تطبيق, 2025, الرابط, عروض   \n",
      "Dania Shinkar                                                                                     NaN   \n",
      "Mama Noura                                                                                        NaN   \n",
      "Panda                                                                                             NaN   \n",
      "Rani                                                                                              NaN   \n",
      "Torba Studio                                                                                      NaN   \n",
      "\n",
      "                                                                                              Topic 5  \\\n",
      "\\n    # Copied from the log where errors starte...  saudi_aramco, سليسسلة, السعودية, sleysla, saud...   \n",
      "APOA                                                anticipated, saudi, brand, fashion, leem, nomi...   \n",
      "Abadia                                              designer, global, world, netaporter, talent, f...   \n",
      "Abdul Samad Al Qurashi                              وظائف, بالكويت, شركة, أكثر, السابق, تفاصيل, ال...   \n",
      "Al Nakheel Mall                                      mall, al, nakheel, انتظار, riyadh, السعودية, لله   \n",
      "Al Rabie                                            الربيع, السعودية, صحة_للجميع, تطبيق, التطبيق, ...   \n",
      "Al Romansiah                                        jeeran, برايكم, ksa, riyadh, الرومانسية, al, r...   \n",
      "Al-Ahli                                                    al, ahli, sc, league, hilal, rwanda, clubs   \n",
      "Al-Hilal                                                   al, saudi, hilal, league, mls, team, teams   \n",
      "Al-Ittihad                                          الاتحاد, الاتحاد_الهلال, الهلال, الهلال_الاتحا...   \n",
      "Al-Nassr                                            النصر, النصر_الحزم, يلعب, الاتحاد, ماني, مبارا...   \n",
      "Al-Othaim Markets                                   شركة, وظائف, الرياض, وظيفة, توفر, أسواق, othai...   \n",
      "Almarai                                                  المراعي, وظائف, إلى, شركة, شكرا, عبر, الرابط   \n",
      "Almunajem Foods                                     saudi, listing, announces, exchange, foods, la...   \n",
      "Arabian Oud                                         العربية_للعود, يوم, العربية, تستاهلين, روز, ar...   \n",
      "Bayara                                              food, uae, saudi, savola_group, acquires, 260m...   \n",
      "BinDawood                                           العروض, اخترنا, لكم, bindawoodco, تسري, 2023, ...   \n",
      "Body Masters                                                خلال, أو, بودي, ماسترز, شهر, أندية, يمكنك   \n",
      "Camel Step                                          قهوة, خطوة_جمل, camel_step, فرع, coffee, الفرع...   \n",
      "Charmaleena                                               riyadh, jeddah, lt3, saudi, ksa, fine, love   \n",
      "DHAD                                                saudi, arabia, ثم, ضاد, الضاد, مسابقة_لبيه_الر...   \n",
      "Fanatics                                            football, flag, classic, riyadh, march, 21, brady   \n",
      "Fitness Time                                        fitness_time, وقت_اللياقة, اللياقه, حي, العمل,...   \n",
      "Goody                                                      saudi, oh, arabia, get, women, bag, prince   \n",
      "Hasawi                                              الأحساء, saudi, بودكاست_حساوي, alahsa, السعودي...   \n",
      "Herfy                                               يورو2024, euro2024, herfyfsc, اسبانيا, هرفي, م...   \n",
      "Hindamme                                            museum, jacket, display, driving, londons, iv,...   \n",
      "Jarir Bookstore                                        عرض, المتمم, جرير, مكتبة, 1443, الثلاثاء, 2021   \n",
      "KSA Anime                                           otaku, الدمام, الخبر, animation, الدمام_الخبر,...   \n",
      "KSA One Piece                                       luffy, ون_بيس, one_piece, فلم, crowdstrike, كا...   \n",
      "Kudu                                                chain, saudi, fastfood, abraaj, sources, tpg, ...   \n",
      "Lazurde                                               saudi, jewelry, gold, company, new, ksa, riyadh   \n",
      "Mall of Arabia                                      mall_of_arabia, مول_العرب, إلى, فرع, ويلز, الق...   \n",
      "Mikyajy                                             مكياجي, هدايا, السعودي, حياة_مول, مجموعة, الحب...   \n",
      "NADEC                                               nadecfoods, jobs, saudi, job, careers, apply, ...   \n",
      "Nada Dairy                                          ندى, food, nada_dairy, dairy, nadadairy, accom...   \n",
      "Nahdi                                                  الرياض, التحلية, فوق, صيدلية, بسعر, النهدي, حي   \n",
      "PureGym KSA                                         إلى, puregym, بيورجيم, imminent, sites, three,...   \n",
      "Qormuz                                                  رمز, smalied, قرمز, بس, حبيب, المعزب26, القلب   \n",
      "Razan Alazzouni                                     القائمة, الزفاف, والأزياء, صاحبات, أكثر, ومؤس, سة   \n",
      "Red Sea Mall                                                     رد, بعد, الف, الشي, قهوتي, best, رقم   \n",
      "Riyadh Park Mall                                    الحين, للسيارات, احجز, متنوعة, تجارب, concours...   \n",
      "SACO                                                      أو, ساكو, 2025, الخصم, سبتمبر, المبكر, الآن   \n",
      "Saudia Dairy (SADAFCO)                              dairy, foodstuff, saudia, company, sadafco, sa...   \n",
      "Sunbulah Group                                      sunbulah_group, sunbulahgroup, السنبلة, مجموعة...   \n",
      "Tamr                                                tourism, learn, dates, saudiarabia, saudi, dat...   \n",
      "The Dropped Collection                                brand, dropped, argentina, 21, tuesday, 387, 24   \n",
      "eXtra                                               العراق, اكسترا_عراق, بنسبة, extra_iraq, اخبار,...   \n",
      "Dania Shinkar                                                                                     NaN   \n",
      "Mama Noura                                                                                        NaN   \n",
      "Panda                                                                                             NaN   \n",
      "Rani                                                                                              NaN   \n",
      "Torba Studio                                                                                      NaN   \n",
      "\n",
      "                                                              Error  \n",
      "\\n    # Copied from the log where errors starte...              NaN  \n",
      "APOA                                                            NaN  \n",
      "Abadia                                                          NaN  \n",
      "Abdul Samad Al Qurashi                                          NaN  \n",
      "Al Nakheel Mall                                                 NaN  \n",
      "Al Rabie                                                        NaN  \n",
      "Al Romansiah                                                    NaN  \n",
      "Al-Ahli                                                         NaN  \n",
      "Al-Hilal                                                        NaN  \n",
      "Al-Ittihad                                                      NaN  \n",
      "Al-Nassr                                                        NaN  \n",
      "Al-Othaim Markets                                               NaN  \n",
      "Almarai                                                         NaN  \n",
      "Almunajem Foods                                                 NaN  \n",
      "Arabian Oud                                                     NaN  \n",
      "Bayara                                                          NaN  \n",
      "BinDawood                                                       NaN  \n",
      "Body Masters                                                    NaN  \n",
      "Camel Step                                                      NaN  \n",
      "Charmaleena                                                     NaN  \n",
      "DHAD                                                            NaN  \n",
      "Fanatics                                                        NaN  \n",
      "Fitness Time                                                    NaN  \n",
      "Goody                                                           NaN  \n",
      "Hasawi                                                          NaN  \n",
      "Herfy                                                           NaN  \n",
      "Hindamme                                                        NaN  \n",
      "Jarir Bookstore                                                 NaN  \n",
      "KSA Anime                                                       NaN  \n",
      "KSA One Piece                                                   NaN  \n",
      "Kudu                                                            NaN  \n",
      "Lazurde                                                         NaN  \n",
      "Mall of Arabia                                                  NaN  \n",
      "Mikyajy                                                         NaN  \n",
      "NADEC                                                           NaN  \n",
      "Nada Dairy                                                      NaN  \n",
      "Nahdi                                                           NaN  \n",
      "PureGym KSA                                                     NaN  \n",
      "Qormuz                                                          NaN  \n",
      "Razan Alazzouni                                                 NaN  \n",
      "Red Sea Mall                                                    NaN  \n",
      "Riyadh Park Mall                                                NaN  \n",
      "SACO                                                            NaN  \n",
      "Saudia Dairy (SADAFCO)                                          NaN  \n",
      "Sunbulah Group                                                  NaN  \n",
      "Tamr                                                            NaN  \n",
      "The Dropped Collection                                          NaN  \n",
      "eXtra                                                           NaN  \n",
      "Dania Shinkar                                       Not enough data  \n",
      "Mama Noura                                          Not enough data  \n",
      "Panda                                               Not enough data  \n",
      "Rani                                                Not enough data  \n",
      "Torba Studio                                        Not enough data  \n",
      "\n",
      "--- Topic Modeling Complete ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Phase 3b - Topic Modeling with LDA\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "print(\"--- Phase 3b: Topic Modeling (LDA) ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_TOPICS = 5 # How many topics to try and find per brand\n",
    "NUM_TOP_WORDS = 7 # How many top words to display for each topic\n",
    "\n",
    "# --- Prepare Stopwords ---\n",
    "# Combine English and Arabic stopwords (basic list, can be expanded)\n",
    "stop_words_en = list(stopwords.words('english'))\n",
    "# Basic Arabic stopwords (consider using a more comprehensive list if needed)\n",
    "# Example source: https://github.com/mohataher/arabic-stop-words\n",
    "stop_words_ar = [\"من\", \"في\", \"على\", \"الى\", \"عن\", \"و\", \"يا\", \"اي\", \"ما\", \"هو\", \"هي\", \n",
    "                 \"هذا\", \"هذه\", \"ذلك\", \"تلك\", \"ان\", \"او\", \"كل\", \"لا\", \"لن\", \"لم\", \n",
    "                 \"تم\", \"قد\", \"مع\", \"به\", \"له\", \"فيه\", \"عليها\", \"اليها\", \"عنه\", \n",
    "                 \"ايضا\", \"كان\", \"يكون\", \"صلى\", \"عليه\", \"وسلم\", \"قال\", \"ص\", \"ع\",\n",
    "                 \"ريال\", \"سعودي\", \"انا\", \"انت\", \"هم\", \"هن\", \"نحن\", \"اليوم\", \"جدا\",\n",
    "                 \"الله\", \"بن\", \"تم\", \"اللي\", \"الي\", \"حتى\", \"التي\", \"الذي\"] # Added common KSA terms\n",
    "stop_words_combined = stop_words_en + stop_words_ar\n",
    "# Add brand names to stopwords to avoid them dominating topics\n",
    "if 'df_tweets' in locals() and not df_tweets.empty:\n",
    "     brand_names_lower = [name.lower() for name in df_tweets['brand_name'].unique()]\n",
    "     # Add variations if needed (e.g., alhilal, al-hilal)\n",
    "     stop_words_combined.extend(brand_names_lower) \n",
    "     # Add common social media terms\n",
    "     stop_words_combined.extend(['rt', 'amp', 'co', 'https', 'http'])\n",
    "\n",
    "# --- Function to display topics ---\n",
    "def display_topics(model, feature_names, num_top_words):\n",
    "    topics = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]\n",
    "        topics[f\"Topic {topic_idx+1}\"] = \", \".join(top_words)\n",
    "        print(f\"Topic {topic_idx+1}: {', '.join(top_words)}\")\n",
    "    return topics\n",
    "\n",
    "# --- Perform LDA for each Brand ---\n",
    "brand_topics = {}\n",
    "\n",
    "if 'df_tweets' in locals() and not df_tweets.empty and 'cleaned_content' in df_tweets.columns:\n",
    "    print(\"\\nProcessing topics for each brand...\")\n",
    "    # Group by brand\n",
    "    for brand_name, group_df in df_tweets.groupby('brand_name'):\n",
    "        print(f\"\\n--- Topics for: {brand_name} ---\")\n",
    "        \n",
    "        # Filter out very short or empty tweets for better topic modeling\n",
    "        texts = group_df['cleaned_content'][group_df['cleaned_content'].str.len() > 10].tolist() \n",
    "        \n",
    "        if len(texts) < NUM_TOPICS: # Need enough documents for LDA\n",
    "            print(f\"   Skipping {brand_name}: Not enough tweets (found {len(texts)}) for LDA.\")\n",
    "            brand_topics[brand_name] = {\"Error\": \"Not enough data\"}\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # 1. Vectorize the text data using TF-IDF\n",
    "            # max_df ignores terms that appear in >95% of docs (too common)\n",
    "            # min_df ignores terms that appear in < 2 docs (too rare)\n",
    "            vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words=stop_words_combined, max_features=1000) \n",
    "            tfidf = vectorizer.fit_transform(texts)\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "            # 2. Apply LDA\n",
    "            lda = LatentDirichletAllocation(n_components=NUM_TOPICS, max_iter=10,\n",
    "                                            learning_method='online', \n",
    "                                            learning_offset=50.,\n",
    "                                            random_state=42) # For reproducibility\n",
    "            lda.fit(tfidf)\n",
    "\n",
    "            # 3. Display and store topics\n",
    "            brand_topics[brand_name] = display_topics(lda, feature_names, NUM_TOP_WORDS)\n",
    "\n",
    "        except ValueError as ve:\n",
    "             # Handle cases where vectorizer fails (e.g., all stopwords)\n",
    "             print(f\"   Skipping {brand_name}: ValueError during vectorization/LDA - {ve}\")\n",
    "             brand_topics[brand_name] = {\"Error\": f\"ValueError: {ve}\"}\n",
    "        except Exception as e:\n",
    "            print(f\"   Skipping {brand_name}: An unexpected error occurred during LDA - {e}\")\n",
    "            brand_topics[brand_name] = {\"Error\": f\"Unexpected error: {e}\"}\n",
    "\n",
    "    # Optional: Convert results to a DataFrame for easier viewing/saving\n",
    "    df_brand_topics = pd.DataFrame.from_dict(brand_topics, orient='index')\n",
    "    print(\"\\n\\n--- Brand Topics Summary ---\")\n",
    "    print(df_brand_topics)\n",
    "\n",
    "else:\n",
    "    print(\"   WARNING: df_tweets is empty or missing 'cleaned_content'. Cannot perform Topic Modeling.\")\n",
    "\n",
    "print(\"\\n--- Topic Modeling Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0440826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to download/verify NLTK stopwords...\n",
      "   Stopwords already downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Cell (Run Once): Download NLTK stopwords (if needed)\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "print(\"Attempting to download/verify NLTK stopwords...\")\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "    print(\"   Stopwords already downloaded.\")\n",
    "except LookupError:\n",
    "    print(\"   Downloading NLTK stopwords...\")\n",
    "    nltk.download('stopwords')\n",
    "    print(\"   Stopwords downloaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"   ERROR checking/downloading stopwords: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ea8a69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 3b: Topic Modeling (LDA) ---\n",
      "Preparing stopwords...\n",
      "   Using 330 combined stopwords.\n",
      "\n",
      "Processing topics for each brand...\n",
      "\n",
      "--- Topics for: \n",
      "    # Copied from the log where errors started\n",
      "    \"Al-Nassr\": \"Al Nassr OR النصر\",\n",
      "    \"Al-Ittihad\": \"Al Ittihad OR الاتحاد\",\n",
      "    \"Al-Ahli\": \"Al Ahli OR الاهلي\",\n",
      "    \"Fanatics\": \"Fanatics saudi\",\n",
      "    \"KSA Anime\": \"anime saudi OR انمي السعودية\",\n",
      "    \"KSA One Piece\": \"one piece saudi OR ون بيس السعودية\",\n",
      "    \"Fitness Time\": \"Fitness Time saudi OR وقت اللياقة\",\n",
      "    \"Body Masters\": \"Body Masters saudi OR بودي ماسترز\",\n",
      "    \"PureGym KSA\": \"PureGym saudi OR بيورجيم\",\n",
      "    \"Jarir Bookstore\": \"Jarir Bookstore saudi OR جرير\",\n",
      "    \"SACO\": \"SACO saudi OR ساكو\",\n",
      "    \"eXtra\": \"eXtra saudi OR اكسترا\",\n",
      "    \"Mall of Arabia\": \"Mall of Arabia saudi OR مول العرب\",\n",
      "    \"Riyadh Park Mall\": \"Riyadh Park saudi OR رياض بارك\",\n",
      "    \"Red Sea Mall\": \"Red Sea Mall saudi OR رد سي مول\",\n",
      "    \"Al Nakheel Mall\": \"Al Nakheel Mall saudi OR النخيل مول\",\n",
      "    \"Kingdom Centre\": \"Kingdom Centre saudi OR برج المملكة\",\n",
      "    \"Al Romansiah\": \"Al Romansiah saudi OR مطعم الرومانسية\",\n",
      "    \"Mama Noura\": \"Mama Noura saudi OR ماما نورة\"\n",
      "    Sleysla ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: saudi_aramco, sleysla saudi_aramco, سليسلة, saudi arabia, arabia, jeddah, sleysla\n",
      "     Topic 2: sleysla_bag, saudi_brand, sleysla_designs, palm_frond, palm_frond sleysla_designs, sleysla_designs high, sleysla_bag palm_frond\n",
      "     Topic 3: sleysla, سليسلة, saud, saudi_heritage, saudi, handmade, handicrafts\n",
      "     Topic 4: saudi, ksa, sleysla, hand_made, saudi_brand, beautiful, modern\n",
      "     Topic 5: women, support, tools support, tools, traditional, saudi, products\n",
      "\n",
      "--- Topics for: APOA ---\n",
      "   Skipping APOA: Not enough sufficiently long tweets (found 5) for reliable LDA.\n",
      "\n",
      "--- Topics for: Abadia ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: ksa, netaporter, shares, brand, first, brands, saudi\n",
      "     Topic 2: ethical, ethical saudi, queen rania, rania, queen, brand, dresses\n",
      "     Topic 3: brands, saudi fashion, saudi, fashion, fashion label, spotlight, artisans\n",
      "     Topic 4: heritage, sustainable, giving, craftsmanship, saudi arabia, arabia, women\n",
      "     Topic 5: saudi, fashion, saudi fashion, scene, founder, international, spotlight\n",
      "\n",
      "--- Topics for: Abdul Samad Al Qurashi ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: qurashi, إضغط, لحملة, شركة, بالكويت الرابط, شركة عبدالصمد, عبدالصمد_القرشي\n",
      "     Topic 2: وظائف, القرشي بالكويت, وظائف شركة, بالكويت, شركة عبدالصمد, شركة, الرابط السابق\n",
      "     Topic 3: عبدالصمد القرشي, القرشي, عبدالصمد, لحملة, العطور, جميع, السعودية\n",
      "     Topic 4: جميع, المملكة, السابق, لحملة, الوظائف وظائف, السعودية, الصحف\n",
      "     Topic 5: samad al, samad, qurashi, al, al qurashi, abdul samad, abdul\n",
      "\n",
      "--- Topics for: Al Nakheel Mall ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: بالرياض, عندنا, مول al, وش, سيفورا, mall, al\n",
      "     Topic 2: mall, mall النخيل, nakheel mall, nakheel, al, al nakheel, riyadh\n",
      "     Topic 3: الرياض, مدينة, يوم, 24, قهوة, إلى, الدمام\n",
      "     Topic 4: يوم, paul, اني, الرياض, nakheel mall, riyadh, al nakheel\n",
      "     Topic 5: الدمام, مجمع, منتجات, مول الدمام, العمل, ولا, بس\n",
      "\n",
      "--- Topics for: Al Rabie ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: بدر, بدر الربيع, مستوصف, مستوصف بدر, الربيع_مليون alrabie, دكتور, الربيع_مليون\n",
      "     Topic 2: حي الربيع, حي, district, district حي, rabie district, الربيع, al\n",
      "     Topic 3: life, decision extradite, saudi, extradite saudi, extradite, saudi citizen, citizen\n",
      "     Topic 4: الربيع, السعودية, موقع, عصير, عصير الربيع, صحة_للجميع, تطبيق\n",
      "     Topic 5: saudi, saudi arabia, arabia, al, rabie, al rabie, jobs\n",
      "\n",
      "--- Topics for: Al Romansiah ---\n",
      "   Skipping Al Romansiah: Not enough sufficiently long tweets (found 7) for reliable LDA.\n",
      "\n",
      "--- Topics for: Al-Ahli ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: al, hospital, sc, rwanda, clubs, al hilal, hilal\n",
      "     Topic 2: al, al ahli, ahli, hospital, 500, ahli hospital, well\n",
      "     Topic 3: al, ahli, al ahli, alahli, ahlicentral, alahli ahlicentral, league\n",
      "     Topic 4: الاهلي, الأهلي, الإمارات_اليوم, as21_al, al_casber, شباب الأهلي, المنتصف\n",
      "     Topic 5: الاهلي, الأهلي, الهلال, مباراة, دوري, الغرافة, الاتحاد\n",
      "\n",
      "--- Topics for: Al-Hilal ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: الهلال, تذاكر, الاتحاد, الرابط, غرينتاهب, تذكرتك, الاتحاد الهلال\n",
      "     Topic 2: barcelona, yamal, saudi, startimes, player, lamine yamal, offer\n",
      "     Topic 3: الاتحاد_الهلال, الاتحاد, تذكرة, والهلال, مربع, الاتحاد والهلال, لمباراة\n",
      "     Topic 4: al, hilal, al hilal, saudi, league, ittihad, al ittihad\n",
      "     Topic 5: player, aldawsari, salem, الهلال, salem aldawsari, afc, الهلال_البوليس_الكيني البوليس_الكيني_الهلال\n",
      "\n",
      "--- Topics for: Al-Ittihad ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: al, ittihad, al ittihad, hilal, al hilal, league, benzema\n",
      "     Topic 2: كاريزما85, الاتحاد_الهلال كاريزما85, لك, الاتحاد_الهلال, طلاب, أو, نجهز لك\n",
      "     Topic 3: الف, مبروك, الاتحاد الهلال, الف مبروك, دوري_روشن_السعودي, الف الف, النادي\n",
      "     Topic 4: الاتحاد, الاتحاد_الهلال, الهلال, الهلال_الاتحاد, جمهور, جمهور الاتحاد, المباراة\n",
      "     Topic 5: al, vs, ittihad, al ittihad, al hilal, hilal, vs al\n",
      "\n",
      "--- Topics for: Al-Nassr ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: alnassrfc, alnassrfc_en, al, nassr, al nassr, cristiano alnassrfc, alnassrfc alnassrfc_en\n",
      "     Topic 2: al, nassr, al nassr, ronaldo, win, felix, league\n",
      "     Topic 3: goals, 950, career goals, 950 career, career, goals al, pro league\n",
      "     Topic 4: النصر, النصر يلعب, يلعب, ولا, هدف, الاتحاد, ماني\n",
      "     Topic 5: النصر_الحزم, للعالمي, للعالمي النصر_الحزم, الفوز, النصر_الحزم كاريزما86, كاريزما86, النصر\n",
      "\n",
      "--- Topics for: Al-Othaim Markets ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: العثيم السعودية, أسواق العثيم, othaim, السعودية, markets, othaim markets, ksa\n",
      "     Topic 2: مصر, العثيم مصر, تسوق_نت_مصر, eg, markets eg, أسواق, eg offers\n",
      "     Topic 3: ٢٠١٩ استمتع, بالتسوق عروض, نون, استمتع بالتسوق, بالتسوق, استمتع, ٢٠١٩\n",
      "     Topic 4: المتمم, عروض العثيم, اخر, اخر عروض, عروض, عروض ركن, ركن\n",
      "     Topic 5: وظائف, شركة, عبدالله, شركة أسواق, أسواق عبدالله, عبدالله العثيم, وظيفة\n",
      "\n",
      "--- Topics for: Almarai ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: saudi, arizona, water, saudi arabia, arabia, fondomonte, leases\n",
      "     Topic 2: المراعي, وطن_له_طعم, المراعي وطن_له_طعم, وطن_له_طعم المراعي, almarai_care, saudi_fda, mcgovsa\n",
      "     Topic 3: saudi, saudi arabia, arabia, job, apply, openings, job openings\n",
      "     Topic 4: egypt, ksa, thailand, egypt thailand, uae egypt, ksa uae, vacancies ksa\n",
      "     Topic 5: dairy, saudi, company, milk, largest, million, billion\n",
      "\n",
      "--- Topics for: Almunajem Foods ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: one saudi, private, demand shares, announces listing, raise much, largest private, saudi arabia\n",
      "     Topic 2: saudi exchange, exchange, exchange announces, listing, announces listing, announces, almunajem foods\n",
      "     Topic 3: q1, revenue, public, almunajem foods, saudi arabias, arabias, announces\n",
      "     Topic 4: initial, initial public, public offering, offering, public, main, main market\n",
      "     Topic 5: almunajem foods, food, saudi food, saudi arabia, largest, arabias largest, private food\n",
      "\n",
      "--- Topics for: Arabian Oud ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: العربية_للعود, العربية_للعود_تهديك, arabian_oud, arabian_oud العربية_للعود_تهديك, arabian_oud العربية_للعود, عطر, 600\n",
      "     Topic 2: للعود, arabian_oud, العربية, العربية للعود, العربيه, العربيه للعود, عطر\n",
      "     Topic 3: اهديه, _للعود, arabian_oud اهديه, _تهديك, العربية_للعود_تهديك, العربيه _للعود, arabian_oud\n",
      "     Topic 4: منتجات العربية, منتجات, حول العالم, حول, فرع حول, المتاجر لك, وأقرب\n",
      "     Topic 5: عطر, العربية_للعود, arabianoud, طيبنا_من_طيبكم العربية_للعود, طيبنا_من_طيبكم, arabian, arabian oud\n",
      "\n",
      "--- Topics for: Bayara ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: بايارا, وظائف, شركة, بايارا مصر, egypt, شركة بايارا, مصر\n",
      "     Topic 2: arabias, 260 million, saudi arabias, group, 260, savola group, holding\n",
      "     Topic 3: maker, snack, saudi arabian, snack maker, arabian, savola, 260 million\n",
      "     Topic 4: food giant, food, uaes holding, acquires uaes, giant, holding, giant savola\n",
      "     Topic 5: food, uaes, savola_group, بايارا, saudi food, saudi, 260m\n",
      "\n",
      "--- Topics for: BinDawood ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: العروض, bindawoodco, لكم, تسري, تسري العروض, اخترنا, اخترنا لكم\n",
      "     Topic 2: القابضة, الرئيس, غرفة_الشرقية, للشركة, داود القابضة, شركة داود, شركة\n",
      "     Topic 3: رابط العرض, رابط, العرض, صفحة, صفحة واحدة, عروض داود, داود\n",
      "     Topic 4: الموافق, عروض داود, داود, الأسبوعية, 1446, 2025 الموافق, 2025\n",
      "     Topic 5: وحتي, داود الفترة, bin, dawood, bin dawood, الفترة, الرابط بن_داود\n",
      "\n",
      "--- Topics for: Body Masters ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: بودي_ماسترز, body_masters, سدير, السويدي, شارع سدير, السويدي شارع, شارع\n",
      "     Topic 2: أو, يمكنك, أندية بودي, أندية, المبارك, ramadan, رمضان المبارك\n",
      "     Topic 3: صدر, جد منطقة, جد, منطقة, مكة, منطقة مكة, ماسترز جد\n",
      "     Topic 4: ماسترز body, قبل, riyadh, والله, خصم, انقطاع, 40\n",
      "     Topic 5: masters بودي, يوم, اجل, افضل, photo, ماسترز photo, حياة\n",
      "\n",
      "--- Topics for: Camel Step ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: step, camel, coffee, camel step, خطوة_جمل, جمل, خطوة جمل\n",
      "     Topic 2: coffee, camel_step, خطوة_جمل, خطوة, step, جمل, خطوة جمل\n",
      "     Topic 3: camel_step, خطوة, جمل, خطوة جمل, camel, خطوة_جمل, camel step\n",
      "     Topic 4: خطوة_جمل, coffee, camel_step, camel, step, camel step, خطوة جمل\n",
      "     Topic 5: جمل, خطوة, خطوة جمل, step, camel step, camel, coffee\n",
      "\n",
      "--- Topics for: Charmaleena ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: شارمالينا, jeddah riyadh, jewellery jeddah, saudi ksa, riyadh, mycharmaleena, charmaleenajewellery\n",
      "     Topic 2: saudi ksa, mycharmaleena, saudi jewellery, jewellery jeddah, شارمالينا, designer, charmaleenajewellery\n",
      "     Topic 3: saudi, jeddah, riyadh, ksa, jeddah riyadh, jewellery jeddah, saudi ksa\n",
      "     Topic 4: designer, saudi jewellery, saudi, ksa, jeddah, charmaleenajewellery شارمالينا, mycharmaleena\n",
      "     Topic 5: charmaleenajewellery, charmaleenajewellery شارمالينا, mycharmaleena, شارمالينا, jeddah, ksa, saudi jewellery\n",
      "\n",
      "--- Topics for: DHAD ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: ضاد, اللغة, العربية, dhad_sa, اللغة العربية, بدأت, العربية dhad_sa\n",
      "     Topic 2: ضاد, dhad_sa, الصوتية, تطبيق, للكتب, تطبيق ضاد, للكتب الصوتية\n",
      "     Topic 3: ضاد, dhad_sa ضاد, الناس, dhad_sa, الصوم, ولم, الفرق\n",
      "     Topic 4: dhad_sa, فوازير_ضاد, كتاب, جاوبوها_صح, فوازير_ضاد جاوبوها_صح, dhad_sa فوازير_ضاد, جاوبوها_صح كتاب\n",
      "     Topic 5: saudi, arabia, saudi arabia, اللغة_العربية, عربي, iran, yemen\n",
      "\n",
      "--- Topics for: Dania Shinkar ---\n",
      "   Skipping Dania Shinkar: Not enough sufficiently long tweets (found 2) for reliable LDA.\n",
      "\n",
      "--- Topics for: Fanatics ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: head, saudi, check, things, qatar, player, waspapping_\n",
      "     Topic 2: saudi, christians, want, world, muslims, saudi arabia, arabia\n",
      "     Topic 3: football, flag football, flag, classic, football classic, brady, tom\n",
      "     Topic 4: wwe, arena, kingdom, kingdom arena, 21 kingdom, arena riyadh, riyadh\n",
      "     Topic 5: saudi, arabia, saudi arabia, religious, iran, israel, dont\n",
      "\n",
      "--- Topics for: Fitness Time ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: وقت_اللياقة, فتنس, فرع, فئة, جدة, الرابط, فئة وقت\n",
      "     Topic 2: time وقت, time, fitness time, fitness, وقت, وقت اللياقة, اللياقة\n",
      "     Topic 3: وقت_اللياقة, fitness_time, وقت اللياقه, اللياقه, وقت_اللياقة fitness_time, وقت_اللياقة fitness, وقت_اللياقه\n",
      "     Topic 4: رياضة, مميزه, مفروشه, شقق, مفروشه مميزه, عرعر_مول, شقق مفروشه\n",
      "     Topic 5: وقـت, وقـت اللـياقة, اللـياقة, time وقـت, الالكتروني, موقعنا, موقعنا الالكتروني\n",
      "\n",
      "--- Topics for: Goody ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: ورق, قودي, شركةة, شركةة قودي, فضيحة, لمحبي, العنب\n",
      "     Topic 2: وصفات, قودي, aklah, bahrain aklah, باستا, الاطفال, جديد\n",
      "     Topic 3: منتجات, منتجات قودي, products, bahrain, consumer, البحرين, products bahrain\n",
      "     Topic 4: قودي, تطبيق, مطبخ, مطبخ قودي, goodykitchen, مجلة, تطبيق مطبخ\n",
      "     Topic 5: saudi, arabia, saudi arabia, oh, like, food, get\n",
      "\n",
      "--- Topics for: Hasawi ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: بالاضافة, ت0135961888, اطباق, 5كبسة, مندي, خضرا, حساوي\n",
      "     Topic 2: الأحساء, بودكاست_حساوي الأحساء, saudi, بودكاست_حساوي, gamer_hasawi, xbox_saudi, saudi arabia\n",
      "     Topic 3: حساوي, aal_hasawi, هههههه, بس, والله, ولا, hasawi_313\n",
      "     Topic 4: حساوي_ديل, عالمية, عالمية بلهجة, لعبة عالمية, حساوي_ديل لعبة, لعبة, بلهجة\n",
      "     Topic 5: saudi, ديل, حساوي ديل, لعبة, بلهجة, حساوي, متوفره\n",
      "\n",
      "--- Topics for: Herfy ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: saudi arabia, arabia, riyadh, im, kingdom, saudi, kingdom saudi\n",
      "     Topic 2: هرفي, herfyfsc, يورو2024, هرفي يورو2024, يورو2024 euro2024, euro2024, هرفيxسوبرمان هرفي\n",
      "     Topic 3: الكنز, بوليفارد_رن_واي بوليفارد_وورلد, وندر_جاردن, وندر_جاردن riyadhseason, موسم_الریاض, بوليفارد_وورلد, الوناسبه\n",
      "     Topic 4: saudi, chain, food, saudi arabia, arabia, fast, world\n",
      "     Topic 5: كاس_العالم_2034, ليس, سعوديا, ليس سعوديا, herfyfsc, الم, ستحيل\n",
      "\n",
      "--- Topics for: Hindamme ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: خارقة, سترة, خارقة تاريخ, تاريخ أيقوني, القيادة السعودية, القيادة, أيقوني\n",
      "     Topic 2: designer, saudi, moekhoja, saudi designer, mohammed, founder, fashion designer\n",
      "     Topic 3: driving jacket, jacket, driving, victoria, victoria albert, londons, albert museum\n",
      "     Topic 4: collection, west, alula, saudi, saudibased, brand, latest\n",
      "     Topic 5: fashion, saudi, wrth_ksa, aramfashion, saudi fashion, fashion brand, miskartinst\n",
      "\n",
      "--- Topics for: Jarir Bookstore ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: مكتبة, جرير, مكتبة جرير, 2021, 2021 المتمم, نهاية, جرير نهاية\n",
      "     Topic 2: offers, ksa, deals, deals offers, ksadeals, ksaoffers, offersinme\n",
      "     Topic 3: jarir, bookstore, jarir bookstore, saudi, saudi arabia, arabia, bookstore saudi\n",
      "     Topic 4: وظائف, الثانوية, لحملة الثانوية, لحملة, تعلن, jarir_bookstore, الرياض\n",
      "     Topic 5: عرض, المتمم, جرير, عرض مكتبة, مكتبة جرير, مكتبة, الثلاثاء\n",
      "\n",
      "--- Topics for: KSA Anime ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: انمي, anime, اليابان, الساعة, اوتاكو, انمي اوتاكو, anime انمي\n",
      "     Topic 2: onepiece, انمي, figures, onepiece figures, ون_بيس onepiece, anime, العراق\n",
      "     Topic 3: الأنمي, انمي, قادم, السينما, anime, انمي anime, السينما السعودية\n",
      "     Topic 4: الحلقة, ささ恋, saudi, مانجا, أنمي, اوتاكو, anime\n",
      "     Topic 5: animekey, جوبلن_سلاير, goblinslayer, انمى_كى, الثاني, anime, اوتاكو\n",
      "\n",
      "--- Topics for: KSA One Piece ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: السعودية, ون_بيس, ون, بيس, ون بيس, one, one piece\n",
      "     Topic 2: كرانشي رول, كرانشي, تقييما, رول, يحصل المركز, بـ, سنة كاملة\n",
      "     Topic 3: 608 تحميل, بيس 608, مترجمة one, تحميل مترجمة, 608, piece khaledalhrbi, السعودية انمي\n",
      "     Topic 4: مانجا, قطر مصر, السعوديه, مصر الجزائر, الجزائر, الكويت قطر, البحرين\n",
      "     Topic 5: 607, مساء, مساء بتوقيت, بتوقيت, بتوقيت السعودية, الساعة, ضد\n",
      "\n",
      "--- Topics for: Kudu ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: arabia, saudi arabia, saudi, المنطقة, restaurant, كودو, good\n",
      "     Topic 2: saudi, fastfood, chain, saudi fastfood, fastfood chain, abraaj, sources\n",
      "     Topic 3: food, investment, says, completes, completes investment, saudis, abraaj says\n",
      "     Topic 4: هلا_باللذيذ, وجبة, كودو, 920006999, اليومية, التوصيل, خدمة التوصيل\n",
      "     Topic 5: كودو, kuduksa, مطعم, وظائف, مطاعم, المملكة, مطاعم كودو\n",
      "\n",
      "--- Topics for: Lazurde ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: montadatakmem, khaleedalshada1, lazurde_injoy, rashaghcom, nawaf_anazi, السعودية, mozahem_takmim\n",
      "     Topic 2: saudi, arabia, saudi arabia, jewelry, apply, arabia apply, lazurde_injoy lolo222811\n",
      "     Topic 3: saudi, maker, listing, regulator, gets regulator, nod, gets\n",
      "     Topic 4: لزوردي, elissakh, lazurde_injoy, السعودية, جدوى_الخبر, تداول, awalan\n",
      "     Topic 5: uae, expansion, jeddah, first saudi, saudi, title, park hyatt\n",
      "\n",
      "--- Topics for: Mall of Arabia ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: مول العرب, mall, mall arabia, arabia, arabia مول, العرب mall, مجمع\n",
      "     Topic 2: arabia cairo, cairo, lt3, arabia, mall arabia, mall, مول العرب\n",
      "     Topic 3: اسمه, اسمه mall, mall 3arabya, 3arabya, هتدوسك, هتدوسك بعون, 3arabya دي\n",
      "     Topic 4: جدة, علي, جدة مول, مول_العرب, 7d, سينما 7d, سينما\n",
      "     Topic 5: mall_of_arabia, مول_العرب, إلى, الفنان, العرب مول, مول العرب, العالمية\n",
      "\n",
      "--- Topics for: Mama Noura ---\n",
      "   Skipping Mama Noura: Not enough sufficiently long tweets (found 2) for reliable LDA.\n",
      "\n",
      "--- Topics for: Mikyajy ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: offer, السعودي, day, 99, set, الوطني, مجموعة الحب\n",
      "     Topic 2: saudi, collection, get, saudi riyadh, riyadh, buy, new\n",
      "     Topic 3: مكياجي, مكياج, منتجات, هدايا, أفضل, المفضلة, احصلي\n",
      "     Topic 4: saudi, makeup, الحب, رمضان, حياة_مول, مجموعة, مكياجي\n",
      "     Topic 5: arabia, saudi arabia, saudi, رمضان_كريم, ramadankareem, رمضان, رمضان_كريم مكياجي\n",
      "\n",
      "--- Topics for: NADEC ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: arabia, jobs, saudi, saudi arabia, foods, job, vacancy\n",
      "     Topic 2: agricultural, national, national agricultural, development, agricultural development, development company, company\n",
      "     Topic 3: saudis, saudis agrees, agrees acquire, competitor, dairy competitor, agrees, acquire dairy\n",
      "     Topic 4: saudi, arabia, saudi arabia, jobs, food, danone, dairy\n",
      "     Topic 5: نادك, شركة, شركة نادك, بالتوظيف, تدريب, تعلن, فتح\n",
      "\n",
      "--- Topics for: Nada Dairy ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: jobs, saudi, al, saudi arabia, arabia, company, years\n",
      "     Topic 2: sales, job, saudi, salesman, van, arabia, openings nada\n",
      "     Topic 3: saudi, arabia, saudi arabia, technician, dairy saudi, years exp, arabia nada\n",
      "     Topic 4: ندى, nadadairy, ندى nada, والطعم, عيشوا أجمل, ومذاق, أجمل\n",
      "     Topic 5: al, dairy saudi, technician, saudi, jobs, ندى nada, food\n",
      "\n",
      "--- Topics for: Nahdi ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: النهدي, صيدلية النهدي, صيدلية, pharmacy, al, al pharmacy, pharmacy صيدلية\n",
      "     Topic 2: عروض, عروض صيدلية, الأسبوعية, الموافق, 2024, صيدلية, صيدلية النهدي\n",
      "     Topic 3: حي, النهدى, pharmacy صيدليه, صيدليه النهدى, صيدليه, بك, pharmacy\n",
      "     Topic 4: السعودية, النهدي, عروض, صيدلية, صيدلية النهدي, جدة, الرياض\n",
      "     Topic 5: nahdihope, صيدلية, صيدلية النهدي, النهدي, pharmacy, جدة, السعودية\n",
      "\n",
      "--- Topics for: Panda ---\n",
      "   Skipping Panda: Not enough sufficiently long tweets (found 3) for reliable LDA.\n",
      "\n",
      "--- Topics for: PureGym KSA ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: supply chain, logistics business, puregym arabia, bachelors, requirements, experience, cv\n",
      "     Topic 2: arabia, darrengrimes_, saudi arabia, darrengrimes_ puregym, saudi, dont, live\n",
      "     Topic 3: بيورجيم, puregymarabia, إلى, بنا, الخاص, الخاص بنا, puregymksa\n",
      "     Topic 4: saudi, gym, puregym saudi, arabian, got, opening, saudi arabian\n",
      "     Topic 5: services puregymarabia, puregym gym, ambitions, hiring, middle east, years, والذي\n",
      "\n",
      "--- Topics for: Qormuz ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: قرمز, عبدالرحمن العابد, عبدالرحمن, العابد, معكم, منها, abdulrhmn_abed\n",
      "     Topic 2: رمز, فيها, الثميري, رمز الثميري, المحل, smalied, قرمز\n",
      "     Topic 3: قرمز, رمز, القلب, هدية, بس, حبيب, wejdanfashion\n",
      "     Topic 4: إلى, saudi, قرمز, الفنان, محمد, سعودية, القطعة\n",
      "     Topic 5: قرمز, smalied, قرمز smalied, السعودية, وش, براند, نادي\n",
      "\n",
      "--- Topics for: Rani ---\n",
      "   Skipping Rani: Not enough sufficiently long tweets (found 1) for reliable LDA.\n",
      "\n",
      "--- Topics for: Razan Alazzouni ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: alazzouni, العلامة التجارية, razan, razan alazzouni, العلامة, العزوني, السعودية\n",
      "     Topic 2: التجارية, السعودية رزان, الأعمال, الموضة والأزياء, الموضة, والأزياء, علامتها\n",
      "     Topic 3: razanalazzouni, الأزياء, مجموعة, رزان_العزوني, علامة, razan alazzouni, مجلة\n",
      "     Topic 4: سعوديه, سعوديه وصلت, وصلت العالمية, العزوني سعوديه, razan alazzouni, العالمية, وصلت\n",
      "     Topic 5: مجموعة, رزان العزوني, العزوني, رزان, سة, المملكة, علامتها\n",
      "\n",
      "--- Topics for: Red Sea Mall ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: ردسي, mall رد, ردسي مول, الفيسبوك, الفيسبوك red, أخبار, إعجابكم\n",
      "     Topic 2: mall رد, redseamallksa, مول redseamallksa, others, بس, جدة, والله\n",
      "     Topic 3: mall رد, like, عزك, ال, نفسك, ذا, الف\n",
      "     Topic 4: mall رد, لمن, shopping, حبيت, love, بعض, time\n",
      "     Topic 5: jeddah, makkah, jeddah makkah, مول jeddah, mall رد, رد_سي_مول, جده\n",
      "\n",
      "--- Topics for: Riyadh Park Mall ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: النادرة, للسيارات, احجز, احجز الحين, موسم_الرياض, معرض, الحين\n",
      "     Topic 2: الحين, احجز, موسم_الرياض, عيشها, ايماجينيشن_بارك, منطقة, الحين عيشها\n",
      "     Topic 3: بارك, لكم, riyadh, مول, park, mall, صباحا\n",
      "     Topic 4: تذكرتك, احجز تذكرتك, عيشها, تذكرتك عيشها, تجربة, ايماجينيشن_بارك, احجز\n",
      "     Topic 5: بارك, رياض, الرياض, رياض بارك, الرياض بارك, بارك مول, افضل\n",
      "\n",
      "--- Topics for: SACO ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: saudi, company hardware, company, hardware investor, investor, saudi company, investor relations\n",
      "     Topic 2: saco_ksa, ساكو, افحصي, مبكرا, سرطان, سرطان الثدي, افحصي مبكرا\n",
      "     Topic 3: saudi, hardware, company, saudi company, saudi hardware, retailer, hardware retailer\n",
      "     Topic 4: saudi, today, news, الفحص, الفحص المبكر, top, riyadh\n",
      "     Topic 5: ساكو, عروض, جدة, جدة ساكو, عروض جدة, sr, إلى\n",
      "\n",
      "--- Topics for: Saudia Dairy (SADAFCO) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: saudi, sadafco, dairy, dairy foodstuff, foodstuff, company, saudia\n",
      "     Topic 2: وظائف, لحملة, مبيعات, جدة, شركة سدافكو, شركة, الطائف\n",
      "     Topic 3: sadafco, talent, jeddah, kingdom saudi, kingdom, talent sadafco, arabia jeddah\n",
      "     Topic 4: وظائف, سدافكو, السعودية, تعلن, والأغذية سدافكو, الشركة السعودية, التقديم\n",
      "     Topic 5: سعودية, الألبان, شركة, التالية, sadafco_, منتجات, لمنتجات الألبان\n",
      "\n",
      "--- Topics for: Sunbulah Group ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: السنبلة, ksa, sunbulah, baytcom ksa, group baytcom, baytcom, job opportunities\n",
      "     Topic 2: sunbulah_group, saudi__platform sunbulah_group, saudi__platform, specialist sunbulah, specialist, recruitment specialist, sunbulah\n",
      "     Topic 3: technical packaging, technical, جامعة_الملك_فهد_للبترول_والمعادن, تشارك, packaging, اليوم_المفتوح, jobs\n",
      "     Topic 4: group, sunbulah, sunbulah group, saudi, manager, jobs, arabia\n",
      "     Topic 5: مجموعة, مجموعة السنبلة, السنبلة, تعلن, جدة, وظيفة, وظائف\n",
      "\n",
      "--- Topics for: Tamr ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: تمر, saudi dates, date, ramadan, saudi, dates تمر, benefits\n",
      "     Topic 2: arabic, used, rutab, رطب, unripe dates, تمر, soft\n",
      "     Topic 3: arabic تمر, food, dates arabic, middle, arabic, تمر, made\n",
      "     Topic 4: like, unripe, ramadan, arabia, ripe, unripe dates, date\n",
      "     Topic 5: saudi, saudi arabia, arabia, traditional, made, arabian, like\n",
      "\n",
      "--- Topics for: The Dropped Collection ---\n",
      "   Discovered Topics:\n",
      "     Topic 1: collection, 387, unexpected, increased 387, 387 tuesday, past 24, arabias\n",
      "     Topic 2: token, following, nft, fan token, nft collection, fan, collection\n",
      "     Topic 3: 387 tuesday, following, argentinas, arabias nft, saudi arabia, increased 387, argentina\n",
      "     Topic 4: 21, argentina, argentinas fan, nft collection, win, win argentina, tuesday\n",
      "     Topic 5: arabia, saudi arabia, collection, nft, nft collection, 21 past, past 24\n",
      "\n",
      "--- Topics for: Torba Studio ---\n",
      "   Skipping Torba Studio: Not enough sufficiently long tweets (found 1) for reliable LDA.\n",
      "\n",
      "--- Topics for: eXtra ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abdul', 'ahli', 'al', 'alazzouni', 'almunajem', 'anime', 'arabia', 'arabian', 'body', 'bookstore', 'camel', 'centre', 'collection', 'copied', 'dairy', 'dania', 'dropped', 'errors', 'fitness', 'foods', 'group', 'hilal', 'ittihad', 'jarir', 'kingdom', 'ksa', 'log', 'mall', 'mama', 'markets', 'masters', 'nada', 'nakheel', 'nassr', 'noura', 'one', 'othaim', 'oud', 'park', 'piece', 'puregym', 'qurashi', 'rabie', 'razan', 'red', 'riyadh', 'romansiah', 'sadafco', 'samad', 'saudi', 'saudia', 'sea', 'shinkar', 'sleysla', 'started', 'step', 'studio', 'sunbulah', 'time', 'torba', 'اكسترا', 'الاتحاد', 'الاهلي', 'الرومانسية', 'السعودية', 'العرب', 'اللياقة', 'المملكة', 'النخيل', 'النصر', 'انمي', 'بارك', 'برج', 'بودي', 'بيس', 'بيورجيم', 'جرير', 'رد', 'رياض', 'ساكو', 'سي', 'ماسترز', 'ماما', 'مطعم', 'مول', 'نورة', 'وقت', 'ون'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Discovered Topics:\n",
      "     Topic 1: اكسترا, تطبيق, إكسترا, تطبيق اكسترا, oman, الرابط, معارضنا\n",
      "     Topic 2: تسري, اكسترا, اكسترا oman, oman, cup, إضافي, super cup\n",
      "     Topic 3: العراق, اكسترا_عراق, بنسبة, extra_iraq, اكسترا_عراق extra_iraq, اخبار, extra_iraq اخبار\n",
      "     Topic 4: saudi, arabia, saudi arabia, money, like, would, oil\n",
      "     Topic 5: اكسترا, عروض, 2025, 10, السعودية, عروض اكسترا, العرض\n",
      "\n",
      "\n",
      "--- Brand Topics Summary ---\n",
      "                                                                                                                                                                                                                                                                      Topic 1  \\\n",
      "\\n    # Copied from the log where errors started\\n    \"Al-Nassr\": \"Al Nassr OR النصر\",\\n    \"Al-Ittihad\": \"Al Ittihad OR الاتحاد\",\\n    \"Al-Ahli\": ...                                      saudi_aramco, sleysla saudi_aramco, سليسلة, saudi arabia, arabia, jeddah, sleysla   \n",
      "Abadia                                                                                                                                                                                                                   ksa, netaporter, shares, brand, first, brands, saudi   \n",
      "Abdul Samad Al Qurashi                                                                                                                                                                             qurashi, إضغط, لحملة, شركة, بالكويت الرابط, شركة عبدالصمد, عبدالصمد_القرشي   \n",
      "Al Nakheel Mall                                                                                                                                                                                                                  بالرياض, عندنا, مول al, وش, سيفورا, mall, al   \n",
      "Al Rabie                                                                                                                                                                                       بدر, بدر الربيع, مستوصف, مستوصف بدر, الربيع_مليون alrabie, دكتور, الربيع_مليون   \n",
      "Al-Ahli                                                                                                                                                                                                                      al, hospital, sc, rwanda, clubs, al hilal, hilal   \n",
      "Al-Hilal                                                                                                                                                                                                     الهلال, تذاكر, الاتحاد, الرابط, غرينتاهب, تذكرتك, الاتحاد الهلال   \n",
      "Al-Ittihad                                                                                                                                                                                                          al, ittihad, al ittihad, hilal, al hilal, league, benzema   \n",
      "Al-Nassr                                                                                                                                                                            alnassrfc, alnassrfc_en, al, nassr, al nassr, cristiano alnassrfc, alnassrfc alnassrfc_en   \n",
      "Al-Othaim Markets                                                                                                                                                                               العثيم السعودية, أسواق العثيم, othaim, السعودية, markets, othaim markets, ksa   \n",
      "Almarai                                                                                                                                                                                                       saudi, arizona, water, saudi arabia, arabia, fondomonte, leases   \n",
      "Almunajem Foods                                                                                                                                                               one saudi, private, demand shares, announces listing, raise much, largest private, saudi arabia   \n",
      "Arabian Oud                                                                                                                                             العربية_للعود, العربية_للعود_تهديك, arabian_oud, arabian_oud العربية_للعود_تهديك, arabian_oud العربية_للعود, عطر, 600   \n",
      "Bayara                                                                                                                                                                                                               بايارا, وظائف, شركة, بايارا مصر, egypt, شركة بايارا, مصر   \n",
      "BinDawood                                                                                                                                                                                                     العروض, bindawoodco, لكم, تسري, تسري العروض, اخترنا, اخترنا لكم   \n",
      "Body Masters                                                                                                                                                                                          بودي_ماسترز, body_masters, سدير, السويدي, شارع سدير, السويدي شارع, شارع   \n",
      "Camel Step                                                                                                                                                                                                           step, camel, coffee, camel step, خطوة_جمل, جمل, خطوة جمل   \n",
      "Charmaleena                                                                                                                                                                شارمالينا, jeddah riyadh, jewellery jeddah, saudi ksa, riyadh, mycharmaleena, charmaleenajewellery   \n",
      "DHAD                                                                                                                                                                                                       ضاد, اللغة, العربية, dhad_sa, اللغة العربية, بدأت, العربية dhad_sa   \n",
      "Fanatics                                                                                                                                                                                                               head, saudi, check, things, qatar, player, waspapping_   \n",
      "Fitness Time                                                                                                                                                                                                                وقت_اللياقة, فتنس, فرع, فئة, جدة, الرابط, فئة وقت   \n",
      "Goody                                                                                                                                                                                                                       ورق, قودي, شركةة, شركةة قودي, فضيحة, لمحبي, العنب   \n",
      "Hasawi                                                                                                                                                                                                                 بالاضافة, ت0135961888, اطباق, 5كبسة, مندي, خضرا, حساوي   \n",
      "Herfy                                                                                                                                                                                                         saudi arabia, arabia, riyadh, im, kingdom, saudi, kingdom saudi   \n",
      "Hindamme                                                                                                                                                                                            خارقة, سترة, خارقة تاريخ, تاريخ أيقوني, القيادة السعودية, القيادة, أيقوني   \n",
      "Jarir Bookstore                                                                                                                                                                                                 مكتبة, جرير, مكتبة جرير, 2021, 2021 المتمم, نهاية, جرير نهاية   \n",
      "KSA Anime                                                                                                                                                                                                       انمي, anime, اليابان, الساعة, اوتاكو, انمي اوتاكو, anime انمي   \n",
      "KSA One Piece                                                                                                                                                                                                               السعودية, ون_بيس, ون, بيس, ون بيس, one, one piece   \n",
      "Kudu                                                                                                                                                                                                             arabia, saudi arabia, saudi, المنطقة, restaurant, كودو, good   \n",
      "Lazurde                                                                                                                                                                      montadatakmem, khaleedalshada1, lazurde_injoy, rashaghcom, nawaf_anazi, السعودية, mozahem_takmim   \n",
      "Mall of Arabia                                                                                                                                                                                             مول العرب, mall, mall arabia, arabia, arabia مول, العرب mall, مجمع   \n",
      "Mikyajy                                                                                                                                                                                                                     offer, السعودي, day, 99, set, الوطني, مجموعة الحب   \n",
      "NADEC                                                                                                                                                                                                                  arabia, jobs, saudi, saudi arabia, foods, job, vacancy   \n",
      "Nada Dairy                                                                                                                                                                                                              jobs, saudi, al, saudi arabia, arabia, company, years   \n",
      "Nahdi                                                                                                                                                                                               النهدي, صيدلية النهدي, صيدلية, pharmacy, al, al pharmacy, pharmacy صيدلية   \n",
      "PureGym KSA                                                                                                                                                                         supply chain, logistics business, puregym arabia, bachelors, requirements, experience, cv   \n",
      "Qormuz                                                                                                                                                                                                  قرمز, عبدالرحمن العابد, عبدالرحمن, العابد, معكم, منها, abdulrhmn_abed   \n",
      "Razan Alazzouni                                                                                                                                                                               alazzouni, العلامة التجارية, razan, razan alazzouni, العلامة, العزوني, السعودية   \n",
      "Red Sea Mall                                                                                                                                                                                                  ردسي, mall رد, ردسي مول, الفيسبوك, الفيسبوك red, أخبار, إعجابكم   \n",
      "Riyadh Park Mall                                                                                                                                                                                                النادرة, للسيارات, احجز, احجز الحين, موسم_الرياض, معرض, الحين   \n",
      "SACO                                                                                                                                                                         saudi, company hardware, company, hardware investor, investor, saudi company, investor relations   \n",
      "Saudia Dairy (SADAFCO)                                                                                                                                                                                     saudi, sadafco, dairy, dairy foodstuff, foodstuff, company, saudia   \n",
      "Sunbulah Group                                                                                                                                                                                 السنبلة, ksa, sunbulah, baytcom ksa, group baytcom, baytcom, job opportunities   \n",
      "Tamr                                                                                                                                                                                                              تمر, saudi dates, date, ramadan, saudi, dates تمر, benefits   \n",
      "The Dropped Collection                                                                                                                                                                              collection, 387, unexpected, increased 387, 387 tuesday, past 24, arabias   \n",
      "eXtra                                                                                                                                                                                                              اكسترا, تطبيق, إكسترا, تطبيق اكسترا, oman, الرابط, معارضنا   \n",
      "APOA                                                                                                                                                                                                                                                                      NaN   \n",
      "Al Romansiah                                                                                                                                                                                                                                                              NaN   \n",
      "Dania Shinkar                                                                                                                                                                                                                                                             NaN   \n",
      "Mama Noura                                                                                                                                                                                                                                                                NaN   \n",
      "Panda                                                                                                                                                                                                                                                                     NaN   \n",
      "Rani                                                                                                                                                                                                                                                                      NaN   \n",
      "Torba Studio                                                                                                                                                                                                                                                              NaN   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                   Topic 2  \\\n",
      "\\n    # Copied from the log where errors started\\n    \"Al-Nassr\": \"Al Nassr OR النصر\",\\n    \"Al-Ittihad\": \"Al Ittihad OR الاتحاد\",\\n    \"Al-Ahli\": ...     sleysla_bag, saudi_brand, sleysla_designs, palm_frond, palm_frond sleysla_designs, sleysla_designs high, sleysla_bag palm_frond   \n",
      "Abadia                                                                                                                                                                                                                   ethical, ethical saudi, queen rania, rania, queen, brand, dresses   \n",
      "Abdul Samad Al Qurashi                                                                                                                                                                                      وظائف, القرشي بالكويت, وظائف شركة, بالكويت, شركة عبدالصمد, شركة, الرابط السابق   \n",
      "Al Nakheel Mall                                                                                                                                                                                                           mall, mall النخيل, nakheel mall, nakheel, al, al nakheel, riyadh   \n",
      "Al Rabie                                                                                                                                                                                                                  حي الربيع, حي, district, district حي, rabie district, الربيع, al   \n",
      "Al-Ahli                                                                                                                                                                                                                              al, al ahli, ahli, hospital, 500, ahli hospital, well   \n",
      "Al-Hilal                                                                                                                                                                                                                   barcelona, yamal, saudi, startimes, player, lamine yamal, offer   \n",
      "Al-Ittihad                                                                                                                                                                                                      كاريزما85, الاتحاد_الهلال كاريزما85, لك, الاتحاد_الهلال, طلاب, أو, نجهز لك   \n",
      "Al-Nassr                                                                                                                                                                                                                                  al, nassr, al nassr, ronaldo, win, felix, league   \n",
      "Al-Othaim Markets                                                                                                                                                                                                           مصر, العثيم مصر, تسوق_نت_مصر, eg, markets eg, أسواق, eg offers   \n",
      "Almarai                                                                                                                                                                                      المراعي, وطن_له_طعم, المراعي وطن_له_طعم, وطن_له_طعم المراعي, almarai_care, saudi_fda, mcgovsa   \n",
      "Almunajem Foods                                                                                                                                                                       saudi exchange, exchange, exchange announces, listing, announces listing, announces, almunajem foods   \n",
      "Arabian Oud                                                                                                                                                                                                        للعود, arabian_oud, العربية, العربية للعود, العربيه, العربيه للعود, عطر   \n",
      "Bayara                                                                                                                                                                                                              arabias, 260 million, saudi arabias, group, 260, savola group, holding   \n",
      "BinDawood                                                                                                                                                                                                             القابضة, الرئيس, غرفة_الشرقية, للشركة, داود القابضة, شركة داود, شركة   \n",
      "Body Masters                                                                                                                                                                                                                 أو, يمكنك, أندية بودي, أندية, المبارك, ramadan, رمضان المبارك   \n",
      "Camel Step                                                                                                                                                                                                                         coffee, camel_step, خطوة_جمل, خطوة, step, جمل, خطوة جمل   \n",
      "Charmaleena                                                                                                                                                                         saudi ksa, mycharmaleena, saudi jewellery, jewellery jeddah, شارمالينا, designer, charmaleenajewellery   \n",
      "DHAD                                                                                                                                                                                                                         ضاد, dhad_sa, الصوتية, تطبيق, للكتب, تطبيق ضاد, للكتب الصوتية   \n",
      "Fanatics                                                                                                                                                                                                                     saudi, christians, want, world, muslims, saudi arabia, arabia   \n",
      "Fitness Time                                                                                                                                                                                                              time وقت, time, fitness time, fitness, وقت, وقت اللياقة, اللياقة   \n",
      "Goody                                                                                                                                                                                                                              وصفات, قودي, aklah, bahrain aklah, باستا, الاطفال, جديد   \n",
      "Hasawi                                                                                                                                                                                        الأحساء, بودكاست_حساوي الأحساء, saudi, بودكاست_حساوي, gamer_hasawi, xbox_saudi, saudi arabia   \n",
      "Herfy                                                                                                                                                                                              هرفي, herfyfsc, يورو2024, هرفي يورو2024, يورو2024 euro2024, euro2024, هرفيxسوبرمان هرفي   \n",
      "Hindamme                                                                                                                                                                                                    designer, saudi, moekhoja, saudi designer, mohammed, founder, fashion designer   \n",
      "Jarir Bookstore                                                                                                                                                                                                          offers, ksa, deals, deals offers, ksadeals, ksaoffers, offersinme   \n",
      "KSA Anime                                                                                                                                                                                                        onepiece, انمي, figures, onepiece figures, ون_بيس onepiece, anime, العراق   \n",
      "KSA One Piece                                                                                                                                                                                                                  كرانشي رول, كرانشي, تقييما, رول, يحصل المركز, بـ, سنة كاملة   \n",
      "Kudu                                                                                                                                                                                                               saudi, fastfood, chain, saudi fastfood, fastfood chain, abraaj, sources   \n",
      "Lazurde                                                                                                                                                                                                saudi, arabia, saudi arabia, jewelry, apply, arabia apply, lazurde_injoy lolo222811   \n",
      "Mall of Arabia                                                                                                                                                                                                              arabia cairo, cairo, lt3, arabia, mall arabia, mall, مول العرب   \n",
      "Mikyajy                                                                                                                                                                                                                             saudi, collection, get, saudi riyadh, riyadh, buy, new   \n",
      "NADEC                                                                                                                                                                   agricultural, national, national agricultural, development, agricultural development, development company, company   \n",
      "Nada Dairy                                                                                                                                                                                                                         sales, job, saudi, salesman, van, arabia, openings nada   \n",
      "Nahdi                                                                                                                                                                                                                   عروض, عروض صيدلية, الأسبوعية, الموافق, 2024, صيدلية, صيدلية النهدي   \n",
      "PureGym KSA                                                                                                                                                                                                  arabia, darrengrimes_, saudi arabia, darrengrimes_ puregym, saudi, dont, live   \n",
      "Qormuz                                                                                                                                                                                                                               رمز, فيها, الثميري, رمز الثميري, المحل, smalied, قرمز   \n",
      "Razan Alazzouni                                                                                                                                                                                               التجارية, السعودية رزان, الأعمال, الموضة والأزياء, الموضة, والأزياء, علامتها   \n",
      "Red Sea Mall                                                                                                                                                                                                             mall رد, redseamallksa, مول redseamallksa, others, بس, جدة, والله   \n",
      "Riyadh Park Mall                                                                                                                                                                                                      الحين, احجز, موسم_الرياض, عيشها, ايماجينيشن_بارك, منطقة, الحين عيشها   \n",
      "SACO                                                                                                                                                                                                                         saco_ksa, ساكو, افحصي, مبكرا, سرطان, سرطان الثدي, افحصي مبكرا   \n",
      "Saudia Dairy (SADAFCO)                                                                                                                                                                                                                وظائف, لحملة, مبيعات, جدة, شركة سدافكو, شركة, الطائف   \n",
      "Sunbulah Group                                                                                                                                          sunbulah_group, saudi__platform sunbulah_group, saudi__platform, specialist sunbulah, specialist, recruitment specialist, sunbulah   \n",
      "Tamr                                                                                                                                                                                                                                     arabic, used, rutab, رطب, unripe dates, تمر, soft   \n",
      "The Dropped Collection                                                                                                                                                                                                   token, following, nft, fan token, nft collection, fan, collection   \n",
      "eXtra                                                                                                                                                                                                                               تسري, اكسترا, اكسترا oman, oman, cup, إضافي, super cup   \n",
      "APOA                                                                                                                                                                                                                                                                                   NaN   \n",
      "Al Romansiah                                                                                                                                                                                                                                                                           NaN   \n",
      "Dania Shinkar                                                                                                                                                                                                                                                                          NaN   \n",
      "Mama Noura                                                                                                                                                                                                                                                                             NaN   \n",
      "Panda                                                                                                                                                                                                                                                                                  NaN   \n",
      "Rani                                                                                                                                                                                                                                                                                   NaN   \n",
      "Torba Studio                                                                                                                                                                                                                                                                           NaN   \n",
      "\n",
      "                                                                                                                                                                                                                                                                  Topic 3  \\\n",
      "\\n    # Copied from the log where errors started\\n    \"Al-Nassr\": \"Al Nassr OR النصر\",\\n    \"Al-Ittihad\": \"Al Ittihad OR الاتحاد\",\\n    \"Al-Ahli\": ...                                                sleysla, سليسلة, saud, saudi_heritage, saudi, handmade, handicrafts   \n",
      "Abadia                                                                                                                                                                                          brands, saudi fashion, saudi, fashion, fashion label, spotlight, artisans   \n",
      "Abdul Samad Al Qurashi                                                                                                                                                                                   عبدالصمد القرشي, القرشي, عبدالصمد, لحملة, العطور, جميع, السعودية   \n",
      "Al Nakheel Mall                                                                                                                                                                                                                 الرياض, مدينة, يوم, 24, قهوة, إلى, الدمام   \n",
      "Al Rabie                                                                                                                                                                              life, decision extradite, saudi, extradite saudi, extradite, saudi citizen, citizen   \n",
      "Al-Ahli                                                                                                                                                                                                al, ahli, al ahli, alahli, ahlicentral, alahli ahlicentral, league   \n",
      "Al-Hilal                                                                                                                                                                                          الاتحاد_الهلال, الاتحاد, تذكرة, والهلال, مربع, الاتحاد والهلال, لمباراة   \n",
      "Al-Ittihad                                                                                                                                                                                      الف, مبروك, الاتحاد الهلال, الف مبروك, دوري_روشن_السعودي, الف الف, النادي   \n",
      "Al-Nassr                                                                                                                                                                                               goals, 950, career goals, 950 career, career, goals al, pro league   \n",
      "Al-Othaim Markets                                                                                                                                                                                   ٢٠١٩ استمتع, بالتسوق عروض, نون, استمتع بالتسوق, بالتسوق, استمتع, ٢٠١٩   \n",
      "Almarai                                                                                                                                                                                                   saudi, saudi arabia, arabia, job, apply, openings, job openings   \n",
      "Almunajem Foods                                                                                                                                                                                   q1, revenue, public, almunajem foods, saudi arabias, arabias, announces   \n",
      "Arabian Oud                                                                                                                                                                    اهديه, _للعود, arabian_oud اهديه, _تهديك, العربية_للعود_تهديك, العربيه _للعود, arabian_oud   \n",
      "Bayara                                                                                                                                                                                             maker, snack, saudi arabian, snack maker, arabian, savola, 260 million   \n",
      "BinDawood                                                                                                                                                                                                      رابط العرض, رابط, العرض, صفحة, صفحة واحدة, عروض داود, داود   \n",
      "Body Masters                                                                                                                                                                                                          صدر, جد منطقة, جد, منطقة, مكة, منطقة مكة, ماسترز جد   \n",
      "Camel Step                                                                                                                                                                                                   camel_step, خطوة, جمل, خطوة جمل, camel, خطوة_جمل, camel step   \n",
      "Charmaleena                                                                                                                                                                                        saudi, jeddah, riyadh, ksa, jeddah riyadh, jewellery jeddah, saudi ksa   \n",
      "DHAD                                                                                                                                                                                                                  ضاد, dhad_sa ضاد, الناس, dhad_sa, الصوم, ولم, الفرق   \n",
      "Fanatics                                                                                                                                                                                             football, flag football, flag, classic, football classic, brady, tom   \n",
      "Fitness Time                                                                                                                                                  وقت_اللياقة, fitness_time, وقت اللياقه, اللياقه, وقت_اللياقة fitness_time, وقت_اللياقة fitness, وقت_اللياقه   \n",
      "Goody                                                                                                                                                                                         منتجات, منتجات قودي, products, bahrain, consumer, البحرين, products bahrain   \n",
      "Hasawi                                                                                                                                                                                                              حساوي, aal_hasawi, هههههه, بس, والله, ولا, hasawi_313   \n",
      "Herfy                                                                                                                                                   الكنز, بوليفارد_رن_واي بوليفارد_وورلد, وندر_جاردن, وندر_جاردن riyadhseason, موسم_الریاض, بوليفارد_وورلد, الوناسبه   \n",
      "Hindamme                                                                                                                                                                               driving jacket, jacket, driving, victoria, victoria albert, londons, albert museum   \n",
      "Jarir Bookstore                                                                                                                                                                           jarir, bookstore, jarir bookstore, saudi, saudi arabia, arabia, bookstore saudi   \n",
      "KSA Anime                                                                                                                                                                                                الأنمي, انمي, قادم, السينما, anime, انمي anime, السينما السعودية   \n",
      "KSA One Piece                                                                                                                                                                        608 تحميل, بيس 608, مترجمة one, تحميل مترجمة, 608, piece khaledalhrbi, السعودية انمي   \n",
      "Kudu                                                                                                                                                                                         food, investment, says, completes, completes investment, saudis, abraaj says   \n",
      "Lazurde                                                                                                                                                                                                       saudi, maker, listing, regulator, gets regulator, nod, gets   \n",
      "Mall of Arabia                                                                                                                                                                                    اسمه, اسمه mall, mall 3arabya, 3arabya, هتدوسك, هتدوسك بعون, 3arabya دي   \n",
      "Mikyajy                                                                                                                                                                                                                مكياجي, مكياج, منتجات, هدايا, أفضل, المفضلة, احصلي   \n",
      "NADEC                                                                                                                                                                          saudis, saudis agrees, agrees acquire, competitor, dairy competitor, agrees, acquire dairy   \n",
      "Nada Dairy                                                                                                                                                                                   saudi, arabia, saudi arabia, technician, dairy saudi, years exp, arabia nada   \n",
      "Nahdi                                                                                                                                                                                                    حي, النهدى, pharmacy صيدليه, صيدليه النهدى, صيدليه, بك, pharmacy   \n",
      "PureGym KSA                                                                                                                                                                                                بيورجيم, puregymarabia, إلى, بنا, الخاص, الخاص بنا, puregymksa   \n",
      "Qormuz                                                                                                                                                                                                                    قرمز, رمز, القلب, هدية, بس, حبيب, wejdanfashion   \n",
      "Razan Alazzouni                                                                                                                                                                               razanalazzouni, الأزياء, مجموعة, رزان_العزوني, علامة, razan alazzouni, مجلة   \n",
      "Red Sea Mall                                                                                                                                                                                                                        mall رد, like, عزك, ال, نفسك, ذا, الف   \n",
      "Riyadh Park Mall                                                                                                                                                                                                                بارك, لكم, riyadh, مول, park, mall, صباحا   \n",
      "SACO                                                                                                                                                                                 saudi, hardware, company, saudi company, saudi hardware, retailer, hardware retailer   \n",
      "Saudia Dairy (SADAFCO)                                                                                                                                                                     sadafco, talent, jeddah, kingdom saudi, kingdom, talent sadafco, arabia jeddah   \n",
      "Sunbulah Group                                                                                                                                                    technical packaging, technical, جامعة_الملك_فهد_للبترول_والمعادن, تشارك, packaging, اليوم_المفتوح, jobs   \n",
      "Tamr                                                                                                                                                                                                            arabic تمر, food, dates arabic, middle, arabic, تمر, made   \n",
      "The Dropped Collection                                                                                                                                                            387 tuesday, following, argentinas, arabias nft, saudi arabia, increased 387, argentina   \n",
      "eXtra                                                                                                                                                                             العراق, اكسترا_عراق, بنسبة, extra_iraq, اكسترا_عراق extra_iraq, اخبار, extra_iraq اخبار   \n",
      "APOA                                                                                                                                                                                                                                                                  NaN   \n",
      "Al Romansiah                                                                                                                                                                                                                                                          NaN   \n",
      "Dania Shinkar                                                                                                                                                                                                                                                         NaN   \n",
      "Mama Noura                                                                                                                                                                                                                                                            NaN   \n",
      "Panda                                                                                                                                                                                                                                                                 NaN   \n",
      "Rani                                                                                                                                                                                                                                                                  NaN   \n",
      "Torba Studio                                                                                                                                                                                                                                                          NaN   \n",
      "\n",
      "                                                                                                                                                                                                                                                  Topic 4  \\\n",
      "\\n    # Copied from the log where errors started\\n    \"Al-Nassr\": \"Al Nassr OR النصر\",\\n    \"Al-Ittihad\": \"Al Ittihad OR الاتحاد\",\\n    \"Al-Ahli\": ...                                     saudi, ksa, sleysla, hand_made, saudi_brand, beautiful, modern   \n",
      "Abadia                                                                                                                                                                          heritage, sustainable, giving, craftsmanship, saudi arabia, arabia, women   \n",
      "Abdul Samad Al Qurashi                                                                                                                                                                       جميع, المملكة, السابق, لحملة, الوظائف وظائف, السعودية, الصحف   \n",
      "Al Nakheel Mall                                                                                                                                                                                  يوم, paul, اني, الرياض, nakheel mall, riyadh, al nakheel   \n",
      "Al Rabie                                                                                                                                                                                     الربيع, السعودية, موقع, عصير, عصير الربيع, صحة_للجميع, تطبيق   \n",
      "Al-Ahli                                                                                                                                                                          الاهلي, الأهلي, الإمارات_اليوم, as21_al, al_casber, شباب الأهلي, المنتصف   \n",
      "Al-Hilal                                                                                                                                                                                          al, hilal, al hilal, saudi, league, ittihad, al ittihad   \n",
      "Al-Ittihad                                                                                                                                                                الاتحاد, الاتحاد_الهلال, الهلال, الهلال_الاتحاد, جمهور, جمهور الاتحاد, المباراة   \n",
      "Al-Nassr                                                                                                                                                                                                 النصر, النصر يلعب, يلعب, ولا, هدف, الاتحاد, ماني   \n",
      "Al-Othaim Markets                                                                                                                                                                                 المتمم, عروض العثيم, اخر, اخر عروض, عروض, عروض ركن, ركن   \n",
      "Almarai                                                                                                                                                                           egypt, ksa, thailand, egypt thailand, uae egypt, ksa uae, vacancies ksa   \n",
      "Almunajem Foods                                                                                                                                                             initial, initial public, public offering, offering, public, main, main market   \n",
      "Arabian Oud                                                                                                                                                                           منتجات العربية, منتجات, حول العالم, حول, فرع حول, المتاجر لك, وأقرب   \n",
      "Bayara                                                                                                                                                                        food giant, food, uaes holding, acquires uaes, giant, holding, giant savola   \n",
      "BinDawood                                                                                                                                                                                   الموافق, عروض داود, داود, الأسبوعية, 1446, 2025 الموافق, 2025   \n",
      "Body Masters                                                                                                                                                                                             ماسترز body, قبل, riyadh, والله, خصم, انقطاع, 40   \n",
      "Camel Step                                                                                                                                                                                خطوة_جمل, coffee, camel_step, camel, step, camel step, خطوة جمل   \n",
      "Charmaleena                                                                                                                                                  designer, saudi jewellery, saudi, ksa, jeddah, charmaleenajewellery شارمالينا, mycharmaleena   \n",
      "DHAD                                                                                                                                                    dhad_sa, فوازير_ضاد, كتاب, جاوبوها_صح, فوازير_ضاد جاوبوها_صح, dhad_sa فوازير_ضاد, جاوبوها_صح كتاب   \n",
      "Fanatics                                                                                                                                                                             wwe, arena, kingdom, kingdom arena, 21 kingdom, arena riyadh, riyadh   \n",
      "Fitness Time                                                                                                                                                                                رياضة, مميزه, مفروشه, شقق, مفروشه مميزه, عرعر_مول, شقق مفروشه   \n",
      "Goody                                                                                                                                                                                        قودي, تطبيق, مطبخ, مطبخ قودي, goodykitchen, مجلة, تطبيق مطبخ   \n",
      "Hasawi                                                                                                                                                                          حساوي_ديل, عالمية, عالمية بلهجة, لعبة عالمية, حساوي_ديل لعبة, لعبة, بلهجة   \n",
      "Herfy                                                                                                                                                                                               saudi, chain, food, saudi arabia, arabia, fast, world   \n",
      "Hindamme                                                                                                                                                                                        collection, west, alula, saudi, saudibased, brand, latest   \n",
      "Jarir Bookstore                                                                                                                                                                     وظائف, الثانوية, لحملة الثانوية, لحملة, تعلن, jarir_bookstore, الرياض   \n",
      "KSA Anime                                                                                                                                                                                                  الحلقة, ささ恋, saudi, مانجا, أنمي, اوتاكو, anime   \n",
      "KSA One Piece                                                                                                                                                                         مانجا, قطر مصر, السعوديه, مصر الجزائر, الجزائر, الكويت قطر, البحرين   \n",
      "Kudu                                                                                                                                                                                   هلا_باللذيذ, وجبة, كودو, 920006999, اليومية, التوصيل, خدمة التوصيل   \n",
      "Lazurde                                                                                                                                                                              لزوردي, elissakh, lazurde_injoy, السعودية, جدوى_الخبر, تداول, awalan   \n",
      "Mall of Arabia                                                                                                                                                                                          جدة, علي, جدة مول, مول_العرب, 7d, سينما 7d, سينما   \n",
      "Mikyajy                                                                                                                                                                                              saudi, makeup, الحب, رمضان, حياة_مول, مجموعة, مكياجي   \n",
      "NADEC                                                                                                                                                                                              saudi, arabia, saudi arabia, jobs, food, danone, dairy   \n",
      "Nada Dairy                                                                                                                                                                                      ندى, nadadairy, ندى nada, والطعم, عيشوا أجمل, ومذاق, أجمل   \n",
      "Nahdi                                                                                                                                                                                          السعودية, النهدي, عروض, صيدلية, صيدلية النهدي, جدة, الرياض   \n",
      "PureGym KSA                                                                                                                                                                               saudi, gym, puregym saudi, arabian, got, opening, saudi arabian   \n",
      "Qormuz                                                                                                                                                                                                     إلى, saudi, قرمز, الفنان, محمد, سعودية, القطعة   \n",
      "Razan Alazzouni                                                                                                                                                       سعوديه, سعوديه وصلت, وصلت العالمية, العزوني سعوديه, razan alazzouni, العالمية, وصلت   \n",
      "Red Sea Mall                                                                                                                                                                                                mall رد, لمن, shopping, حبيت, love, بعض, time   \n",
      "Riyadh Park Mall                                                                                                                                                                   تذكرتك, احجز تذكرتك, عيشها, تذكرتك عيشها, تجربة, ايماجينيشن_بارك, احجز   \n",
      "SACO                                                                                                                                                                                                 saudi, today, news, الفحص, الفحص المبكر, top, riyadh   \n",
      "Saudia Dairy (SADAFCO)                                                                                                                                                           وظائف, سدافكو, السعودية, تعلن, والأغذية سدافكو, الشركة السعودية, التقديم   \n",
      "Sunbulah Group                                                                                                                                                                              group, sunbulah, sunbulah group, saudi, manager, jobs, arabia   \n",
      "Tamr                                                                                                                                                                                              like, unripe, ramadan, arabia, ripe, unripe dates, date   \n",
      "The Dropped Collection                                                                                                                                                         21, argentina, argentinas fan, nft collection, win, win argentina, tuesday   \n",
      "eXtra                                                                                                                                                                                                saudi, arabia, saudi arabia, money, like, would, oil   \n",
      "APOA                                                                                                                                                                                                                                                  NaN   \n",
      "Al Romansiah                                                                                                                                                                                                                                          NaN   \n",
      "Dania Shinkar                                                                                                                                                                                                                                         NaN   \n",
      "Mama Noura                                                                                                                                                                                                                                            NaN   \n",
      "Panda                                                                                                                                                                                                                                                 NaN   \n",
      "Rani                                                                                                                                                                                                                                                  NaN   \n",
      "Torba Studio                                                                                                                                                                                                                                          NaN   \n",
      "\n",
      "                                                                                                                                                                                                                                                             Topic 5  \\\n",
      "\\n    # Copied from the log where errors started\\n    \"Al-Nassr\": \"Al Nassr OR النصر\",\\n    \"Al-Ittihad\": \"Al Ittihad OR الاتحاد\",\\n    \"Al-Ahli\": ...                                            women, support, tools support, tools, traditional, saudi, products   \n",
      "Abadia                                                                                                                                                                                       saudi, fashion, saudi fashion, scene, founder, international, spotlight   \n",
      "Abdul Samad Al Qurashi                                                                                                                                                                                  samad al, samad, qurashi, al, al qurashi, abdul samad, abdul   \n",
      "Al Nakheel Mall                                                                                                                                                                                                     الدمام, مجمع, منتجات, مول الدمام, العمل, ولا, بس   \n",
      "Al Rabie                                                                                                                                                                                                      saudi, saudi arabia, arabia, al, rabie, al rabie, jobs   \n",
      "Al-Ahli                                                                                                                                                                                                       الاهلي, الأهلي, الهلال, مباراة, دوري, الغرافة, الاتحاد   \n",
      "Al-Hilal                                                                                                                                                         player, aldawsari, salem, الهلال, salem aldawsari, afc, الهلال_البوليس_الكيني البوليس_الكيني_الهلال   \n",
      "Al-Ittihad                                                                                                                                                                                                       al, vs, ittihad, al ittihad, al hilal, hilal, vs al   \n",
      "Al-Nassr                                                                                                                                                                   النصر_الحزم, للعالمي, للعالمي النصر_الحزم, الفوز, النصر_الحزم كاريزما86, كاريزما86, النصر   \n",
      "Al-Othaim Markets                                                                                                                                                                             وظائف, شركة, عبدالله, شركة أسواق, أسواق عبدالله, عبدالله العثيم, وظيفة   \n",
      "Almarai                                                                                                                                                                                                       dairy, saudi, company, milk, largest, million, billion   \n",
      "Almunajem Foods                                                                                                                                                              almunajem foods, food, saudi food, saudi arabia, largest, arabias largest, private food   \n",
      "Arabian Oud                                                                                                                                                       عطر, العربية_للعود, arabianoud, طيبنا_من_طيبكم العربية_للعود, طيبنا_من_طيبكم, arabian, arabian oud   \n",
      "Bayara                                                                                                                                                                                                     food, uaes, savola_group, بايارا, saudi food, saudi, 260m   \n",
      "BinDawood                                                                                                                                                                                         وحتي, داود الفترة, bin, dawood, bin dawood, الفترة, الرابط بن_داود   \n",
      "Body Masters                                                                                                                                                                                                 masters بودي, يوم, اجل, افضل, photo, ماسترز photo, حياة   \n",
      "Camel Step                                                                                                                                                                                                      جمل, خطوة, خطوة جمل, step, camel step, camel, coffee   \n",
      "Charmaleena                                                                                                                                             charmaleenajewellery, charmaleenajewellery شارمالينا, mycharmaleena, شارمالينا, jeddah, ksa, saudi jewellery   \n",
      "DHAD                                                                                                                                                                                                   saudi, arabia, saudi arabia, اللغة_العربية, عربي, iran, yemen   \n",
      "Fanatics                                                                                                                                                                                                  saudi, arabia, saudi arabia, religious, iran, israel, dont   \n",
      "Fitness Time                                                                                                                                                                         وقـت, وقـت اللـياقة, اللـياقة, time وقـت, الالكتروني, موقعنا, موقعنا الالكتروني   \n",
      "Goody                                                                                                                                                                                                               saudi, arabia, saudi arabia, oh, like, food, get   \n",
      "Hasawi                                                                                                                                                                                                             saudi, ديل, حساوي ديل, لعبة, بلهجة, حساوي, متوفره   \n",
      "Herfy                                                                                                                                                                                                 كاس_العالم_2034, ليس, سعوديا, ليس سعوديا, herfyfsc, الم, ستحيل   \n",
      "Hindamme                                                                                                                                                                            fashion, saudi, wrth_ksa, aramfashion, saudi fashion, fashion brand, miskartinst   \n",
      "Jarir Bookstore                                                                                                                                                                                            عرض, المتمم, جرير, عرض مكتبة, مكتبة جرير, مكتبة, الثلاثاء   \n",
      "KSA Anime                                                                                                                                                                                        animekey, جوبلن_سلاير, goblinslayer, انمى_كى, الثاني, anime, اوتاكو   \n",
      "KSA One Piece                                                                                                                                                                                            607, مساء, مساء بتوقيت, بتوقيت, بتوقيت السعودية, الساعة, ضد   \n",
      "Kudu                                                                                                                                                                                                          كودو, kuduksa, مطعم, وظائف, مطاعم, المملكة, مطاعم كودو   \n",
      "Lazurde                                                                                                                                                                                                uae, expansion, jeddah, first saudi, saudi, title, park hyatt   \n",
      "Mall of Arabia                                                                                                                                                                                mall_of_arabia, مول_العرب, إلى, الفنان, العرب مول, مول العرب, العالمية   \n",
      "Mikyajy                                                                                                                                                                             arabia, saudi arabia, saudi, رمضان_كريم, ramadankareem, رمضان, رمضان_كريم مكياجي   \n",
      "NADEC                                                                                                                                                                                                              نادك, شركة, شركة نادك, بالتوظيف, تدريب, تعلن, فتح   \n",
      "Nada Dairy                                                                                                                                                                                                  al, dairy saudi, technician, saudi, jobs, ندى nada, food   \n",
      "Nahdi                                                                                                                                                                                              nahdihope, صيدلية, صيدلية النهدي, النهدي, pharmacy, جدة, السعودية   \n",
      "PureGym KSA                                                                                                                                                                        services puregymarabia, puregym gym, ambitions, hiring, middle east, years, والذي   \n",
      "Qormuz                                                                                                                                                                                                        قرمز, smalied, قرمز smalied, السعودية, وش, براند, نادي   \n",
      "Razan Alazzouni                                                                                                                                                                                            مجموعة, رزان العزوني, العزوني, رزان, سة, المملكة, علامتها   \n",
      "Red Sea Mall                                                                                                                                                                                      jeddah, makkah, jeddah makkah, مول jeddah, mall رد, رد_سي_مول, جده   \n",
      "Riyadh Park Mall                                                                                                                                                                                          بارك, رياض, الرياض, رياض بارك, الرياض بارك, بارك مول, افضل   \n",
      "SACO                                                                                                                                                                                                                    ساكو, عروض, جدة, جدة ساكو, عروض جدة, sr, إلى   \n",
      "Saudia Dairy (SADAFCO)                                                                                                                                                                             سعودية, الألبان, شركة, التالية, sadafco_, منتجات, لمنتجات الألبان   \n",
      "Sunbulah Group                                                                                                                                                                                              مجموعة, مجموعة السنبلة, السنبلة, تعلن, جدة, وظيفة, وظائف   \n",
      "Tamr                                                                                                                                                                                                   saudi, saudi arabia, arabia, traditional, made, arabian, like   \n",
      "The Dropped Collection                                                                                                                                                                       arabia, saudi arabia, collection, nft, nft collection, 21 past, past 24   \n",
      "eXtra                                                                                                                                                                                                           اكسترا, عروض, 2025, 10, السعودية, عروض اكسترا, العرض   \n",
      "APOA                                                                                                                                                                                                                                                             NaN   \n",
      "Al Romansiah                                                                                                                                                                                                                                                     NaN   \n",
      "Dania Shinkar                                                                                                                                                                                                                                                    NaN   \n",
      "Mama Noura                                                                                                                                                                                                                                                       NaN   \n",
      "Panda                                                                                                                                                                                                                                                            NaN   \n",
      "Rani                                                                                                                                                                                                                                                             NaN   \n",
      "Torba Studio                                                                                                                                                                                                                                                     NaN   \n",
      "\n",
      "                                                                                                                                                                   Info  \n",
      "\\n    # Copied from the log where errors started\\n    \"Al-Nassr\": \"Al Nassr OR النصر\",\\n    \"Al-Ittihad\": \"Al Ittihad OR الاتحاد\",\\n    \"Al-Ahli\": ...              NaN  \n",
      "Abadia                                                                                                                                                              NaN  \n",
      "Abdul Samad Al Qurashi                                                                                                                                              NaN  \n",
      "Al Nakheel Mall                                                                                                                                                     NaN  \n",
      "Al Rabie                                                                                                                                                            NaN  \n",
      "Al-Ahli                                                                                                                                                             NaN  \n",
      "Al-Hilal                                                                                                                                                            NaN  \n",
      "Al-Ittihad                                                                                                                                                          NaN  \n",
      "Al-Nassr                                                                                                                                                            NaN  \n",
      "Al-Othaim Markets                                                                                                                                                   NaN  \n",
      "Almarai                                                                                                                                                             NaN  \n",
      "Almunajem Foods                                                                                                                                                     NaN  \n",
      "Arabian Oud                                                                                                                                                         NaN  \n",
      "Bayara                                                                                                                                                              NaN  \n",
      "BinDawood                                                                                                                                                           NaN  \n",
      "Body Masters                                                                                                                                                        NaN  \n",
      "Camel Step                                                                                                                                                          NaN  \n",
      "Charmaleena                                                                                                                                                         NaN  \n",
      "DHAD                                                                                                                                                                NaN  \n",
      "Fanatics                                                                                                                                                            NaN  \n",
      "Fitness Time                                                                                                                                                        NaN  \n",
      "Goody                                                                                                                                                               NaN  \n",
      "Hasawi                                                                                                                                                              NaN  \n",
      "Herfy                                                                                                                                                               NaN  \n",
      "Hindamme                                                                                                                                                            NaN  \n",
      "Jarir Bookstore                                                                                                                                                     NaN  \n",
      "KSA Anime                                                                                                                                                           NaN  \n",
      "KSA One Piece                                                                                                                                                       NaN  \n",
      "Kudu                                                                                                                                                                NaN  \n",
      "Lazurde                                                                                                                                                             NaN  \n",
      "Mall of Arabia                                                                                                                                                      NaN  \n",
      "Mikyajy                                                                                                                                                             NaN  \n",
      "NADEC                                                                                                                                                               NaN  \n",
      "Nada Dairy                                                                                                                                                          NaN  \n",
      "Nahdi                                                                                                                                                               NaN  \n",
      "PureGym KSA                                                                                                                                                         NaN  \n",
      "Qormuz                                                                                                                                                              NaN  \n",
      "Razan Alazzouni                                                                                                                                                     NaN  \n",
      "Red Sea Mall                                                                                                                                                        NaN  \n",
      "Riyadh Park Mall                                                                                                                                                    NaN  \n",
      "SACO                                                                                                                                                                NaN  \n",
      "Saudia Dairy (SADAFCO)                                                                                                                                              NaN  \n",
      "Sunbulah Group                                                                                                                                                      NaN  \n",
      "Tamr                                                                                                                                                                NaN  \n",
      "The Dropped Collection                                                                                                                                              NaN  \n",
      "eXtra                                                                                                                                                               NaN  \n",
      "APOA                                                                                                                                                    Not enough data  \n",
      "Al Romansiah                                                                                                                                            Not enough data  \n",
      "Dania Shinkar                                                                                                                                           Not enough data  \n",
      "Mama Noura                                                                                                                                              Not enough data  \n",
      "Panda                                                                                                                                                   Not enough data  \n",
      "Rani                                                                                                                                                    Not enough data  \n",
      "Torba Studio                                                                                                                                            Not enough data  \n",
      "\n",
      "--- Topic Modeling Complete ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Phase 3b - Topic Modeling with LDA\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "print(\"--- Phase 3b: Topic Modeling (LDA) ---\")\n",
    "\n",
    "# --- Configuration ---\n",
    "NUM_TOPICS = 5 # How many topics to try and find per brand\n",
    "NUM_TOP_WORDS = 7 # How many top words to display for each topic\n",
    "\n",
    "# --- Prepare Stopwords ---\n",
    "print(\"Preparing stopwords...\")\n",
    "try:\n",
    "    stop_words_en = list(stopwords.words('english'))\n",
    "    # Consider using a more extensive Arabic list if results are poor\n",
    "    stop_words_ar = [\"من\", \"في\", \"على\", \"الى\", \"عن\", \"و\", \"يا\", \"اي\", \"ما\", \"هو\", \"هي\",\n",
    "                     \"هذا\", \"هذه\", \"ذلك\", \"تلك\", \"ان\", \"او\", \"كل\", \"لا\", \"لن\", \"لم\",\n",
    "                     \"تم\", \"قد\", \"مع\", \"به\", \"له\", \"فيه\", \"عليها\", \"اليها\", \"عنه\",\n",
    "                     \"ايضا\", \"كان\", \"يكون\", \"صلى\", \"عليه\", \"وسلم\", \"قال\", \"ص\", \"ع\",\n",
    "                     \"ريال\", \"سعودي\", \"انا\", \"انت\", \"هم\", \"هن\", \"نحن\", \"اليوم\", \"جدا\",\n",
    "                     \"الله\", \"بن\", \"تم\", \"اللي\", \"الي\", \"حتى\", \"التي\", \"الذي\", \"بعد\",\n",
    "                     \"هنا\", \"هناك\", \"عند\", \"خلال\", \"فقط\", \"إذا\", \"كيف\", \"متى\", \"أين\",\n",
    "                     \"بين\", \"تحت\", \"فوق\", \"ثم\", \"حين\", \"الآن\"] # Added more Arabic stopwords\n",
    "    stop_words_combined = stop_words_en + stop_words_ar\n",
    "\n",
    "    # Add brand names (lowercase) to stopwords\n",
    "    if 'df_tweets' in locals() and not df_tweets.empty:\n",
    "        brand_names_lower = [str(name).lower() for name in df_tweets['brand_name'].unique()]\n",
    "        # Add variations if needed (e.g., alhilal, al-hilal)\n",
    "        stop_words_combined.extend(brand_names_lower)\n",
    "        # Add common social media/URL artifacts\n",
    "        stop_words_combined.extend(['rt', 'amp', 'co', 'https', 'http', 'www', 'com'])\n",
    "        print(f\"   Using {len(stop_words_combined)} combined stopwords.\")\n",
    "    else:\n",
    "        print(\"   WARNING: df_tweets not found, cannot add brand names to stopwords.\")\n",
    "        stop_words_combined.extend(['rt', 'amp', 'co', 'https', 'http', 'www', 'com'])\n",
    "\n",
    "\n",
    "except LookupError:\n",
    "    print(\"   ERROR: NLTK stopwords not found. Please run the previous cell to download them.\")\n",
    "    stop_words_combined = [] # Use empty list to avoid crashing, but topics will be poor\n",
    "\n",
    "\n",
    "# --- Function to display topics ---\n",
    "def display_topics(model, feature_names, num_top_words):\n",
    "    topics = {}\n",
    "    print(\"   Discovered Topics:\")\n",
    "    for topic_idx, topic_weights in enumerate(model.components_):\n",
    "        # Ensure indices are within bounds\n",
    "        valid_indices = topic_weights.argsort()[:-num_top_words - 1:-1]\n",
    "        valid_indices = [i for i in valid_indices if i < len(feature_names)] # Safety check\n",
    "        top_words = [feature_names[i] for i in valid_indices]\n",
    "\n",
    "        topic_key = f\"Topic {topic_idx+1}\"\n",
    "        topics[topic_key] = \", \".join(top_words)\n",
    "        print(f\"     {topic_key}: {topics[topic_key]}\")\n",
    "    return topics\n",
    "\n",
    "# --- Perform LDA for each Brand ---\n",
    "brand_topics = {}\n",
    "\n",
    "if 'df_tweets' in locals() and not df_tweets.empty and 'cleaned_content' in df_tweets.columns and stop_words_combined:\n",
    "    print(\"\\nProcessing topics for each brand...\")\n",
    "    # Group by brand\n",
    "    for brand_name, group_df in df_tweets.groupby('brand_name'):\n",
    "        print(f\"\\n--- Topics for: {brand_name} ---\")\n",
    "\n",
    "        # Filter out very short or empty tweets\n",
    "        texts = group_df['cleaned_content'][group_df['cleaned_content'].str.strip().str.len() > 15].tolist() # Increased min length\n",
    "\n",
    "        if len(texts) < NUM_TOPICS * 2 : # Need sufficient documents relative to topics\n",
    "            print(f\"   Skipping {brand_name}: Not enough sufficiently long tweets (found {len(texts)}) for reliable LDA.\")\n",
    "            brand_topics[brand_name] = {\"Info\": \"Not enough data\"}\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # 1. Vectorize\n",
    "            vectorizer = TfidfVectorizer(max_df=0.90, min_df=3, stop_words=stop_words_combined, max_features=1000, ngram_range=(1,2)) # Added ngrams\n",
    "            tfidf = vectorizer.fit_transform(texts)\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "            # Check if vectorization produced features\n",
    "            if tfidf.shape[1] == 0:\n",
    "                 print(f\"   Skipping {brand_name}: No features found after vectorization (check stopwords/text).\")\n",
    "                 brand_topics[brand_name] = {\"Error\": \"No features found\"}\n",
    "                 continue\n",
    "\n",
    "            # 2. Apply LDA\n",
    "            lda = LatentDirichletAllocation(n_components=NUM_TOPICS, max_iter=15, # Increased iterations\n",
    "                                            learning_method='online',\n",
    "                                            learning_offset=50.,\n",
    "                                            random_state=42)\n",
    "            lda.fit(tfidf)\n",
    "\n",
    "            # 3. Display and store topics\n",
    "            brand_topics[brand_name] = display_topics(lda, feature_names, NUM_TOP_WORDS)\n",
    "\n",
    "        except ValueError as ve:\n",
    "             print(f\"   Skipping {brand_name}: ValueError during vectorization/LDA - {ve}\")\n",
    "             brand_topics[brand_name] = {\"Error\": f\"ValueError: {ve}\"}\n",
    "        except Exception as e:\n",
    "            print(f\"   Skipping {brand_name}: An unexpected error occurred during LDA - {e}\")\n",
    "            brand_topics[brand_name] = {\"Error\": f\"Unexpected error: {e}\"}\n",
    "\n",
    "    # Optional: Convert results to a DataFrame\n",
    "    df_brand_topics = pd.DataFrame.from_dict(brand_topics, orient='index')\n",
    "    # Make topics easier to read in DataFrame display\n",
    "    pd.set_option('display.max_colwidth', 150)\n",
    "    print(\"\\n\\n--- Brand Topics Summary ---\")\n",
    "    print(df_brand_topics)\n",
    "\n",
    "else:\n",
    "    print(\"   WARNING: df_tweets empty, missing 'cleaned_content', or stopwords failed. Cannot perform Topic Modeling.\")\n",
    "\n",
    "print(\"\\n--- Topic Modeling Complete ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1350cf",
   "metadata": {},
   "source": [
    "Visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc7d471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 4: Refined Data Visualization ---\n",
      "\n",
      "Generating Plot 1: Tweet Volume by Brand...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nayef Alam\\AppData\\Local\\Temp\\ipykernel_15664\\3324904178.py:19: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=df_sorted_hype, y='brand_name', x='tweet_volume', palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved plot as tweet_volume_by_brand_v3.png\n",
      "\n",
      "Generating Plot 2: Market Saturation (Amazon Products) by Brand...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nayef Alam\\AppData\\Local\\Temp\\ipykernel_15664\\3324904178.py:37: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=df_sorted_saturation, y='brand_name', x='market_saturation', palette='magma')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved plot as market_saturation_by_brand_v3.png\n",
      "\n",
      "Generating Plot 3: Tweet Volume vs. Market Saturation...\n",
      "   Saved plot as hype_vs_saturation_v3.png\n",
      "\n",
      "Generating Plot 4: Average Tweet Sentiment by Brand...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nayef Alam\\AppData\\Local\\Temp\\ipykernel_15664\\3324904178.py:120: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  barplot_sentiment = sns.barplot(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_15664\\3324904178.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    116\u001b[39m     \u001b[38;5;66;03m# Apply categorize function to main df for coloring this plot too\u001b[39;00m\n\u001b[32m    117\u001b[39m     df_sorted_sentiment[\u001b[33m'sentiment_category'\u001b[39m] = df_sorted_sentiment[\u001b[33m'avg_tweet_sentiment'\u001b[39m].apply(categorize_sentiment)\n\u001b[32m    118\u001b[39m     bar_colors = df_sorted_sentiment[\u001b[33m'sentiment_category'\u001b[39m].map(sentiment_colors)\n\u001b[32m    119\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     barplot_sentiment = sns.barplot(\n\u001b[32m    121\u001b[39m         data=df_sorted_sentiment,\n\u001b[32m    122\u001b[39m         y=\u001b[33m'brand_name'\u001b[39m,\n\u001b[32m    123\u001b[39m         x=\u001b[33m'avg_tweet_sentiment'\u001b[39m,\n",
      "\u001b[32mc:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\seaborn\\categorical.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, seed, units, weights, orient, color, palette, saturation, fill, hue_norm, width, dodge, gap, log_scale, native_scale, formatter, legend, capsize, err_kws, ci, errcolor, errwidth, ax, **kwargs)\u001b[39m\n\u001b[32m   2366\u001b[39m     hue_order = p._palette_without_hue_backcompat(palette, hue_order)\n\u001b[32m   2367\u001b[39m     palette, hue_order = p._hue_backcompat(color, palette, hue_order)\n\u001b[32m   2368\u001b[39m \n\u001b[32m   2369\u001b[39m     saturation = saturation \u001b[38;5;28;01mif\u001b[39;00m fill \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2370\u001b[39m     p.map_hue(palette=palette, order=hue_order, norm=hue_norm, saturation=saturation)\n\u001b[32m   2371\u001b[39m     color = _default_color(ax.bar, hue, color, kwargs, saturation=saturation)\n\u001b[32m   2372\u001b[39m \n\u001b[32m   2373\u001b[39m     agg_cls = WeightedAggregator \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"weight\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m p.plot_data \u001b[38;5;28;01melse\u001b[39;00m EstimateAggregator\n",
      "\u001b[32mc:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\seaborn\\_base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, palette, order, norm, saturation)\u001b[39m\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m map_hue(self, palette=\u001b[38;5;28;01mNone\u001b[39;00m, order=\u001b[38;5;28;01mNone\u001b[39;00m, norm=\u001b[38;5;28;01mNone\u001b[39;00m, saturation=\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m         mapping = HueMapping(self, palette, order, norm, saturation)\n\u001b[32m    839\u001b[39m         self._hue_map = mapping\n",
      "\u001b[32mc:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\seaborn\\_base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, plotter, palette, order, norm, saturation)\u001b[39m\n\u001b[32m    124\u001b[39m                 msg = \u001b[33m\"Ignoring `palette` because no `hue` variable has been assigned.\"\u001b[39m\n\u001b[32m    125\u001b[39m                 warnings.warn(msg, stacklevel=\u001b[32m4\u001b[39m)\n\u001b[32m    126\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    127\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m             map_type = self.infer_map_type(\n\u001b[32m    129\u001b[39m                 palette, norm, plotter.input_format, plotter.var_types[\u001b[33m\"hue\"\u001b[39m]\n\u001b[32m    130\u001b[39m             )\n\u001b[32m    131\u001b[39m \n",
      "\u001b[32mc:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\seaborn\\_base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, palette, norm, input_format, var_type)\u001b[39m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m infer_map_type(self, palette, norm, input_format, var_type):\n\u001b[32m    206\u001b[39m         \u001b[33m\"\"\"Determine how to implement the mapping.\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m palette \u001b[38;5;28;01min\u001b[39;00m QUAL_PALETTES:\n\u001b[32m    208\u001b[39m             map_type = \u001b[33m\"categorical\"\u001b[39m\n\u001b[32m    209\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m norm \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    210\u001b[39m             map_type = \u001b[33m\"numeric\"\u001b[39m\n",
      "\u001b[32mc:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1578\u001b[39m     @final\n\u001b[32m   1579\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __nonzero__(self) -> NoReturn:\n\u001b[32m-> \u001b[39m\u001b[32m1580\u001b[39m         raise ValueError(\n\u001b[32m   1581\u001b[39m             f\"The truth value of a {type(self).__name__} is ambiguous. \"\n\u001b[32m   1582\u001b[39m             \u001b[33m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[39m\n\u001b[32m   1583\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 5: Phase 4 - Refined Visualization (Style Fix)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd # Ensure pandas is imported\n",
    "\n",
    "print(\"--- Phase 4: Refined Data Visualization ---\")\n",
    "\n",
    "# Ensure the combined metrics DataFrame exists and includes sentiment\n",
    "if 'df_combined_metrics' in locals() and not df_combined_metrics.empty and 'avg_tweet_sentiment' in df_combined_metrics.columns:\n",
    "\n",
    "    # --- Plot 1: Tweet Volume (Hype Proxy) ---\n",
    "    # (Keep this plot the same as before)\n",
    "    print(\"\\nGenerating Plot 1: Tweet Volume by Brand...\")\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    df_sorted_hype = df_combined_metrics.sort_values('tweet_volume', ascending=False).head(30)\n",
    "    sns.barplot(data=df_sorted_hype, y='brand_name', x='tweet_volume', palette='viridis')\n",
    "    plt.title('Tweet Volume (Hype Proxy) by Brand (Top 30)')\n",
    "    plt.xlabel('Total Tweets Collected')\n",
    "    plt.ylabel('Brand')\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('..', 'tweet_volume_by_brand_v3.png'))\n",
    "    print(\"   Saved plot as tweet_volume_by_brand_v3.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # --- Plot 2: Market Saturation ---\n",
    "    # (Keep this plot the same as before)\n",
    "    print(\"\\nGenerating Plot 2: Market Saturation (Amazon Products) by Brand...\")\n",
    "    df_saturated = df_combined_metrics[df_combined_metrics['market_saturation'] > 0]\n",
    "    if not df_saturated.empty:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        df_sorted_saturation = df_saturated.sort_values('market_saturation', ascending=False)\n",
    "        sns.barplot(data=df_sorted_saturation, y='brand_name', x='market_saturation', palette='magma')\n",
    "        plt.title('Market Saturation (Amazon Products Found) by Brand')\n",
    "        plt.xlabel('Number of Products Found (Max 25)')\n",
    "        plt.ylabel('Brand')\n",
    "        plt.yticks(fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join('..', 'market_saturation_by_brand_v3.png'))\n",
    "        print(\"   Saved plot as market_saturation_by_brand_v3.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"   Skipping Market Saturation plot: No brands with products found.\")\n",
    "\n",
    "\n",
    "    # --- Plot 3: Hype vs. Saturation Scatter Plot (Style Fix) ---\n",
    "    print(\"\\nGenerating Plot 3: Tweet Volume vs. Market Saturation...\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    df_plot_data = df_combined_metrics[(df_combined_metrics['market_saturation'] > 0) & (df_combined_metrics['tweet_volume'] > 0)].copy()\n",
    "\n",
    "    if not df_plot_data.empty:\n",
    "        # --- FIX: Create a categorical sentiment column ---\n",
    "        def categorize_sentiment(score):\n",
    "            if score >= 0.05: # Threshold for positive\n",
    "                return 'Positive'\n",
    "            elif score <= -0.05: # Threshold for negative\n",
    "                return 'Negative'\n",
    "            else:\n",
    "                return 'Neutral'\n",
    "\n",
    "        df_plot_data['sentiment_category'] = df_plot_data['avg_tweet_sentiment'].apply(categorize_sentiment)\n",
    "        # --- End Fix ---\n",
    "\n",
    "        scatter = sns.scatterplot(\n",
    "            data=df_plot_data,\n",
    "            x='market_saturation',\n",
    "            y='tweet_volume',\n",
    "            hue='avg_perceived_quality',\n",
    "            size='avg_num_reviews',\n",
    "            style='sentiment_category', # *** USE THE NEW CATEGORICAL COLUMN ***\n",
    "            style_order=['Positive', 'Neutral', 'Negative'], # Order remains the same\n",
    "            markers={'Positive': 'P', 'Neutral': 'o', 'Negative': 'X'}, # Markers remain the same\n",
    "            sizes=(50, 600),\n",
    "            palette='coolwarm',\n",
    "            legend='auto'\n",
    "        )\n",
    "\n",
    "        # Add labels (Keep as before)\n",
    "        for i in range(df_plot_data.shape[0]):\n",
    "            plt.text(\n",
    "                x=df_plot_data['market_saturation'].iloc[i] + 0.15,\n",
    "                y=df_plot_data['tweet_volume'].iloc[i] + 10,\n",
    "                s=df_plot_data['brand_name'].iloc[i],\n",
    "                fontdict=dict(color='black', size=8)\n",
    "            )\n",
    "\n",
    "        plt.title('Hype (Tweet Volume) vs. Market Saturation')\n",
    "        plt.xlabel('Market Saturation (Amazon Products)')\n",
    "        plt.ylabel('Tweet Volume (Total Tweets)')\n",
    "\n",
    "        # Add quadrant lines (Keep as before)\n",
    "        median_hype = df_plot_data['tweet_volume'].median()\n",
    "        median_saturation = df_plot_data['market_saturation'].median()\n",
    "        if pd.notna(median_hype): plt.axhline(median_hype, color='grey', linestyle='--', linewidth=0.8)\n",
    "        if pd.notna(median_saturation): plt.axvline(median_saturation, color='grey', linestyle='--', linewidth=0.8)\n",
    "\n",
    "        plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "        plt.savefig(os.path.join('..', 'hype_vs_saturation_v3.png')) # Overwrite previous v3\n",
    "        print(\"   Saved plot as hype_vs_saturation_v3.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "         print(\"   Skipping Hype vs. Saturation plot: No brands with both products and tweets found.\")\n",
    "\n",
    "    # --- Plot 4: Average Tweet Sentiment ---\n",
    "    # (Keep this plot the same as before)\n",
    "    print(\"\\nGenerating Plot 4: Average Tweet Sentiment by Brand...\")\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    df_sorted_sentiment = df_combined_metrics.sort_values('avg_tweet_sentiment', ascending=False)\n",
    "    # Define colors based on sentiment category\n",
    "    sentiment_colors = {'Positive': 'green', 'Neutral': 'grey', 'Negative': 'red'}\n",
    "    # Apply categorize function to main df for coloring this plot too\n",
    "    df_sorted_sentiment['sentiment_category'] = df_sorted_sentiment['avg_tweet_sentiment'].apply(categorize_sentiment)\n",
    "    bar_colors = df_sorted_sentiment['sentiment_category'].map(sentiment_colors)\n",
    "\n",
    "    barplot_sentiment = sns.barplot(\n",
    "        data=df_sorted_sentiment,\n",
    "        y='brand_name',\n",
    "        x='avg_tweet_sentiment',\n",
    "        palette=bar_colors # Use mapped colors\n",
    "    )\n",
    "    plt.title('Average Tweet Sentiment by Brand (VADER Compound Score)')\n",
    "    plt.xlabel('Average Sentiment (-1 Negative to +1 Positive)')\n",
    "    plt.ylabel('Brand')\n",
    "    plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('..', 'avg_tweet_sentiment_by_brand_v3.png')) # Overwrite previous v3\n",
    "    print(\"   Saved plot as avg_tweet_sentiment_by_brand_v3.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    print(\"\\n--- Visualization Complete ---\")\n",
    "\n",
    "else:\n",
    "    print(\"   ERROR: 'df_combined_metrics' DataFrame not found or empty, or missing 'avg_tweet_sentiment'. Cannot create plots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76176b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 4: Refined Data Visualization ---\n",
      "\n",
      "Generating Plot 1: Tweet Volume by Brand...\n",
      "   Saved plot as tweet_volume_by_brand_v3.png\n",
      "\n",
      "Generating Plot 2: Market Saturation (Amazon Products) by Brand...\n",
      "   Saved plot as market_saturation_by_brand_v3.png\n",
      "\n",
      "Generating Plot 3: Tweet Volume vs. Market Saturation...\n",
      "   Saved plot as hype_vs_saturation_v3.png\n",
      "\n",
      "Generating Plot 4: Average Tweet Sentiment by Brand...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nayef Alam\\AppData\\Local\\Temp\\ipykernel_15664\\1281034600.py:115: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  barplot_sentiment = sns.barplot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved plot as avg_tweet_sentiment_by_brand_v3.png\n",
      "\n",
      "--- Visualization Complete ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Phase 4 - Refined Visualization (Palette Fix)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd # Ensure pandas is imported\n",
    "\n",
    "print(\"--- Phase 4: Refined Data Visualization ---\")\n",
    "\n",
    "# Ensure the combined metrics DataFrame exists and includes sentiment\n",
    "if 'df_combined_metrics' in locals() and not df_combined_metrics.empty and 'avg_tweet_sentiment' in df_combined_metrics.columns:\n",
    "\n",
    "    # --- Plot 1: Tweet Volume (Hype Proxy) ---\n",
    "    # (Keep this plot the same as before)\n",
    "    print(\"\\nGenerating Plot 1: Tweet Volume by Brand...\")\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    df_sorted_hype = df_combined_metrics.sort_values('tweet_volume', ascending=False).head(30)\n",
    "    sns.barplot(data=df_sorted_hype, y='brand_name', x='tweet_volume', hue='brand_name', palette='viridis', legend=False) # Use hue trick\n",
    "    plt.title('Tweet Volume (Hype Proxy) by Brand (Top 30)')\n",
    "    plt.xlabel('Total Tweets Collected')\n",
    "    plt.ylabel('Brand')\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('..', 'tweet_volume_by_brand_v3.png'))\n",
    "    print(\"   Saved plot as tweet_volume_by_brand_v3.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    # --- Plot 2: Market Saturation ---\n",
    "    # (Keep this plot the same as before)\n",
    "    print(\"\\nGenerating Plot 2: Market Saturation (Amazon Products) by Brand...\")\n",
    "    df_saturated = df_combined_metrics[df_combined_metrics['market_saturation'] > 0]\n",
    "    if not df_saturated.empty:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        df_sorted_saturation = df_saturated.sort_values('market_saturation', ascending=False)\n",
    "        sns.barplot(data=df_sorted_saturation, y='brand_name', x='market_saturation', hue='brand_name', palette='magma', legend=False) # Use hue trick\n",
    "        plt.title('Market Saturation (Amazon Products Found) by Brand')\n",
    "        plt.xlabel('Number of Products Found (Max 25)')\n",
    "        plt.ylabel('Brand')\n",
    "        plt.yticks(fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join('..', 'market_saturation_by_brand_v3.png'))\n",
    "        print(\"   Saved plot as market_saturation_by_brand_v3.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"   Skipping Market Saturation plot: No brands with products found.\")\n",
    "\n",
    "\n",
    "    # --- Plot 3: Hype vs. Saturation Scatter Plot ---\n",
    "    # (Keep this plot the same as before - v2 fix)\n",
    "    print(\"\\nGenerating Plot 3: Tweet Volume vs. Market Saturation...\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    df_plot_data = df_combined_metrics[(df_combined_metrics['market_saturation'] > 0) & (df_combined_metrics['tweet_volume'] > 0)].copy()\n",
    "\n",
    "    if not df_plot_data.empty:\n",
    "        # Create a categorical sentiment column\n",
    "        def categorize_sentiment(score):\n",
    "            if score >= 0.05: return 'Positive'\n",
    "            elif score <= -0.05: return 'Negative'\n",
    "            else: return 'Neutral'\n",
    "        df_plot_data['sentiment_category'] = df_plot_data['avg_tweet_sentiment'].apply(categorize_sentiment)\n",
    "\n",
    "        scatter = sns.scatterplot(\n",
    "            data=df_plot_data,\n",
    "            x='market_saturation',\n",
    "            y='tweet_volume',\n",
    "            hue='avg_perceived_quality',\n",
    "            size='avg_num_reviews',\n",
    "            style='sentiment_category', # Use the categorical column\n",
    "            style_order=['Positive', 'Neutral', 'Negative'],\n",
    "            markers={'Positive': 'P', 'Neutral': 'o', 'Negative': 'X'},\n",
    "            sizes=(50, 600),\n",
    "            palette='coolwarm',\n",
    "            legend='auto'\n",
    "        )\n",
    "        # Add labels\n",
    "        for i in range(df_plot_data.shape[0]):\n",
    "            plt.text(x=df_plot_data['market_saturation'].iloc[i] + 0.15,\n",
    "                     y=df_plot_data['tweet_volume'].iloc[i] + 10,\n",
    "                     s=df_plot_data['brand_name'].iloc[i],\n",
    "                     fontdict=dict(color='black', size=8))\n",
    "\n",
    "        plt.title('Hype (Tweet Volume) vs. Market Saturation')\n",
    "        plt.xlabel('Market Saturation (Amazon Products)')\n",
    "        plt.ylabel('Tweet Volume (Total Tweets)')\n",
    "        # Add quadrant lines\n",
    "        median_hype = df_plot_data['tweet_volume'].median()\n",
    "        median_saturation = df_plot_data['market_saturation'].median()\n",
    "        if pd.notna(median_hype): plt.axhline(median_hype, color='grey', linestyle='--', linewidth=0.8)\n",
    "        if pd.notna(median_saturation): plt.axvline(median_saturation, color='grey', linestyle='--', linewidth=0.8)\n",
    "\n",
    "        plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "        plt.savefig(os.path.join('..', 'hype_vs_saturation_v3.png'))\n",
    "        print(\"   Saved plot as hype_vs_saturation_v3.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "         print(\"   Skipping Hype vs. Saturation plot: No brands with both products and tweets found.\")\n",
    "\n",
    "    # --- Plot 4: Average Tweet Sentiment (Palette Fix) ---\n",
    "    print(\"\\nGenerating Plot 4: Average Tweet Sentiment by Brand...\")\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    df_sorted_sentiment = df_combined_metrics.sort_values('avg_tweet_sentiment', ascending=False)\n",
    "\n",
    "    # --- FIX: Create a list of colors in the correct sorted order ---\n",
    "    sentiment_colors_map = {'Positive': '#2ca02c', 'Neutral': '#8c8c8c', 'Negative': '#d62728'} # Green/Grey/Red\n",
    "    # Apply categorize function if not already present from scatter plot section\n",
    "    if 'sentiment_category' not in df_sorted_sentiment.columns:\n",
    "         df_sorted_sentiment['sentiment_category'] = df_sorted_sentiment['avg_tweet_sentiment'].apply(categorize_sentiment)\n",
    "    # Create the list of colors based on the sorted data\n",
    "    bar_colors_list = df_sorted_sentiment['sentiment_category'].map(sentiment_colors_map).tolist()\n",
    "    # --- End Fix ---\n",
    "\n",
    "    barplot_sentiment = sns.barplot(\n",
    "        data=df_sorted_sentiment,\n",
    "        y='brand_name',\n",
    "        x='avg_tweet_sentiment',\n",
    "        palette=bar_colors_list # *** USE THE LIST OF COLORS ***\n",
    "        # hue='brand_name', # Alt: Could map category to hue, but less direct color control\n",
    "        # legend=False\n",
    "    )\n",
    "    plt.title('Average Tweet Sentiment by Brand (VADER Compound Score)')\n",
    "    plt.xlabel('Average Sentiment (-1 Negative to +1 Positive)')\n",
    "    plt.ylabel('Brand')\n",
    "    plt.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "    plt.yticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('..', 'avg_tweet_sentiment_by_brand_v3.png'))\n",
    "    print(\"   Saved plot as avg_tweet_sentiment_by_brand_v3.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    print(\"\\n--- Visualization Complete ---\")\n",
    "\n",
    "else:\n",
    "    print(\"   ERROR: 'df_combined_metrics' DataFrame not found or empty, or missing 'avg_tweet_sentiment'. Cannot create plots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c958a92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving Final Combined Metrics (with Sentiment) ---\n",
      "   Successfully saved final metrics to: c:\\Users\\Nayef Alam\\Desktop\\ksa_licensing_model\\data\\brand_metrics_final_v2.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Save Final Metrics to CSV\n",
    "\n",
    "import os\n",
    "import pandas as pd # Ensure pandas is imported\n",
    "\n",
    "print(\"\\n--- Saving Final Combined Metrics (with Sentiment) ---\")\n",
    "\n",
    "# Ensure the DataFrame exists\n",
    "if 'df_combined_metrics' in locals() and not df_combined_metrics.empty:\n",
    "    # Define the output path\n",
    "    csv_path_relative = os.path.join('..', 'data', 'brand_metrics_final_v2.csv') # New filename\n",
    "    csv_path = os.path.abspath(csv_path_relative)\n",
    "    \n",
    "    try:\n",
    "        # Save to CSV, excluding the index\n",
    "        df_combined_metrics.to_csv(csv_path, index=False)\n",
    "        print(f\"   Successfully saved final metrics to: {csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Error saving metrics to CSV: {e}\")\n",
    "else:\n",
    "    print(\"   ERROR: 'df_combined_metrics' not found or empty. Cannot save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70381525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
